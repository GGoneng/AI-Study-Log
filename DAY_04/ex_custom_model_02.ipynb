{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchmetrics.regression import R2Score\n",
    "from torchmetrics.classification import F1Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 랜덤 고정\n",
    "torch.manual_seed(1)\n",
    "\n",
    "# 텐서 저장 및 실행 위치\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 사용자 정의 모델 클래스\n",
    "- 부모클래스 : nn.Module\n",
    "- 필수 오버라이딩\n",
    "    * _ _ init _ _ () : 모델 층 구성 즉, 설계\n",
    "    * forward() : 순방향 학습 진행 코드 구현\n",
    "- 동적 모델\n",
    "    * container 모듈 중 nn.ModuleList() 사용해서 동적으로 Layer 추가\n",
    "        - forward 기능 미 제공\n",
    "        - layer 인스턴스 요소 사이에 연관성 없음\n",
    "        - layer 인스턴스 요소는 인덱싱으로 접근\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델 설계 - 동적 모델 <tr>\n",
    "    * 목표 : 은닉층의 개수가 동적인 모델\n",
    "    * 조건\n",
    "        - 입력층과 출력층 개수 동적 => 입력층의 입력값, 출력층의 출력값\n",
    "        - 은닉층의 개수 동적, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------\n",
    "# 모델이름 : DynamicModel\n",
    "# 부모클래스 : nn.Module\n",
    "# 매개 변수 : in_in, out_out, h_inout, h_cnt\n",
    "# -------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DynamicModel(nn.Module):\n",
    "    \n",
    "    # 모델 구조 설계 함수 즉, 생성자 메서드\n",
    "    def __init__(self, in_in, out_out, h_inout, h_cnt):\n",
    "        super().__init__()\n",
    "\n",
    "        self.in_layer = nn.Linear(in_in, h_inout)\n",
    "        self.h_layers = nn.ModuleList([nn.Linear(h_inout, h_inout) for _ in range(h_cnt)])\n",
    "        self.out_layer = nn.Linear(h_inout, out_out)\n",
    "\n",
    "\n",
    "    # 학습 진행 콜백 메서드\n",
    "    def forward(self, x):\n",
    "        # 입력층\n",
    "        y = self.in_layer(x)        # y = x1w1 + x2w2 + x3w3 + b\n",
    "        y = F.relu(y)               # 0 <= y\n",
    "        # y = F.relu(self.in_layer(x))\n",
    "\n",
    "        # 은닉층\n",
    "        for linear in self.h_layers:\n",
    "            y = linear(y)           \n",
    "            y = F.relu(y)\n",
    "        # y = F.relu(linear(y))\n",
    "\n",
    "        # 출력층\n",
    "        return self.out_layer(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 인스턴스 생성\n",
    "m1 = DynamicModel(3, 2, 5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DynamicModel(\n",
      "  (in_layer): Linear(in_features=3, out_features=5, bias=True)\n",
      "  (h_layers): ModuleList(\n",
      "    (0-9): 10 x Linear(in_features=5, out_features=5, bias=True)\n",
      "  )\n",
      "  (out_layer): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 모델 구조 확인\n",
    "print(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in_layer.weight torch.Size([5, 3])\n",
      "in_layer.bias torch.Size([5])\n",
      "h_layers.0.weight torch.Size([5, 5])\n",
      "h_layers.0.bias torch.Size([5])\n",
      "h_layers.1.weight torch.Size([5, 5])\n",
      "h_layers.1.bias torch.Size([5])\n",
      "h_layers.2.weight torch.Size([5, 5])\n",
      "h_layers.2.bias torch.Size([5])\n",
      "h_layers.3.weight torch.Size([5, 5])\n",
      "h_layers.3.bias torch.Size([5])\n",
      "h_layers.4.weight torch.Size([5, 5])\n",
      "h_layers.4.bias torch.Size([5])\n",
      "h_layers.5.weight torch.Size([5, 5])\n",
      "h_layers.5.bias torch.Size([5])\n",
      "h_layers.6.weight torch.Size([5, 5])\n",
      "h_layers.6.bias torch.Size([5])\n",
      "h_layers.7.weight torch.Size([5, 5])\n",
      "h_layers.7.bias torch.Size([5])\n",
      "h_layers.8.weight torch.Size([5, 5])\n",
      "h_layers.8.bias torch.Size([5])\n",
      "h_layers.9.weight torch.Size([5, 5])\n",
      "h_layers.9.bias torch.Size([5])\n",
      "out_layer.weight torch.Size([2, 5])\n",
      "out_layer.bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# 모델 파라미터 확인\n",
    "for name, param in m1.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 임시 데이터 생성\n",
    "\n",
    "dataTS = torch.FloatTensor([[1, 3, 5], [2, 4, 6], [3, 5, 7], [4, 6, 8]])  # 2D (4, 3)\n",
    "targetTS = torch.FloatTensor([[7, 9], [8, 7], [9, 11], [10, 12]])         # 2D (4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1237, 0.0215],\n",
      "        [0.1237, 0.0215],\n",
      "        [0.1237, 0.0215],\n",
      "        [0.1237, 0.0215]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "pre_y = m1(dataTS)\n",
    "print(pre_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
