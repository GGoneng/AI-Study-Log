{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torchmetrics.regression import R2Score, MeanAbsoluteError, MeanAbsolutePercentageError, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/'\n",
    "\n",
    "electric_df = pd.read_csv(DATA_PATH + 'electric_df_clear_29_days.csv')\n",
    "water_df = pd.read_csv(DATA_PATH + 'water_df_clear_29_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>46</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>43</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "      <td>169</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285993</th>\n",
       "      <td>157</td>\n",
       "      <td>230</td>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>218</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285994</th>\n",
       "      <td>230</td>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>...</td>\n",
       "      <td>218</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285995</th>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285996</th>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>143</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285997</th>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>143</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "      <td>280</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>285998 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...   19   20   21  \\\n",
       "0        30  120  210  410   32  184  180  260   35  145  ...   95   46  139   \n",
       "1       120  210  410   32  184  180  260   35  145  203  ...   46  139  204   \n",
       "2       210  410   32  184  180  260   35  145  203  216  ...  139  204  198   \n",
       "3       410   32  184  180  260   35  145  203  216   43  ...  204  198   53   \n",
       "4        32  184  180  260   35  145  203  216   43  136  ...  198   53  162   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "285993  157  230  169   47  122  218  350  110  183  190  ...   58  218  290   \n",
       "285994  230  169   47  122  218  350  110  183  190  230  ...  218  290  105   \n",
       "285995  169   47  122  218  350  110  183  190  230   98  ...  290  105   10   \n",
       "285996   47  122  218  350  110  183  190  230   98  143  ...  105   10   68   \n",
       "285997  122  218  350  110  183  190  230   98  143  253  ...   10   68   38   \n",
       "\n",
       "         22   23   24   25   26   27   28  \n",
       "0       204  198   53  162  210  150   51  \n",
       "1       198   53  162  210  150   51  169  \n",
       "2        53  162  210  150   51  169  204  \n",
       "3       162  210  150   51  169  204  169  \n",
       "4       210  150   51  169  204  169   38  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "285993  105   10   68   38  263   78  158  \n",
       "285994   10   68   38  263   78  158  290  \n",
       "285995   68   38  263   78  158  290  300  \n",
       "285996   38  263   78  158  290  300  280  \n",
       "285997  263   78  158  290  300  280  160  \n",
       "\n",
       "[285998 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_features = electric_df[electric_df.columns[:-1]]\n",
    "# electric_target = electric_df[electric_df.columns[-1:]]\n",
    "\n",
    "# electric_X_train, electric_X_test, electric_y_train, electric_y_test = train_test_split(electric_features,\n",
    "#                                                     electric_target,\n",
    "#                                                     random_state = 42,\n",
    "                                                    # test_size = 0.2)\n",
    "\n",
    "water_features = water_df[water_df.columns[:-1]]\n",
    "water_target = water_df[water_df.columns[-1:]]\n",
    "\n",
    "water_X_train, water_X_test, water_y_train, water_y_test = train_test_split(water_features,\n",
    "                                                                            water_target,\n",
    "                                                                            random_state = 42,\n",
    "                                                                            test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = self.featureDF.shape[0]\n",
    "        self.n_cols = self.featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, input_size, n_layers, dropout,\n",
    "                 bidirectional):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = n_layers,\n",
    "            dropout = dropout,\n",
    "            bidirectional = bidirectional,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        if bidirectional:\n",
    "            self.linear = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "        else:\n",
    "            self.linear = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # 성능에 따라 추가\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output, _ = self.model(inputs)\n",
    "        logits = self.linear(output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_mmscaler = MinMaxScaler().fit(electric_X_train)\n",
    "water_rbscaler = RobustScaler().fit(water_X_train)\n",
    "\n",
    "# with open('electric_min_max_scaler.pkl', 'wb') as f:\n",
    "#     pickle.dump(electric_mmscaler, f)\n",
    "\n",
    "with open('water_robust_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(water_rbscaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_X_train_scaled = electric_mmscaler.transform(electric_X_train)\n",
    "# electric_X_test_scaled = electric_mmscaler.transform(electric_X_test)\n",
    "\n",
    "water_X_train_scaled = water_rbscaler.transform(water_X_train)\n",
    "water_X_test_scaled = water_rbscaler.transform(water_X_test)\n",
    "\n",
    "# electric_X_train = pd.DataFrame(electric_X_train_scaled, columns = electric_X_train.columns)\n",
    "# electric_X_test = pd.DataFrame(electric_X_test_scaled, columns = electric_X_test.columns)\n",
    "\n",
    "water_X_train = pd.DataFrame(water_X_train_scaled, columns = water_X_train.columns)\n",
    "water_X_test = pd.DataFrame(water_X_test_scaled, columns = water_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 1000\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_trainDS = CustomDataset(electric_X_train, electric_y_train)\n",
    "water_trainDS = CustomDataset(water_X_train, water_y_train)\n",
    "\n",
    "# electric_trainDL = DataLoader(electric_trainDS, batch_size = BATCH_SIZE)\n",
    "water_trainDL = DataLoader(water_trainDS, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "hidden_dim = 32\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "lstm_model = LSTMModel(input_size = input_size, hidden_dim = hidden_dim,\n",
    "                       n_layers = n_layers, dropout = 0.8, bidirectional = True).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MAEloss = MeanAbsoluteError()\n",
    "MAPEloss = MeanAbsolutePercentageError()\n",
    "MSEloss = MeanSquaredError()\n",
    "R2score = R2Score()\n",
    "\n",
    "optimizer = optim.RMSprop(lstm_model.parameters(), lr = LR)\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience = 10, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(featureDF, targetDF, model):\n",
    "    featureTS = torch.FloatTensor(featureDF.values).to(DEVICE)\n",
    "    targetTS = torch.FloatTensor(targetDF.values).to(DEVICE)\n",
    "\n",
    "    model.dropout = nn.Dropout(0)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pre_val = model(featureTS)\n",
    "        mae_loss_val = MAEloss(pre_val, targetTS)\n",
    "        mape_loss_val = MAPEloss(pre_val, targetTS)\n",
    "        mse_loss_val = MSEloss(pre_val, targetTS)\n",
    "        score_val = R2score(pre_val, targetTS)\n",
    "    \n",
    "    return mae_loss_val, mape_loss_val, mse_loss_val, score_val, pre_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def training(testDF, testtargetDF, model, trainDL, test_value):\n",
    "    SAVE_PATH = './saved_models/'\n",
    "    os.makedirs(SAVE_PATH, exist_ok = True)\n",
    "    \n",
    "    BREAK_CNT_LOSS = 0\n",
    "    BREAK_CNT_SCORE = 0\n",
    "    LIMIT_VALUE = 10\n",
    "\n",
    "    MAE_LOSS_HISTORY, MAPE_LOSS_HISTORY, MSE_LOSS_HISTORY, SCORE_HISTORY = [[], []], [[], []], [[], []], [[], []]\n",
    "\n",
    "    for epoch in range(1, EPOCH + 1):\n",
    "        SAVE_MODEL = os.path.join(SAVE_PATH, f'model_{epoch}.pth')\n",
    "        SAVE_WEIGHT = os.path.join(SAVE_PATH, f'model_weights_{epoch}.pth')\n",
    "\n",
    "        mae_loss_total, mape_loss_total, mse_loss_total, score_total = 0, 0, 0, 0\n",
    "\n",
    "        for featureTS, targetTS in trainDL:\n",
    "            pre_y = model(featureTS)\n",
    "\n",
    "            mae_loss = MAEloss(pre_y, targetTS)\n",
    "            mape_loss = MAPEloss(pre_y, targetTS)\n",
    "            mse_loss = MSEloss(pre_y, targetTS)\n",
    "\n",
    "            mae_loss_total += mae_loss.item()\n",
    "            mape_loss_total += mape_loss.item()\n",
    "            mse_loss_total += mse_loss.item()\n",
    "\n",
    "            score = R2score(pre_y, targetTS)\n",
    "            score_total += score.item()\n",
    "\n",
    "            total_loss = mae_loss + mape_loss + mse_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            total_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        test_mae_loss, test_mape_loss, test_mse_loss, test_score, pre_val = testing(testDF, testtargetDF, model)\n",
    "\n",
    "        MAE_LOSS_HISTORY[1].append(test_mae_loss)\n",
    "        MAPE_LOSS_HISTORY[1].append(test_mape_loss)\n",
    "        MSE_LOSS_HISTORY[1].append(test_mse_loss)\n",
    "        SCORE_HISTORY[1].append(test_score)\n",
    "\n",
    "        MAE_LOSS_HISTORY[0].append(mae_loss_total / len(trainDL))\n",
    "        MAPE_LOSS_HISTORY[0].append(mape_loss_total / len(trainDL))\n",
    "        MSE_LOSS_HISTORY[0].append(mse_loss_total / len(trainDL))\n",
    "        SCORE_HISTORY[0].append(score_total / len(trainDL))\n",
    "\n",
    "        print(f'pre_val : {pre_val.squeeze().tolist()[:10]}\\ny_val : {test_value.values.squeeze()[:10]}\\n')\n",
    "        print(f'[{epoch} / {EPOCH}]\\n- TRAIN MAE LOSS : {MAE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN MAPE LOSS : {MAPE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN MSE LOSS : {MSE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN R2 SCORE : {SCORE_HISTORY[0][-1]}')\n",
    "\n",
    "        print(f'\\n- TEST MAE LOSS : {MAE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST MAPE LOSS : {MAPE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST MSE LOSS : {MSE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST R2 SCORE : {SCORE_HISTORY[1][-1]}')\n",
    "\n",
    "        scheduler.step(test_mae_loss)\n",
    "\n",
    "        if len(MAE_LOSS_HISTORY[1]) >= 2:\n",
    "            if MAE_LOSS_HISTORY[1][-1] >= MAE_LOSS_HISTORY[1][-2]: BREAK_CNT_LOSS += 1\n",
    "        \n",
    "        if len(MAE_LOSS_HISTORY[1]) == 1:\n",
    "            torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "            torch.save(model, SAVE_MODEL)\n",
    "\n",
    "        else:\n",
    "            if MAE_LOSS_HISTORY[1][-1] < min(MAE_LOSS_HISTORY[1][:-1]):\n",
    "                torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "                torch.save(model, SAVE_MODEL)\n",
    "\n",
    "        if BREAK_CNT_LOSS > LIMIT_VALUE:\n",
    "            print(f\"성능 및 손실 개선이 없어서 {epoch} EPOCH에 학습 중단\")\n",
    "            # break\n",
    "\n",
    "    return MAE_LOSS_HISTORY, MAPE_LOSS_HISTORY, MSE_LOSS_HISTORY, SCORE_HISTORY\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>119333</th>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236638</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117513</th>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209007</th>\n",
       "      <td>247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207409</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43073</th>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52402</th>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277853</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59613</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114786</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57200 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         28\n",
       "119333   89\n",
       "236638   48\n",
       "117513  247\n",
       "209007  247\n",
       "207409    0\n",
       "...     ...\n",
       "43073   183\n",
       "52402   138\n",
       "277853   68\n",
       "59613   169\n",
       "114786   98\n",
       "\n",
       "[57200 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_val : [-0.0005031281616538763, 0.0002174127148464322, -0.0006967181107029319, -0.002038670936599374, 0.0005717736785300076, 0.0012404473964124918, 0.0006877220585010946, 0.00014109385665506124, -0.0002617588033899665, -0.0001903116935864091]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[1 / 1000]\n",
      "- TRAIN MAE LOSS : 148.4133433671431\n",
      "- TRAIN MAPE LOSS : 56.276339930954514\n",
      "- TRAIN MSE LOSS : 27965.38809112762\n",
      "- TRAIN R2 SCORE : -3.917754272380909\n",
      "\n",
      "- TEST MAE LOSS : 148.40951538085938\n",
      "- TEST MAPE LOSS : 4.171219825744629\n",
      "- TEST MSE LOSS : 27992.443359375\n",
      "- TEST R2 SCORE : -3.691161632537842\n",
      "pre_val : [0.2561482787132263, 0.786186933517456, 8.731070518493652, 8.226560592651367, -0.027132399380207062, -0.028904732316732407, -0.016484947875142097, 0.26703178882598877, 5.556141376495361, 9.656758308410645]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[2 / 1000]\n",
      "- TRAIN MAE LOSS : 147.0631425849541\n",
      "- TRAIN MAPE LOSS : 393.19455222089806\n",
      "- TRAIN MSE LOSS : 27496.623267045456\n",
      "- TRAIN R2 SCORE : -3.8342396849518887\n",
      "\n",
      "- TEST MAE LOSS : 142.50035095214844\n",
      "- TEST MAPE LOSS : 1102.6170654296875\n",
      "- TEST MSE LOSS : 25984.48828125\n",
      "- TEST R2 SCORE : -3.3546547889709473\n",
      "pre_val : [2.3503336906433105, 17.736909866333008, 34.529518127441406, 31.068058013916016, -0.0053801266476511955, -0.01793729141354561, 0.013096372596919537, 1.3798489570617676, 24.533279418945312, 34.25750732421875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[3 / 1000]\n",
      "- TRAIN MAE LOSS : 133.5355219252793\n",
      "- TRAIN MAPE LOSS : 2858.4138574102876\n",
      "- TRAIN MSE LOSS : 23289.74263740166\n",
      "- TRAIN R2 SCORE : -3.0841143008545564\n",
      "\n",
      "- TEST MAE LOSS : 124.79730987548828\n",
      "- TEST MAPE LOSS : 3714.3046875\n",
      "- TEST MSE LOSS : 20661.73828125\n",
      "- TEST R2 SCORE : -2.462632656097412\n",
      "pre_val : [14.279955863952637, 43.27168655395508, 62.99561309814453, 57.79800796508789, -0.00024268458946608007, 0.6711336374282837, 0.11385315656661987, 1.6945363283157349, 48.51736831665039, 62.685546875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[4 / 1000]\n",
      "- TRAIN MAE LOSS : 113.32412566711852\n",
      "- TRAIN MAPE LOSS : 5624.483867692381\n",
      "- TRAIN MSE LOSS : 17742.87887784091\n",
      "- TRAIN R2 SCORE : -2.098751436113478\n",
      "\n",
      "- TEST MAE LOSS : 104.30498504638672\n",
      "- TEST MAPE LOSS : 5979.931640625\n",
      "- TEST MSE LOSS : 15341.6943359375\n",
      "- TEST R2 SCORE : -1.5710639953613281\n",
      "pre_val : [30.7845516204834, 62.848751068115234, 85.57772827148438, 81.40093994140625, -0.001301165553741157, 0.6819790005683899, 0.15432165563106537, 0.8377676010131836, 70.8049545288086, 84.33262634277344]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[5 / 1000]\n",
      "- TRAIN MAE LOSS : 96.06903869842316\n",
      "- TRAIN MAPE LOSS : 7455.776895227982\n",
      "- TRAIN MSE LOSS : 13510.397743935751\n",
      "- TRAIN R2 SCORE : -1.3479056120919182\n",
      "\n",
      "- TEST MAE LOSS : 90.08724975585938\n",
      "- TEST MAPE LOSS : 7478.10498046875\n",
      "- TEST MSE LOSS : 12083.26953125\n",
      "- TEST R2 SCORE : -1.0249953269958496\n",
      "pre_val : [56.1922492980957, 90.29606628417969, 109.17533874511719, 105.54487609863281, 0.0007813571719452739, 1.603020191192627, 0.2960074245929718, 2.944941997528076, 100.17111206054688, 108.25069427490234]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[6 / 1000]\n",
      "- TRAIN MAE LOSS : 81.20657901150364\n",
      "- TRAIN MAPE LOSS : 8210.263985409812\n",
      "- TRAIN MSE LOSS : 10236.06231411167\n",
      "- TRAIN R2 SCORE : -0.769060240025287\n",
      "\n",
      "- TEST MAE LOSS : 71.38228607177734\n",
      "- TEST MAPE LOSS : 14749.0546875\n",
      "- TEST MSE LOSS : 8256.4375\n",
      "- TEST R2 SCORE : -0.38366925716400146\n",
      "pre_val : [73.33692932128906, 82.67925262451172, 130.02911376953125, 126.04204559326172, -0.000857834646012634, 2.2094638347625732, 1.006474494934082, 1.5444812774658203, 117.38162994384766, 128.90821838378906]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[7 / 1000]\n",
      "- TRAIN MAE LOSS : 69.18906872729322\n",
      "- TRAIN MAPE LOSS : 8373.052741582786\n",
      "- TRAIN MSE LOSS : 7905.881775021853\n",
      "- TRAIN R2 SCORE : -0.35877299962343867\n",
      "\n",
      "- TEST MAE LOSS : 60.20476531982422\n",
      "- TEST MAPE LOSS : 16472.509765625\n",
      "- TEST MSE LOSS : 6327.41259765625\n",
      "- TEST R2 SCORE : -0.06039023399353027\n",
      "pre_val : [70.45110321044922, 70.16992950439453, 146.19671630859375, 140.39772033691406, -0.00016892497660592198, 2.1585323810577393, 0.42252811789512634, 1.7876533269882202, 131.3910369873047, 139.28176879882812]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[8 / 1000]\n",
      "- TRAIN MAE LOSS : 59.701187331192976\n",
      "- TRAIN MAPE LOSS : 8453.358664118126\n",
      "- TRAIN MSE LOSS : 6386.487895200503\n",
      "- TRAIN R2 SCORE : -0.09332828995231149\n",
      "\n",
      "- TEST MAE LOSS : 53.49982452392578\n",
      "- TEST MAPE LOSS : 18899.623046875\n",
      "- TEST MSE LOSS : 5371.40234375\n",
      "- TEST R2 SCORE : 0.09982430934906006\n",
      "pre_val : [30.982969284057617, 54.57573318481445, 160.2926025390625, 152.16351318359375, -0.0012347858864814043, 1.6051803827285767, 0.08311097323894501, 0.10511539876461029, 102.99466705322266, 147.589599609375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[9 / 1000]\n",
      "- TRAIN MAE LOSS : 55.22176767309229\n",
      "- TRAIN MAPE LOSS : 6507.568815285046\n",
      "- TRAIN MSE LOSS : 5669.939179004589\n",
      "- TRAIN R2 SCORE : 0.029511536034670743\n",
      "\n",
      "- TEST MAE LOSS : 53.01390838623047\n",
      "- TEST MAPE LOSS : 11211.27734375\n",
      "- TEST MSE LOSS : 5252.13916015625\n",
      "- TEST R2 SCORE : 0.11981123685836792\n",
      "pre_val : [38.4758186340332, 69.56629943847656, 172.7102813720703, 161.6136474609375, 0.0014945592265576124, 15.634401321411133, 0.12674210965633392, 0.0010072618024423718, 147.21896362304688, 153.8919677734375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[10 / 1000]\n",
      "- TRAIN MAE LOSS : 51.68574015210559\n",
      "- TRAIN MAPE LOSS : 4798.119572299464\n",
      "- TRAIN MSE LOSS : 4969.947929858227\n",
      "- TRAIN R2 SCORE : 0.1489527673154444\n",
      "\n",
      "- TEST MAE LOSS : 50.93163299560547\n",
      "- TEST MAPE LOSS : 13216.9423828125\n",
      "- TEST MSE LOSS : 4835.3623046875\n",
      "- TEST R2 SCORE : 0.18965750932693481\n",
      "pre_val : [27.39461898803711, 73.68701934814453, 178.46266174316406, 161.33314514160156, 0.0011130814673379064, 20.6632022857666, 0.20377320051193237, -0.04515339806675911, 133.1910858154297, 146.3465576171875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[11 / 1000]\n",
      "- TRAIN MAE LOSS : 48.90160978197218\n",
      "- TRAIN MAPE LOSS : 3883.6000785152187\n",
      "- TRAIN MSE LOSS : 4507.257332447825\n",
      "- TRAIN R2 SCORE : 0.22807974421894633\n",
      "\n",
      "- TEST MAE LOSS : 48.389957427978516\n",
      "- TEST MAPE LOSS : 13652.146484375\n",
      "- TEST MSE LOSS : 4436.93603515625\n",
      "- TEST R2 SCORE : 0.25642848014831543\n",
      "pre_val : [28.80303192138672, 71.4819564819336, 182.40699768066406, 163.4413604736328, 0.0006819948321208358, 46.74103927612305, 1.6837756633758545, -0.33642375469207764, 160.16775512695312, 116.1917495727539]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[12 / 1000]\n",
      "- TRAIN MAE LOSS : 45.293898875629985\n",
      "- TRAIN MAPE LOSS : 2571.2060295256283\n",
      "- TRAIN MSE LOSS : 4063.762835309222\n",
      "- TRAIN R2 SCORE : 0.3050977366620844\n",
      "\n",
      "- TEST MAE LOSS : 46.66593551635742\n",
      "- TEST MAPE LOSS : 11694.1015625\n",
      "- TEST MSE LOSS : 4344.80322265625\n",
      "- TEST R2 SCORE : 0.2718687057495117\n",
      "pre_val : [32.291473388671875, 65.50888061523438, 184.11099243164062, 156.2073211669922, -0.0007215731893666089, 38.630393981933594, 6.1353440284729, -0.02452327311038971, 165.60780334472656, 130.769287109375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[13 / 1000]\n",
      "- TRAIN MAE LOSS : 43.54462945257867\n",
      "- TRAIN MAPE LOSS : 2646.1770605459665\n",
      "- TRAIN MSE LOSS : 3851.994386916794\n",
      "- TRAIN R2 SCORE : 0.3414456067051921\n",
      "\n",
      "- TEST MAE LOSS : 42.8524284362793\n",
      "- TEST MAPE LOSS : 13279.3271484375\n",
      "- TEST MSE LOSS : 3761.092041015625\n",
      "- TEST R2 SCORE : 0.3696909546852112\n",
      "pre_val : [39.02806091308594, 72.01101684570312, 202.12522888183594, 168.72621154785156, 0.0006052349344827235, 33.565879821777344, 2.448932647705078, -0.12357962876558304, 190.70684814453125, 123.22686767578125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[14 / 1000]\n",
      "- TRAIN MAE LOSS : 41.101747233250755\n",
      "- TRAIN MAPE LOSS : 1675.6751811357688\n",
      "- TRAIN MSE LOSS : 3519.146876331676\n",
      "- TRAIN R2 SCORE : 0.39845209780272905\n",
      "\n",
      "- TEST MAE LOSS : 41.28887176513672\n",
      "- TEST MAPE LOSS : 11349.83203125\n",
      "- TEST MSE LOSS : 3521.925048828125\n",
      "- TEST R2 SCORE : 0.4097721576690674\n",
      "pre_val : [52.09597396850586, 69.96835327148438, 204.3731689453125, 175.69744873046875, 0.00029982926207594573, 47.19546127319336, 5.723025798797607, -0.2228332906961441, 197.94996643066406, 117.00414276123047]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[15 / 1000]\n",
      "- TRAIN MAE LOSS : 39.084455275102094\n",
      "- TRAIN MAPE LOSS : 1331.3807577440164\n",
      "- TRAIN MSE LOSS : 3258.903692430616\n",
      "- TRAIN R2 SCORE : 0.44283059285237236\n",
      "\n",
      "- TEST MAE LOSS : 39.276241302490234\n",
      "- TEST MAPE LOSS : 12847.5322265625\n",
      "- TEST MSE LOSS : 3302.37109375\n",
      "- TEST R2 SCORE : 0.44656646251678467\n",
      "pre_val : [26.604412078857422, 62.21879196166992, 207.4422607421875, 192.80111694335938, 0.00035435418249107897, 40.18681716918945, 7.488453388214111, 0.008340888656675816, 210.05770874023438, 114.70442962646484]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[16 / 1000]\n",
      "- TRAIN MAE LOSS : 37.28452028874751\n",
      "- TRAIN MAPE LOSS : 966.4958641706605\n",
      "- TRAIN MSE LOSS : 2996.2947798295454\n",
      "- TRAIN R2 SCORE : 0.48762274782140774\n",
      "\n",
      "- TEST MAE LOSS : 37.943084716796875\n",
      "- TEST MAPE LOSS : 12606.7900390625\n",
      "- TEST MSE LOSS : 3101.6435546875\n",
      "- TEST R2 SCORE : 0.4802057147026062\n",
      "pre_val : [16.084856033325195, 57.37434768676758, 210.3877716064453, 200.20657348632812, 0.0014571989886462688, 42.93730163574219, 21.572542190551758, 0.572654128074646, 223.90919494628906, 117.41895294189453]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[17 / 1000]\n",
      "- TRAIN MAE LOSS : 35.21014732040725\n",
      "- TRAIN MAPE LOSS : 1080.8919841354002\n",
      "- TRAIN MSE LOSS : 2717.59982988691\n",
      "- TRAIN R2 SCORE : 0.536117072088735\n",
      "\n",
      "- TEST MAE LOSS : 34.883689880371094\n",
      "- TEST MAPE LOSS : 18274.8828125\n",
      "- TEST MSE LOSS : 2667.555419921875\n",
      "- TEST R2 SCORE : 0.5529531240463257\n",
      "pre_val : [21.32012939453125, 57.42844009399414, 219.73605346679688, 202.1100311279297, 0.00020606940961442888, 59.63032150268555, 39.81270980834961, 0.05260978639125824, 233.8778839111328, 103.68814086914062]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[18 / 1000]\n",
      "- TRAIN MAE LOSS : 33.29401388048292\n",
      "- TRAIN MAPE LOSS : 717.2838787565698\n",
      "- TRAIN MSE LOSS : 2468.001298623252\n",
      "- TRAIN R2 SCORE : 0.5788887089615935\n",
      "\n",
      "- TEST MAE LOSS : 33.278629302978516\n",
      "- TEST MAPE LOSS : 16038.470703125\n",
      "- TEST MSE LOSS : 2512.999755859375\n",
      "- TEST R2 SCORE : 0.5788546204566956\n",
      "pre_val : [28.223169326782227, 63.47313690185547, 230.0333709716797, 214.4718475341797, 0.0006509695667773485, 66.31898498535156, 72.79261016845703, 0.028038574382662773, 239.7721405029297, 101.6652603149414]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[19 / 1000]\n",
      "- TRAIN MAE LOSS : 31.97396999119045\n",
      "- TRAIN MAPE LOSS : 663.2980460146674\n",
      "- TRAIN MSE LOSS : 2296.5359784575776\n",
      "- TRAIN R2 SCORE : 0.6071684758646505\n",
      "\n",
      "- TEST MAE LOSS : 30.931379318237305\n",
      "- TEST MAPE LOSS : 16926.779296875\n",
      "- TEST MSE LOSS : 2185.040771484375\n",
      "- TEST R2 SCORE : 0.6338161826133728\n",
      "pre_val : [21.151559829711914, 56.30742645263672, 233.50901794433594, 200.1565399169922, -0.0018337462097406387, 63.45969009399414, 101.27462005615234, -0.01676088199019432, 249.32113647460938, 108.30635833740234]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[20 / 1000]\n",
      "- TRAIN MAE LOSS : 30.001954733041618\n",
      "- TRAIN MAPE LOSS : 753.6288787300562\n",
      "- TRAIN MSE LOSS : 2059.324868659173\n",
      "- TRAIN R2 SCORE : 0.6479196932599262\n",
      "\n",
      "- TEST MAE LOSS : 29.00138282775879\n",
      "- TEST MAPE LOSS : 19861.271484375\n",
      "- TEST MSE LOSS : 1978.0880126953125\n",
      "- TEST R2 SCORE : 0.6684987545013428\n",
      "pre_val : [14.642580032348633, 56.25552749633789, 237.6457977294922, 159.8123779296875, -0.0006628839764744043, 78.23014068603516, 114.73344421386719, -0.24268758296966553, 252.27294921875, 108.9194107055664]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[21 / 1000]\n",
      "- TRAIN MAE LOSS : 28.99346883280294\n",
      "- TRAIN MAPE LOSS : 625.2515915000855\n",
      "- TRAIN MSE LOSS : 1953.4708412437171\n",
      "- TRAIN R2 SCORE : 0.6653852785550631\n",
      "\n",
      "- TEST MAE LOSS : 29.05586051940918\n",
      "- TEST MAPE LOSS : 15100.4443359375\n",
      "- TEST MSE LOSS : 1989.123046875\n",
      "- TEST R2 SCORE : 0.6666494011878967\n",
      "pre_val : [17.132612228393555, 53.30632781982422, 235.2838592529297, 175.24005126953125, -0.00040364338201470673, 62.250572204589844, 118.33466339111328, -0.013583733700215816, 256.32708740234375, 115.6894760131836]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[22 / 1000]\n",
      "- TRAIN MAE LOSS : 27.545353927612304\n",
      "- TRAIN MAPE LOSS : 537.52272151446\n",
      "- TRAIN MSE LOSS : 1792.374860114251\n",
      "- TRAIN R2 SCORE : 0.6924014484465539\n",
      "\n",
      "- TEST MAE LOSS : 26.373798370361328\n",
      "- TEST MAPE LOSS : 20458.888671875\n",
      "- TEST MSE LOSS : 1713.2122802734375\n",
      "- TEST R2 SCORE : 0.7128883600234985\n",
      "pre_val : [23.23554229736328, 55.62155532836914, 237.72427368164062, 186.14515686035156, 0.0009981195908039808, 63.84496307373047, 151.48484802246094, -0.04170072823762894, 251.035888671875, 110.3213119506836]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[23 / 1000]\n",
      "- TRAIN MAE LOSS : 25.940585687010437\n",
      "- TRAIN MAPE LOSS : 295.2284035781047\n",
      "- TRAIN MSE LOSS : 1630.365426768056\n",
      "- TRAIN R2 SCORE : 0.7201544908043388\n",
      "\n",
      "- TEST MAE LOSS : 25.38923454284668\n",
      "- TEST MAPE LOSS : 17421.080078125\n",
      "- TEST MSE LOSS : 1611.419677734375\n",
      "- TEST R2 SCORE : 0.7299474477767944\n",
      "pre_val : [13.812542915344238, 48.713802337646484, 249.0734100341797, 146.53253173828125, 0.0012118894373998046, 52.884010314941406, 142.9923095703125, 0.08998159319162369, 247.2351837158203, 115.9789810180664]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[24 / 1000]\n",
      "- TRAIN MAE LOSS : 24.782957677774498\n",
      "- TRAIN MAPE LOSS : 279.43316221497486\n",
      "- TRAIN MSE LOSS : 1508.3532807548897\n",
      "- TRAIN R2 SCORE : 0.7405996307126292\n",
      "\n",
      "- TEST MAE LOSS : 24.119094848632812\n",
      "- TEST MAPE LOSS : 21709.80859375\n",
      "- TEST MSE LOSS : 1492.9454345703125\n",
      "- TEST R2 SCORE : 0.7498021721839905\n",
      "pre_val : [24.503509521484375, 55.12220764160156, 251.33058166503906, 158.28265380859375, -0.00034643590333871543, 72.27269744873047, 165.70399475097656, -0.007988018915057182, 247.2981414794922, 115.07640075683594]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[25 / 1000]\n",
      "- TRAIN MAE LOSS : 23.47064986649093\n",
      "- TRAIN MAPE LOSS : 345.4566954258376\n",
      "- TRAIN MSE LOSS : 1394.177071575885\n",
      "- TRAIN R2 SCORE : 0.7600555291709367\n",
      "\n",
      "- TEST MAE LOSS : 23.142696380615234\n",
      "- TEST MAPE LOSS : 18040.6875\n",
      "- TEST MSE LOSS : 1403.7376708984375\n",
      "- TEST R2 SCORE : 0.764752209186554\n",
      "pre_val : [17.419174194335938, 51.420440673828125, 258.9714660644531, 156.33668518066406, -0.001014092587865889, 70.13246154785156, 155.36676025390625, 0.0154918497428298, 241.21658325195312, 114.44235229492188]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[26 / 1000]\n",
      "- TRAIN MAE LOSS : 22.781017323740713\n",
      "- TRAIN MAPE LOSS : 376.1812650175403\n",
      "- TRAIN MSE LOSS : 1325.3374944001312\n",
      "- TRAIN R2 SCORE : 0.7713389455688583\n",
      "\n",
      "- TEST MAE LOSS : 22.221179962158203\n",
      "- TEST MAPE LOSS : 20667.26953125\n",
      "- TEST MSE LOSS : 1319.362548828125\n",
      "- TEST R2 SCORE : 0.7788923978805542\n",
      "pre_val : [34.228519439697266, 57.99974060058594, 261.50970458984375, 182.4645233154297, 0.00048203690676018596, 79.68827056884766, 205.33094787597656, 0.45818448066711426, 244.06500244140625, 117.20350646972656]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[27 / 1000]\n",
      "- TRAIN MAE LOSS : 21.801505973122335\n",
      "- TRAIN MAPE LOSS : 339.985630179554\n",
      "- TRAIN MSE LOSS : 1250.4796257904693\n",
      "- TRAIN R2 SCORE : 0.7840231354420002\n",
      "\n",
      "- TEST MAE LOSS : 21.012561798095703\n",
      "- TEST MAPE LOSS : 24718.67578125\n",
      "- TEST MSE LOSS : 1204.17529296875\n",
      "- TEST R2 SCORE : 0.7981961965560913\n",
      "pre_val : [21.80379867553711, 52.81609344482422, 255.37033081054688, 138.9327850341797, 0.0013691418571397662, 67.0077133178711, 175.6062469482422, 0.023983292281627655, 230.86566162109375, 112.47581481933594]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[28 / 1000]\n",
      "- TRAIN MAE LOSS : 20.85837203819435\n",
      "- TRAIN MAPE LOSS : 546.4603771267383\n",
      "- TRAIN MSE LOSS : 1170.3413174801274\n",
      "- TRAIN R2 SCORE : 0.7978210914718521\n",
      "\n",
      "- TEST MAE LOSS : 20.873247146606445\n",
      "- TEST MAPE LOSS : 23213.30859375\n",
      "- TEST MSE LOSS : 1196.635498046875\n",
      "- TEST R2 SCORE : 0.7994598150253296\n",
      "pre_val : [35.41004180908203, 58.60935974121094, 269.3395690917969, 176.1493682861328, 0.0013547370908781886, 67.12191772460938, 197.18898010253906, 3.385446548461914, 249.05966186523438, 112.91950988769531]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[29 / 1000]\n",
      "- TRAIN MAE LOSS : 20.493467190882544\n",
      "- TRAIN MAPE LOSS : 707.6706033683761\n",
      "- TRAIN MSE LOSS : 1144.757264387224\n",
      "- TRAIN R2 SCORE : 0.8019728434669388\n",
      "\n",
      "- TEST MAE LOSS : 19.78019142150879\n",
      "- TEST MAPE LOSS : 25493.291015625\n",
      "- TEST MSE LOSS : 1107.666748046875\n",
      "- TEST R2 SCORE : 0.814369797706604\n",
      "pre_val : [27.927257537841797, 62.8719596862793, 260.26690673828125, 173.69900512695312, 0.0018915461841970682, 68.87225341796875, 190.11428833007812, 0.38902002573013306, 248.3711395263672, 120.77001190185547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[30 / 1000]\n",
      "- TRAIN MAE LOSS : 19.75180907802982\n",
      "- TRAIN MAPE LOSS : 538.1311050383923\n",
      "- TRAIN MSE LOSS : 1074.6061542174866\n",
      "- TRAIN R2 SCORE : 0.8141173760040656\n",
      "\n",
      "- TEST MAE LOSS : 19.626062393188477\n",
      "- TEST MAPE LOSS : 22346.72265625\n",
      "- TEST MSE LOSS : 1106.05859375\n",
      "- TEST R2 SCORE : 0.8146392703056335\n",
      "pre_val : [7.489499092102051, 57.581974029541016, 277.5794982910156, 156.4637908935547, -6.909045623615384e-05, 56.66765594482422, 170.04696655273438, 0.005305400583893061, 230.53475952148438, 119.09646606445312]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[31 / 1000]\n",
      "- TRAIN MAE LOSS : 19.0471961550946\n",
      "- TRAIN MAPE LOSS : 710.7590556447052\n",
      "- TRAIN MSE LOSS : 1031.8760365135354\n",
      "- TRAIN R2 SCORE : 0.821291284394431\n",
      "\n",
      "- TEST MAE LOSS : 18.974672317504883\n",
      "- TEST MAPE LOSS : 23000.171875\n",
      "- TEST MSE LOSS : 1050.121337890625\n",
      "- TEST R2 SCORE : 0.8240135908126831\n",
      "pre_val : [47.972652435302734, 58.891239166259766, 268.9513854980469, 184.23251342773438, 0.0014328653924167156, 66.29008483886719, 200.91464233398438, 1.220433235168457, 238.560791015625, 113.66317749023438]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[32 / 1000]\n",
      "- TRAIN MAE LOSS : 18.553525103322276\n",
      "- TRAIN MAPE LOSS : 200.1594891631499\n",
      "- TRAIN MSE LOSS : 983.6156584711675\n",
      "- TRAIN R2 SCORE : 0.8296474228705559\n",
      "\n",
      "- TEST MAE LOSS : 17.795326232910156\n",
      "- TEST MAPE LOSS : 22773.375\n",
      "- TEST MSE LOSS : 977.6248779296875\n",
      "- TEST R2 SCORE : 0.8361630439758301\n",
      "pre_val : [16.85388946533203, 67.81105041503906, 267.630615234375, 152.1041717529297, 0.001478475285694003, 61.53437042236328, 182.528076171875, 0.023845046758651733, 229.2418670654297, 115.7853012084961]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[33 / 1000]\n",
      "- TRAIN MAE LOSS : 17.73421044836511\n",
      "- TRAIN MAPE LOSS : 161.15503527452063\n",
      "- TRAIN MSE LOSS : 929.9000768274694\n",
      "- TRAIN R2 SCORE : 0.8389724977366574\n",
      "\n",
      "- TEST MAE LOSS : 17.78031349182129\n",
      "- TEST MAPE LOSS : 22878.212890625\n",
      "- TEST MSE LOSS : 964.530029296875\n",
      "- TEST R2 SCORE : 0.8383575677871704\n",
      "pre_val : [51.96579360961914, 68.25147247314453, 274.3197326660156, 170.10081481933594, 0.0015931961825117469, 67.68061828613281, 205.0354766845703, 5.109556674957275, 240.28347778320312, 113.9810562133789]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[34 / 1000]\n",
      "- TRAIN MAE LOSS : 17.241823866784156\n",
      "- TRAIN MAPE LOSS : 204.40812084401196\n",
      "- TRAIN MSE LOSS : 895.536948408647\n",
      "- TRAIN R2 SCORE : 0.8447197152851345\n",
      "\n",
      "- TEST MAE LOSS : 16.536270141601562\n",
      "- TEST MAPE LOSS : 27363.0\n",
      "- TEST MSE LOSS : 881.44873046875\n",
      "- TEST R2 SCORE : 0.8522809147834778\n",
      "pre_val : [37.182125091552734, 65.59793090820312, 251.40968322753906, 137.0871124267578, -0.00017418341303709894, 57.74127197265625, 195.9276885986328, 0.18433286249637604, 238.1531219482422, 113.91883087158203]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[35 / 1000]\n",
      "- TRAIN MAE LOSS : 16.544692557008116\n",
      "- TRAIN MAPE LOSS : 212.50878934829177\n",
      "- TRAIN MSE LOSS : 851.1399279230291\n",
      "- TRAIN R2 SCORE : 0.8525087058127343\n",
      "\n",
      "- TEST MAE LOSS : 16.509510040283203\n",
      "- TEST MAPE LOSS : 23120.2421875\n",
      "- TEST MSE LOSS : 895.0332641601562\n",
      "- TEST R2 SCORE : 0.8500043153762817\n",
      "pre_val : [33.26165771484375, 75.53096771240234, 255.35740661621094, 135.04299926757812, -0.0011945314472541213, 63.05975341796875, 194.87045288085938, 0.7501317858695984, 236.1345977783203, 109.97863006591797]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[36 / 1000]\n",
      "- TRAIN MAE LOSS : 16.182362170986362\n",
      "- TRAIN MAPE LOSS : 272.2968000527091\n",
      "- TRAIN MSE LOSS : 830.7026780220511\n",
      "- TRAIN R2 SCORE : 0.8560154490204124\n",
      "\n",
      "- TEST MAE LOSS : 15.66557788848877\n",
      "- TEST MAPE LOSS : 26505.564453125\n",
      "- TEST MSE LOSS : 834.1220703125\n",
      "- TEST R2 SCORE : 0.8602122068405151\n",
      "pre_val : [41.47891616821289, 76.64784240722656, 265.5386962890625, 182.55801391601562, -0.0015218353364616632, 69.86688232421875, 204.87271118164062, 27.25857162475586, 233.81210327148438, 107.68668365478516]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[37 / 1000]\n",
      "- TRAIN MAE LOSS : 15.690156838477074\n",
      "- TRAIN MAPE LOSS : 142.90503759092698\n",
      "- TRAIN MSE LOSS : 795.0823095852512\n",
      "- TRAIN R2 SCORE : 0.8621895302259005\n",
      "\n",
      "- TEST MAE LOSS : 15.242456436157227\n",
      "- TEST MAPE LOSS : 26253.033203125\n",
      "- TEST MSE LOSS : 807.3728637695312\n",
      "- TEST R2 SCORE : 0.8646950125694275\n",
      "pre_val : [45.00082015991211, 76.62689971923828, 260.84967041015625, 176.63255310058594, -0.0012311815517023206, 68.86332702636719, 202.0569305419922, 8.64071273803711, 233.1062469482422, 107.74357604980469]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[38 / 1000]\n",
      "- TRAIN MAE LOSS : 15.416420010119886\n",
      "- TRAIN MAPE LOSS : 399.8191436528138\n",
      "- TRAIN MSE LOSS : 777.6862324748006\n",
      "- TRAIN R2 SCORE : 0.8651191833469417\n",
      "\n",
      "- TEST MAE LOSS : 14.858583450317383\n",
      "- TEST MAPE LOSS : 26111.2109375\n",
      "- TEST MSE LOSS : 785.8279418945312\n",
      "- TEST R2 SCORE : 0.8683056831359863\n",
      "pre_val : [31.063432693481445, 76.38102722167969, 261.78778076171875, 135.83505249023438, -0.0007020150660537183, 67.40511322021484, 199.36520385742188, 1.3598670959472656, 236.52276611328125, 105.94046783447266]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[39 / 1000]\n",
      "- TRAIN MAE LOSS : 14.96698527382804\n",
      "- TRAIN MAPE LOSS : 157.72354888808164\n",
      "- TRAIN MSE LOSS : 747.0020302192314\n",
      "- TRAIN R2 SCORE : 0.8703980547231394\n",
      "\n",
      "- TEST MAE LOSS : 14.768943786621094\n",
      "- TEST MAPE LOSS : 25356.06640625\n",
      "- TEST MSE LOSS : 780.2318115234375\n",
      "- TEST R2 SCORE : 0.8692435026168823\n",
      "pre_val : [35.63356399536133, 74.28614807128906, 255.76824951171875, 129.58668518066406, -0.002178966999053955, 69.04808807373047, 199.01287841796875, 10.306822776794434, 230.55474853515625, 106.29690551757812]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[40 / 1000]\n",
      "- TRAIN MAE LOSS : 14.608205904127\n",
      "- TRAIN MAPE LOSS : 103.31886662158932\n",
      "- TRAIN MSE LOSS : 724.8334256984471\n",
      "- TRAIN R2 SCORE : 0.8742941704996816\n",
      "\n",
      "- TEST MAE LOSS : 14.347394943237305\n",
      "- TEST MAPE LOSS : 26594.54296875\n",
      "- TEST MSE LOSS : 752.6383056640625\n",
      "- TEST R2 SCORE : 0.8738678097724915\n",
      "pre_val : [41.01742935180664, 73.27349090576172, 257.5655517578125, 154.16676330566406, -0.0007183297420851886, 67.43274688720703, 199.54092407226562, 4.660794734954834, 232.25218200683594, 106.32535552978516]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[41 / 1000]\n",
      "- TRAIN MAE LOSS : 14.25256507460054\n",
      "- TRAIN MAPE LOSS : 125.47872372824828\n",
      "- TRAIN MSE LOSS : 701.1437294870657\n",
      "- TRAIN R2 SCORE : 0.8783643535300568\n",
      "\n",
      "- TEST MAE LOSS : 13.995946884155273\n",
      "- TEST MAPE LOSS : 26408.4921875\n",
      "- TEST MSE LOSS : 737.2970581054688\n",
      "- TEST R2 SCORE : 0.8764387965202332\n",
      "pre_val : [42.145362854003906, 69.28831481933594, 258.94549560546875, 143.83328247070312, -0.0011206995695829391, 64.5071029663086, 191.14218139648438, 0.527044415473938, 232.52682495117188, 107.5847396850586]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[42 / 1000]\n",
      "- TRAIN MAE LOSS : 14.199310366623886\n",
      "- TRAIN MAPE LOSS : 713.1051415708432\n",
      "- TRAIN MSE LOSS : 696.6298336642606\n",
      "- TRAIN R2 SCORE : 0.8790946291543387\n",
      "\n",
      "- TEST MAE LOSS : 14.150545120239258\n",
      "- TEST MAPE LOSS : 23443.306640625\n",
      "- TEST MSE LOSS : 750.926025390625\n",
      "- TEST R2 SCORE : 0.874154806137085\n",
      "pre_val : [30.151626586914062, 76.27458190917969, 263.8717956542969, 169.9107666015625, -0.0007799692684784532, 64.53148651123047, 190.768798828125, 0.9798067808151245, 236.13156127929688, 109.38653564453125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[43 / 1000]\n",
      "- TRAIN MAE LOSS : 13.86461887346281\n",
      "- TRAIN MAPE LOSS : 141.32852898813837\n",
      "- TRAIN MSE LOSS : 675.674601713594\n",
      "- TRAIN R2 SCORE : 0.8826379654457519\n",
      "\n",
      "- TEST MAE LOSS : 13.739326477050781\n",
      "- TEST MAPE LOSS : 25873.576171875\n",
      "- TEST MSE LOSS : 721.0454711914062\n",
      "- TEST R2 SCORE : 0.8791623711585999\n",
      "pre_val : [43.68686294555664, 66.96124267578125, 267.06817626953125, 197.79139709472656, -0.0010677737882360816, 68.09160614013672, 197.8157958984375, 16.85189437866211, 227.8040771484375, 108.89497375488281]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[44 / 1000]\n",
      "- TRAIN MAE LOSS : 13.536762875643644\n",
      "- TRAIN MAPE LOSS : 151.75790785074963\n",
      "- TRAIN MSE LOSS : 656.4953277289117\n",
      "- TRAIN R2 SCORE : 0.88598988399639\n",
      "\n",
      "- TEST MAE LOSS : 13.328471183776855\n",
      "- TEST MAPE LOSS : 25885.263671875\n",
      "- TEST MSE LOSS : 698.7037963867188\n",
      "- TEST R2 SCORE : 0.8829065561294556\n",
      "pre_val : [40.69869613647461, 66.60496520996094, 263.6587219238281, 192.54217529296875, -0.0015001448336988688, 57.27347946166992, 197.43797302246094, 10.817991256713867, 231.99734497070312, 106.3294448852539]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[45 / 1000]\n",
      "- TRAIN MAE LOSS : 13.25625778558371\n",
      "- TRAIN MAPE LOSS : 75.43680925426992\n",
      "- TRAIN MSE LOSS : 639.756754843972\n",
      "- TRAIN R2 SCORE : 0.8889441354458149\n",
      "\n",
      "- TEST MAE LOSS : 13.189351081848145\n",
      "- TEST MAPE LOSS : 25465.978515625\n",
      "- TEST MSE LOSS : 689.6549682617188\n",
      "- TEST R2 SCORE : 0.884423017501831\n",
      "pre_val : [45.91735076904297, 61.654449462890625, 267.0716552734375, 224.01976013183594, -0.0010933117009699345, 63.94598388671875, 200.17428588867188, 23.30371856689453, 226.5973663330078, 107.82440948486328]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[46 / 1000]\n",
      "- TRAIN MAE LOSS : 13.063409561077197\n",
      "- TRAIN MAPE LOSS : 179.05324604486773\n",
      "- TRAIN MSE LOSS : 624.0437202080146\n",
      "- TRAIN R2 SCORE : 0.8915735269593192\n",
      "\n",
      "- TEST MAE LOSS : 12.833977699279785\n",
      "- TEST MAPE LOSS : 27494.076171875\n",
      "- TEST MSE LOSS : 670.4573364257812\n",
      "- TEST R2 SCORE : 0.8876402378082275\n",
      "pre_val : [45.39955520629883, 64.08831787109375, 263.02667236328125, 213.48873901367188, -0.0012257605558261275, 57.87879180908203, 198.10289001464844, 25.04824447631836, 226.99114990234375, 110.79964447021484]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[47 / 1000]\n",
      "- TRAIN MAE LOSS : 12.873756769220313\n",
      "- TRAIN MAPE LOSS : 56.699528202187345\n",
      "- TRAIN MSE LOSS : 612.8840751850688\n",
      "- TRAIN R2 SCORE : 0.8934688870890157\n",
      "\n",
      "- TEST MAE LOSS : 12.805354118347168\n",
      "- TEST MAPE LOSS : 25297.94140625\n",
      "- TEST MSE LOSS : 670.9584350585938\n",
      "- TEST R2 SCORE : 0.887556254863739\n",
      "pre_val : [48.13701248168945, 61.76295852661133, 260.5382080078125, 201.4912567138672, 0.0007546917768195271, 63.5074462890625, 199.73980712890625, 24.912376403808594, 228.5225067138672, 110.49898529052734]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[48 / 1000]\n",
      "- TRAIN MAE LOSS : 12.613813732253922\n",
      "- TRAIN MAPE LOSS : 62.82625100864293\n",
      "- TRAIN MSE LOSS : 596.9528674167019\n",
      "- TRAIN R2 SCORE : 0.8962299307242974\n",
      "\n",
      "- TEST MAE LOSS : 12.734302520751953\n",
      "- TEST MAPE LOSS : 23705.228515625\n",
      "- TEST MSE LOSS : 665.6675415039062\n",
      "- TEST R2 SCORE : 0.8884429931640625\n",
      "pre_val : [49.10896301269531, 54.853759765625, 266.3968200683594, 221.83950805664062, -0.000981904217042029, 61.478981018066406, 200.30606079101562, 27.0795955657959, 226.60108947753906, 109.83171081542969]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[49 / 1000]\n",
      "- TRAIN MAE LOSS : 12.401533939388248\n",
      "- TRAIN MAPE LOSS : 90.67586384573913\n",
      "- TRAIN MSE LOSS : 582.7248319324414\n",
      "- TRAIN R2 SCORE : 0.8987350674942657\n",
      "\n",
      "- TEST MAE LOSS : 12.411201477050781\n",
      "- TEST MAPE LOSS : 25897.228515625\n",
      "- TEST MSE LOSS : 649.6492309570312\n",
      "- TEST R2 SCORE : 0.8911274075508118\n",
      "pre_val : [48.359107971191406, 58.53981018066406, 263.03875732421875, 215.2338104248047, -0.001076944055967033, 62.59890365600586, 201.7529296875, 25.064889907836914, 231.36270141601562, 112.18970489501953]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[50 / 1000]\n",
      "- TRAIN MAE LOSS : 12.283918157324091\n",
      "- TRAIN MAPE LOSS : 412.60134444966286\n",
      "- TRAIN MSE LOSS : 575.0267275936953\n",
      "- TRAIN R2 SCORE : 0.8999593972159432\n",
      "\n",
      "- TEST MAE LOSS : 12.352084159851074\n",
      "- TEST MAPE LOSS : 24610.4765625\n",
      "- TEST MSE LOSS : 647.9732055664062\n",
      "- TEST R2 SCORE : 0.8914083242416382\n",
      "pre_val : [46.56899642944336, 57.1134033203125, 255.72552490234375, 195.84762573242188, -0.0009644280653446913, 60.127357482910156, 198.16656494140625, 17.944293975830078, 237.15199279785156, 110.30558776855469]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[51 / 1000]\n",
      "- TRAIN MAE LOSS : 12.255236667419647\n",
      "- TRAIN MAPE LOSS : 120.61548132839424\n",
      "- TRAIN MSE LOSS : 568.6740302836812\n",
      "- TRAIN R2 SCORE : 0.9010637011227908\n",
      "\n",
      "- TEST MAE LOSS : 12.422697067260742\n",
      "- TEST MAPE LOSS : 23709.423828125\n",
      "- TEST MSE LOSS : 651.0862426757812\n",
      "- TEST R2 SCORE : 0.8908866047859192\n",
      "pre_val : [55.29111862182617, 57.72244644165039, 262.513671875, 210.94729614257812, -0.0007104638498276472, 66.0628890991211, 204.81121826171875, 29.58110237121582, 230.57891845703125, 109.71426391601562]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[52 / 1000]\n",
      "- TRAIN MAE LOSS : 11.937525995961437\n",
      "- TRAIN MAPE LOSS : 159.98344652465903\n",
      "- TRAIN MSE LOSS : 555.3088972121019\n",
      "- TRAIN R2 SCORE : 0.9033942760120739\n",
      "\n",
      "- TEST MAE LOSS : 12.032736778259277\n",
      "- TEST MAPE LOSS : 25870.462890625\n",
      "- TEST MSE LOSS : 630.173828125\n",
      "- TEST R2 SCORE : 0.8943912386894226\n",
      "pre_val : [53.31184768676758, 51.857242584228516, 264.5034484863281, 220.0975341796875, 0.0009599291952326894, 71.47069549560547, 207.60171508789062, 31.900415420532227, 229.26751708984375, 110.81685638427734]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[53 / 1000]\n",
      "- TRAIN MAE LOSS : 11.848136940669347\n",
      "- TRAIN MAPE LOSS : 114.70576377901997\n",
      "- TRAIN MSE LOSS : 547.4259118257536\n",
      "- TRAIN R2 SCORE : 0.9047106122637129\n",
      "\n",
      "- TEST MAE LOSS : 11.98433780670166\n",
      "- TEST MAPE LOSS : 23642.306640625\n",
      "- TEST MSE LOSS : 628.1202392578125\n",
      "- TEST R2 SCORE : 0.8947353959083557\n",
      "pre_val : [56.080322265625, 55.69498062133789, 268.94244384765625, 219.70809936523438, -0.0010806702775880694, 65.81851196289062, 205.40420532226562, 32.23365783691406, 225.5638885498047, 111.19342803955078]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[54 / 1000]\n",
      "- TRAIN MAE LOSS : 11.597765362079327\n",
      "- TRAIN MAPE LOSS : 50.89475814140135\n",
      "- TRAIN MSE LOSS : 534.3812556350815\n",
      "- TRAIN R2 SCORE : 0.9069654830685863\n",
      "\n",
      "- TEST MAE LOSS : 11.841397285461426\n",
      "- TEST MAPE LOSS : 22218.904296875\n",
      "- TEST MSE LOSS : 625.9981079101562\n",
      "- TEST R2 SCORE : 0.8950910568237305\n",
      "pre_val : [64.19378662109375, 51.576560974121094, 267.2093505859375, 228.174560546875, -0.0006151701672933996, 64.09369659423828, 207.47567749023438, 31.053377151489258, 229.81927490234375, 109.06639099121094]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[55 / 1000]\n",
      "- TRAIN MAE LOSS : 11.415090209987614\n",
      "- TRAIN MAPE LOSS : 36.7822113669648\n",
      "- TRAIN MSE LOSS : 523.1517333536215\n",
      "- TRAIN R2 SCORE : 0.9088878908690873\n",
      "\n",
      "- TEST MAE LOSS : 11.687928199768066\n",
      "- TEST MAPE LOSS : 22856.49609375\n",
      "- TEST MSE LOSS : 614.1165161132812\n",
      "- TEST R2 SCORE : 0.8970822095870972\n",
      "pre_val : [53.75680160522461, 49.96556091308594, 265.2283020019531, 228.56788635253906, 0.0012984891654923558, 65.99594116210938, 206.82159423828125, 33.96424102783203, 228.29933166503906, 108.81981658935547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[56 / 1000]\n",
      "- TRAIN MAE LOSS : 11.3869919084669\n",
      "- TRAIN MAPE LOSS : 210.38065147991884\n",
      "- TRAIN MSE LOSS : 518.970162360985\n",
      "- TRAIN R2 SCORE : 0.9096039562458759\n",
      "\n",
      "- TEST MAE LOSS : 11.635348320007324\n",
      "- TEST MAPE LOSS : 22482.193359375\n",
      "- TEST MSE LOSS : 608.3464965820312\n",
      "- TEST R2 SCORE : 0.8980492353439331\n",
      "pre_val : [64.56494140625, 57.45022201538086, 266.7918395996094, 210.77064514160156, -0.0013428735546767712, 69.1819076538086, 212.06712341308594, 35.36491012573242, 228.57032775878906, 110.9185562133789]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[57 / 1000]\n",
      "- TRAIN MAE LOSS : 11.217505201059621\n",
      "- TRAIN MAPE LOSS : 78.59601169309103\n",
      "- TRAIN MSE LOSS : 507.40542964695214\n",
      "- TRAIN R2 SCORE : 0.9115902658942696\n",
      "\n",
      "- TEST MAE LOSS : 11.95639419555664\n",
      "- TEST MAPE LOSS : 20431.087890625\n",
      "- TEST MSE LOSS : 623.712890625\n",
      "- TEST R2 SCORE : 0.8954740166664124\n",
      "pre_val : [61.200523376464844, 46.3885383605957, 264.7317810058594, 214.72657775878906, -0.0010164732811972499, 67.28091430664062, 212.4534149169922, 34.77666473388672, 227.67312622070312, 109.44438934326172]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[58 / 1000]\n",
      "- TRAIN MAE LOSS : 11.136981382436685\n",
      "- TRAIN MAPE LOSS : 94.14176061206452\n",
      "- TRAIN MSE LOSS : 501.103816699048\n",
      "- TRAIN R2 SCORE : 0.9126796221566367\n",
      "\n",
      "- TEST MAE LOSS : 11.52115249633789\n",
      "- TEST MAPE LOSS : 22627.388671875\n",
      "- TEST MSE LOSS : 605.384033203125\n",
      "- TEST R2 SCORE : 0.8985456824302673\n",
      "pre_val : [60.17723846435547, 49.26195526123047, 258.6747131347656, 232.01925659179688, -0.0012865441385656595, 68.40705108642578, 207.054443359375, 38.166770935058594, 227.77955627441406, 109.98045349121094]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[59 / 1000]\n",
      "- TRAIN MAE LOSS : 10.827465114860267\n",
      "- TRAIN MAPE LOSS : 37.17765005795897\n",
      "- TRAIN MSE LOSS : 488.9122301915309\n",
      "- TRAIN R2 SCORE : 0.9147835046594793\n",
      "\n",
      "- TEST MAE LOSS : 11.337858200073242\n",
      "- TEST MAPE LOSS : 22122.599609375\n",
      "- TEST MSE LOSS : 597.6094970703125\n",
      "- TEST R2 SCORE : 0.8998485803604126\n",
      "pre_val : [68.7966537475586, 50.40653991699219, 264.74908447265625, 228.18263244628906, 0.001247365609742701, 66.78849792480469, 212.07809448242188, 37.55405044555664, 226.85154724121094, 108.59410858154297]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[60 / 1000]\n",
      "- TRAIN MAE LOSS : 10.715806570386553\n",
      "- TRAIN MAPE LOSS : 193.66954360432246\n",
      "- TRAIN MSE LOSS : 479.21637246085214\n",
      "- TRAIN R2 SCORE : 0.9164483736111567\n",
      "\n",
      "- TEST MAE LOSS : 11.123507499694824\n",
      "- TEST MAPE LOSS : 23006.60546875\n",
      "- TEST MSE LOSS : 590.6194458007812\n",
      "- TEST R2 SCORE : 0.9010200500488281\n",
      "pre_val : [60.854862213134766, 50.159393310546875, 256.3894958496094, 233.90968322753906, 0.00129987602122128, 67.98507690429688, 214.24850463867188, 36.314964294433594, 226.1584930419922, 106.77899169921875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[61 / 1000]\n",
      "- TRAIN MAE LOSS : 10.653064918651447\n",
      "- TRAIN MAPE LOSS : 123.2236384967032\n",
      "- TRAIN MSE LOSS : 474.8832021646566\n",
      "- TRAIN R2 SCORE : 0.917162936767498\n",
      "\n",
      "- TEST MAE LOSS : 11.172584533691406\n",
      "- TEST MAPE LOSS : 22302.216796875\n",
      "- TEST MSE LOSS : 590.6425170898438\n",
      "- TEST R2 SCORE : 0.9010161757469177\n",
      "pre_val : [74.2307357788086, 48.52366256713867, 259.1127624511719, 235.9687042236328, 0.0007942182710394263, 66.78491973876953, 218.316162109375, 38.18901443481445, 230.16073608398438, 107.9202651977539]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[62 / 1000]\n",
      "- TRAIN MAE LOSS : 10.555845614346591\n",
      "- TRAIN MAPE LOSS : 197.32817303471424\n",
      "- TRAIN MSE LOSS : 467.44761839539854\n",
      "- TRAIN R2 SCORE : 0.9184426306511139\n",
      "\n",
      "- TEST MAE LOSS : 11.004093170166016\n",
      "- TEST MAPE LOSS : 22607.873046875\n",
      "- TEST MSE LOSS : 579.5286254882812\n",
      "- TEST R2 SCORE : 0.9028787016868591\n",
      "pre_val : [61.44715118408203, 48.33308792114258, 266.70343017578125, 223.4751739501953, 0.0005615967675112188, 64.16705322265625, 215.87594604492188, 38.87603759765625, 227.5692596435547, 109.99805450439453]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[63 / 1000]\n",
      "- TRAIN MAE LOSS : 10.420867553524204\n",
      "- TRAIN MAPE LOSS : 89.34994072902869\n",
      "- TRAIN MSE LOSS : 460.7622667037857\n",
      "- TRAIN R2 SCORE : 0.9195671637575109\n",
      "\n",
      "- TEST MAE LOSS : 11.191984176635742\n",
      "- TEST MAPE LOSS : 21597.87890625\n",
      "- TEST MSE LOSS : 591.3616943359375\n",
      "- TEST R2 SCORE : 0.9008956551551819\n",
      "pre_val : [62.414920806884766, 50.74962615966797, 259.7765197753906, 238.90895080566406, -0.0004727256309706718, 65.50067901611328, 216.69366455078125, 39.708526611328125, 229.13059997558594, 106.11786651611328]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[64 / 1000]\n",
      "- TRAIN MAE LOSS : 10.275654026111523\n",
      "- TRAIN MAPE LOSS : 216.66050012741786\n",
      "- TRAIN MSE LOSS : 452.2459802982357\n",
      "- TRAIN R2 SCORE : 0.9210512121740755\n",
      "\n",
      "- TEST MAE LOSS : 10.971796035766602\n",
      "- TEST MAPE LOSS : 22774.251953125\n",
      "- TEST MSE LOSS : 578.7928466796875\n",
      "- TEST R2 SCORE : 0.9030020236968994\n",
      "pre_val : [70.92536163330078, 49.79885482788086, 259.8904724121094, 235.15823364257812, -0.0012454165844246745, 61.434593200683594, 221.9266815185547, 40.88462829589844, 227.52099609375, 109.88068389892578]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[65 / 1000]\n",
      "- TRAIN MAE LOSS : 10.257791722304338\n",
      "- TRAIN MAPE LOSS : 375.98537363642686\n",
      "- TRAIN MSE LOSS : 449.3627274071753\n",
      "- TRAIN R2 SCORE : 0.9215221467384925\n",
      "\n",
      "- TEST MAE LOSS : 10.818525314331055\n",
      "- TEST MAPE LOSS : 22939.158203125\n",
      "- TEST MSE LOSS : 573.9175415039062\n",
      "- TEST R2 SCORE : 0.9038190245628357\n",
      "pre_val : [63.18795394897461, 50.775413513183594, 265.9254455566406, 212.70135498046875, 0.0013539014616981149, 57.56352233886719, 222.25558471679688, 39.542930603027344, 230.45828247070312, 112.33992767333984]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[66 / 1000]\n",
      "- TRAIN MAE LOSS : 10.054032547957414\n",
      "- TRAIN MAPE LOSS : 72.13687221922137\n",
      "- TRAIN MSE LOSS : 442.22757086053593\n",
      "- TRAIN R2 SCORE : 0.9227817695124166\n",
      "\n",
      "- TEST MAE LOSS : 11.070161819458008\n",
      "- TEST MAPE LOSS : 20886.216796875\n",
      "- TEST MSE LOSS : 585.4857177734375\n",
      "- TEST R2 SCORE : 0.9018803834915161\n",
      "pre_val : [57.135459899902344, 50.225830078125, 258.7100524902344, 199.88966369628906, -0.0009214152814820409, 59.83708572387695, 218.56272888183594, 39.3260383605957, 226.25714111328125, 111.3864517211914]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[67 / 1000]\n",
      "- TRAIN MAE LOSS : 10.106097105733165\n",
      "- TRAIN MAPE LOSS : 193.6663466931619\n",
      "- TRAIN MSE LOSS : 438.8514228180572\n",
      "- TRAIN R2 SCORE : 0.9233357428337311\n",
      "\n",
      "- TEST MAE LOSS : 11.075920104980469\n",
      "- TEST MAPE LOSS : 20709.755859375\n",
      "- TEST MSE LOSS : 587.4736938476562\n",
      "- TEST R2 SCORE : 0.9015471935272217\n",
      "pre_val : [58.10786437988281, 47.65149688720703, 255.46737670898438, 243.7566680908203, 0.0009904919425025582, 63.13019943237305, 222.83363342285156, 40.18600082397461, 227.1254119873047, 110.11649322509766]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[68 / 1000]\n",
      "- TRAIN MAE LOSS : 10.008562818273798\n",
      "- TRAIN MAPE LOSS : 204.96265592710748\n",
      "- TRAIN MSE LOSS : 433.09605198786807\n",
      "- TRAIN R2 SCORE : 0.9243253249555201\n",
      "\n",
      "- TEST MAE LOSS : 10.72707462310791\n",
      "- TEST MAPE LOSS : 22585.4453125\n",
      "- TEST MSE LOSS : 567.6299438476562\n",
      "- TEST R2 SCORE : 0.9048727750778198\n",
      "pre_val : [66.95306396484375, 47.425628662109375, 255.89129638671875, 236.6097412109375, -0.0009358537499792874, 62.1961669921875, 225.7950439453125, 42.000816345214844, 226.24522399902344, 110.30572509765625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[69 / 1000]\n",
      "- TRAIN MAE LOSS : 9.88735112637073\n",
      "- TRAIN MAPE LOSS : 32.11574615794253\n",
      "- TRAIN MSE LOSS : 429.42166787100837\n",
      "- TRAIN R2 SCORE : 0.9249495725865131\n",
      "\n",
      "- TEST MAE LOSS : 10.535054206848145\n",
      "- TEST MAPE LOSS : 22425.814453125\n",
      "- TEST MSE LOSS : 561.8999633789062\n",
      "- TEST R2 SCORE : 0.9058330059051514\n",
      "pre_val : [61.246280670166016, 47.74427795410156, 250.43287658691406, 241.94874572753906, 0.001041328883729875, 59.85213088989258, 224.53060913085938, 39.77701950073242, 228.245361328125, 111.75506591796875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[70 / 1000]\n",
      "- TRAIN MAE LOSS : 9.764551989948833\n",
      "- TRAIN MAPE LOSS : 53.96760137569863\n",
      "- TRAIN MSE LOSS : 422.2091319755074\n",
      "- TRAIN R2 SCORE : 0.9262177002346599\n",
      "\n",
      "- TEST MAE LOSS : 10.594152450561523\n",
      "- TEST MAPE LOSS : 22499.64453125\n",
      "- TEST MSE LOSS : 565.9873657226562\n",
      "- TEST R2 SCORE : 0.9051480293273926\n",
      "pre_val : [63.39455032348633, 45.98955535888672, 250.4921875, 247.74375915527344, 0.0012583605712279677, 62.2308464050293, 225.35589599609375, 40.48372268676758, 226.55044555664062, 107.74464416503906]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[71 / 1000]\n",
      "- TRAIN MAE LOSS : 9.690748667950396\n",
      "- TRAIN MAPE LOSS : 29.137394943590557\n",
      "- TRAIN MSE LOSS : 418.4598255493591\n",
      "- TRAIN R2 SCORE : 0.9268577825773012\n",
      "\n",
      "- TEST MAE LOSS : 10.380693435668945\n",
      "- TEST MAPE LOSS : 22624.466796875\n",
      "- TEST MSE LOSS : 553.9596557617188\n",
      "- TEST R2 SCORE : 0.9071637392044067\n",
      "pre_val : [60.34539031982422, 44.25463104248047, 255.7089080810547, 228.1576690673828, 0.0007469827542081475, 63.45134353637695, 224.61590576171875, 41.28898620605469, 227.35647583007812, 110.6046142578125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[72 / 1000]\n",
      "- TRAIN MAE LOSS : 9.669373220163626\n",
      "- TRAIN MAPE LOSS : 309.746641261959\n",
      "- TRAIN MSE LOSS : 414.84986188501745\n",
      "- TRAIN R2 SCORE : 0.9274893065432569\n",
      "\n",
      "- TEST MAE LOSS : 10.508085250854492\n",
      "- TEST MAPE LOSS : 23123.16015625\n",
      "- TEST MSE LOSS : 558.177734375\n",
      "- TEST R2 SCORE : 0.9064568281173706\n",
      "pre_val : [58.86238479614258, 44.59349822998047, 251.16868591308594, 241.44378662109375, 0.0008601665031164885, 66.6295394897461, 227.5565948486328, 41.554927825927734, 227.4881591796875, 112.2122802734375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[73 / 1000]\n",
      "- TRAIN MAE LOSS : 9.55479946056446\n",
      "- TRAIN MAPE LOSS : 22.28697825307925\n",
      "- TRAIN MSE LOSS : 408.3046915659871\n",
      "- TRAIN R2 SCORE : 0.9286067396610767\n",
      "\n",
      "- TEST MAE LOSS : 10.47241497039795\n",
      "- TEST MAPE LOSS : 22346.921875\n",
      "- TEST MSE LOSS : 558.5422973632812\n",
      "- TEST R2 SCORE : 0.9063957333564758\n",
      "pre_val : [64.49996948242188, 45.87617492675781, 247.79151916503906, 245.0558624267578, 0.0013121151132509112, 63.717201232910156, 233.73045349121094, 40.43870162963867, 227.15716552734375, 109.7939453125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[74 / 1000]\n",
      "- TRAIN MAE LOSS : 9.466678623519577\n",
      "- TRAIN MAPE LOSS : 22.554243264900638\n",
      "- TRAIN MSE LOSS : 404.6079694169051\n",
      "- TRAIN R2 SCORE : 0.9292374649748102\n",
      "\n",
      "- TEST MAE LOSS : 10.279803276062012\n",
      "- TEST MAPE LOSS : 21986.3203125\n",
      "- TEST MSE LOSS : 551.4838256835938\n",
      "- TEST R2 SCORE : 0.9075786471366882\n",
      "pre_val : [56.67466735839844, 43.58977127075195, 248.4960479736328, 248.56951904296875, 0.0009439251734875143, 68.2879638671875, 230.89068603515625, 42.676719665527344, 227.89846801757812, 110.05814361572266]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[75 / 1000]\n",
      "- TRAIN MAE LOSS : 9.416476195942272\n",
      "- TRAIN MAPE LOSS : 67.66210805537297\n",
      "- TRAIN MSE LOSS : 399.0707438243519\n",
      "- TRAIN R2 SCORE : 0.9302280298479787\n",
      "\n",
      "- TEST MAE LOSS : 10.319534301757812\n",
      "- TEST MAPE LOSS : 21961.9609375\n",
      "- TEST MSE LOSS : 550.983642578125\n",
      "- TEST R2 SCORE : 0.9076624512672424\n",
      "성능 및 손실 개선이 없어서 75 EPOCH에 학습 중단\n",
      "pre_val : [55.680381774902344, 44.93867111206055, 248.39395141601562, 247.71884155273438, -0.0015517324209213257, 68.83293151855469, 230.16311645507812, 44.3463249206543, 228.583251953125, 111.37617492675781]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[76 / 1000]\n",
      "- TRAIN MAE LOSS : 9.336470585269527\n",
      "- TRAIN MAPE LOSS : 18.54782571289506\n",
      "- TRAIN MSE LOSS : 395.1277960269101\n",
      "- TRAIN R2 SCORE : 0.9308740365755308\n",
      "\n",
      "- TEST MAE LOSS : 10.233144760131836\n",
      "- TEST MAPE LOSS : 22169.806640625\n",
      "- TEST MSE LOSS : 546.3367309570312\n",
      "- TEST R2 SCORE : 0.9084412455558777\n",
      "성능 및 손실 개선이 없어서 76 EPOCH에 학습 중단\n",
      "pre_val : [63.65150833129883, 44.93635940551758, 253.47674560546875, 247.61695861816406, -0.0006217688205651939, 66.0294418334961, 230.79847717285156, 45.65525436401367, 228.7393341064453, 112.02587127685547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[77 / 1000]\n",
      "- TRAIN MAE LOSS : 9.282428905246976\n",
      "- TRAIN MAPE LOSS : 41.12418749833441\n",
      "- TRAIN MSE LOSS : 391.84778976547136\n",
      "- TRAIN R2 SCORE : 0.931432389529435\n",
      "\n",
      "- TEST MAE LOSS : 10.107327461242676\n",
      "- TEST MAPE LOSS : 22125.267578125\n",
      "- TEST MSE LOSS : 542.4268188476562\n",
      "- TEST R2 SCORE : 0.9090964794158936\n",
      "성능 및 손실 개선이 없어서 77 EPOCH에 학습 중단\n",
      "pre_val : [56.174049377441406, 46.816627502441406, 252.5293426513672, 252.2889862060547, -0.0015212992439046502, 65.656005859375, 228.80740356445312, 44.02726745605469, 227.51695251464844, 112.00505828857422]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[78 / 1000]\n",
      "- TRAIN MAE LOSS : 9.244968700142174\n",
      "- TRAIN MAPE LOSS : 76.34835133418702\n",
      "- TRAIN MSE LOSS : 387.77687950294336\n",
      "- TRAIN R2 SCORE : 0.9321345617887857\n",
      "\n",
      "- TEST MAE LOSS : 10.250746726989746\n",
      "- TEST MAPE LOSS : 20697.693359375\n",
      "- TEST MSE LOSS : 548.2149658203125\n",
      "- TEST R2 SCORE : 0.9081264734268188\n",
      "성능 및 손실 개선이 없어서 78 EPOCH에 학습 중단\n",
      "pre_val : [66.04025268554688, 47.83815002441406, 256.0685729980469, 253.50132751464844, 0.0012454906245693564, 65.22869110107422, 232.56658935546875, 47.5642204284668, 230.39305114746094, 110.49266052246094]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[79 / 1000]\n",
      "- TRAIN MAE LOSS : 9.190530664670717\n",
      "- TRAIN MAPE LOSS : 24.497687188125365\n",
      "- TRAIN MSE LOSS : 383.4669520728905\n",
      "- TRAIN R2 SCORE : 0.9328791773569334\n",
      "\n",
      "- TEST MAE LOSS : 10.113092422485352\n",
      "- TEST MAPE LOSS : 21581.87890625\n",
      "- TEST MSE LOSS : 543.335693359375\n",
      "- TEST R2 SCORE : 0.9089441299438477\n",
      "성능 및 손실 개선이 없어서 79 EPOCH에 학습 중단\n",
      "pre_val : [56.663204193115234, 44.64348602294922, 256.0330810546875, 246.21705627441406, 0.000984757556580007, 68.74124908447266, 229.50875854492188, 47.00566864013672, 229.929931640625, 112.19563293457031]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[80 / 1000]\n",
      "- TRAIN MAE LOSS : 9.093290623751553\n",
      "- TRAIN MAPE LOSS : 69.02222574838913\n",
      "- TRAIN MSE LOSS : 378.7879646482668\n",
      "- TRAIN R2 SCORE : 0.9336983484654994\n",
      "\n",
      "- TEST MAE LOSS : 10.13090705871582\n",
      "- TEST MAPE LOSS : 22002.263671875\n",
      "- TEST MSE LOSS : 542.7125244140625\n",
      "- TEST R2 SCORE : 0.9090485572814941\n",
      "성능 및 손실 개선이 없어서 80 EPOCH에 학습 중단\n",
      "pre_val : [55.96220016479492, 46.886287689208984, 259.1352844238281, 254.15353393554688, 0.0014873981708660722, 71.3624267578125, 230.38746643066406, 49.4779167175293, 232.81295776367188, 110.85888671875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[81 / 1000]\n",
      "- TRAIN MAE LOSS : 9.062773785090947\n",
      "- TRAIN MAPE LOSS : 51.73422234062444\n",
      "- TRAIN MSE LOSS : 375.2942823727481\n",
      "- TRAIN R2 SCORE : 0.9343019105337717\n",
      "\n",
      "- TEST MAE LOSS : 10.022637367248535\n",
      "- TEST MAPE LOSS : 22660.501953125\n",
      "- TEST MSE LOSS : 537.6063232421875\n",
      "- TEST R2 SCORE : 0.9099043607711792\n",
      "성능 및 손실 개선이 없어서 81 EPOCH에 학습 중단\n",
      "pre_val : [64.46895599365234, 46.61451721191406, 257.0882263183594, 257.3175354003906, -0.0006560520851053298, 67.92424011230469, 231.9832000732422, 47.48379135131836, 230.69747924804688, 110.25830078125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[82 / 1000]\n",
      "- TRAIN MAE LOSS : 8.96154613748297\n",
      "- TRAIN MAPE LOSS : 18.947329789897154\n",
      "- TRAIN MSE LOSS : 372.6366408576165\n",
      "- TRAIN R2 SCORE : 0.9347544864007643\n",
      "\n",
      "- TEST MAE LOSS : 9.924049377441406\n",
      "- TEST MAPE LOSS : 21341.875\n",
      "- TEST MSE LOSS : 531.6986083984375\n",
      "- TEST R2 SCORE : 0.9108943939208984\n",
      "성능 및 손실 개선이 없어서 82 EPOCH에 학습 중단\n",
      "pre_val : [56.37047576904297, 46.9459342956543, 259.8794860839844, 246.73558044433594, 0.0011385894613340497, 69.13803100585938, 231.4358367919922, 50.24423599243164, 231.47996520996094, 113.70045471191406]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[83 / 1000]\n",
      "- TRAIN MAE LOSS : 9.043904918457244\n",
      "- TRAIN MAPE LOSS : 316.7491324209724\n",
      "- TRAIN MSE LOSS : 371.74963460535434\n",
      "- TRAIN R2 SCORE : 0.9349027077301398\n",
      "\n",
      "- TEST MAE LOSS : 10.067964553833008\n",
      "- TEST MAPE LOSS : 21540.5546875\n",
      "- TEST MSE LOSS : 541.5679931640625\n",
      "- TEST R2 SCORE : 0.9092403650283813\n",
      "성능 및 손실 개선이 없어서 83 EPOCH에 학습 중단\n",
      "pre_val : [56.87184524536133, 45.86041259765625, 254.9620819091797, 248.1097412109375, 0.0013739954447373748, 68.27063751220703, 230.55300903320312, 50.70459747314453, 231.7142333984375, 113.47541046142578]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[84 / 1000]\n",
      "- TRAIN MAE LOSS : 8.930610467203847\n",
      "- TRAIN MAPE LOSS : 26.426060182609028\n",
      "- TRAIN MSE LOSS : 368.32167327400686\n",
      "- TRAIN R2 SCORE : 0.9355107254581851\n",
      "\n",
      "- TEST MAE LOSS : 10.001516342163086\n",
      "- TEST MAPE LOSS : 21719.958984375\n",
      "- TEST MSE LOSS : 540.2169799804688\n",
      "- TEST R2 SCORE : 0.9094668030738831\n",
      "성능 및 손실 개선이 없어서 84 EPOCH에 학습 중단\n",
      "pre_val : [63.39242172241211, 47.554080963134766, 259.3450622558594, 250.32418823242188, 0.0011816885089501739, 66.89653778076172, 231.37841796875, 48.5984001159668, 231.97828674316406, 112.18254089355469]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[85 / 1000]\n",
      "- TRAIN MAE LOSS : 8.862530754062679\n",
      "- TRAIN MAPE LOSS : 38.96116062293676\n",
      "- TRAIN MSE LOSS : 363.6853607060359\n",
      "- TRAIN R2 SCORE : 0.9363205658805954\n",
      "\n",
      "- TEST MAE LOSS : 9.896868705749512\n",
      "- TEST MAPE LOSS : 21416.388671875\n",
      "- TEST MSE LOSS : 535.3760375976562\n",
      "- TEST R2 SCORE : 0.9102780818939209\n",
      "성능 및 손실 개선이 없어서 85 EPOCH에 학습 중단\n",
      "pre_val : [58.36703872680664, 49.87260818481445, 249.7373809814453, 234.65771484375, 0.0008483933634124696, 65.45751953125, 230.80551147460938, 53.00590133666992, 227.76910400390625, 119.10945129394531]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[86 / 1000]\n",
      "- TRAIN MAE LOSS : 8.825848529722307\n",
      "- TRAIN MAPE LOSS : 107.91887259295353\n",
      "- TRAIN MSE LOSS : 361.057098789882\n",
      "- TRAIN R2 SCORE : 0.9367790702506379\n",
      "\n",
      "- TEST MAE LOSS : 10.232521057128906\n",
      "- TEST MAPE LOSS : 20324.94921875\n",
      "- TEST MSE LOSS : 550.3232421875\n",
      "- TEST R2 SCORE : 0.9077731370925903\n",
      "성능 및 손실 개선이 없어서 86 EPOCH에 학습 중단\n",
      "pre_val : [54.6330451965332, 47.364356994628906, 256.0122985839844, 246.93035888671875, 0.0012475928524509072, 68.35033416748047, 228.19970703125, 48.91387176513672, 229.35293579101562, 115.66419219970703]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[87 / 1000]\n",
      "- TRAIN MAE LOSS : 8.823643329860447\n",
      "- TRAIN MAPE LOSS : 161.63576459999217\n",
      "- TRAIN MSE LOSS : 357.90256533109226\n",
      "- TRAIN R2 SCORE : 0.9372978924037694\n",
      "\n",
      "- TEST MAE LOSS : 9.98688793182373\n",
      "- TEST MAPE LOSS : 21889.78125\n",
      "- TEST MSE LOSS : 537.6443481445312\n",
      "- TEST R2 SCORE : 0.9098979234695435\n",
      "성능 및 손실 개선이 없어서 87 EPOCH에 학습 중단\n",
      "pre_val : [63.2349853515625, 44.8165168762207, 254.36488342285156, 246.8787841796875, 0.0009725530981086195, 64.80304718017578, 229.76451110839844, 48.0393180847168, 229.56527709960938, 116.40760803222656]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[88 / 1000]\n",
      "- TRAIN MAE LOSS : 8.745268824784072\n",
      "- TRAIN MAPE LOSS : 29.957135272967022\n",
      "- TRAIN MSE LOSS : 356.0590427073232\n",
      "- TRAIN R2 SCORE : 0.9376484802052691\n",
      "\n",
      "- TEST MAE LOSS : 9.833131790161133\n",
      "- TEST MAPE LOSS : 21045.0234375\n",
      "- TEST MSE LOSS : 534.4467163085938\n",
      "- TEST R2 SCORE : 0.910433828830719\n",
      "성능 및 손실 개선이 없어서 88 EPOCH에 학습 중단\n",
      "pre_val : [58.960289001464844, 46.25630187988281, 255.5723114013672, 242.89561462402344, 0.0012855896493420005, 69.2529067993164, 226.5009002685547, 50.2083854675293, 227.10012817382812, 114.69892883300781]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[89 / 1000]\n",
      "- TRAIN MAE LOSS : 8.71755260300803\n",
      "- TRAIN MAPE LOSS : 48.7757240477642\n",
      "- TRAIN MSE LOSS : 353.1879967717524\n",
      "- TRAIN R2 SCORE : 0.9381555128264261\n",
      "\n",
      "- TEST MAE LOSS : 9.925448417663574\n",
      "- TEST MAPE LOSS : 21768.017578125\n",
      "- TEST MSE LOSS : 534.369873046875\n",
      "- TEST R2 SCORE : 0.9104467034339905\n",
      "성능 및 손실 개선이 없어서 89 EPOCH에 학습 중단\n",
      "pre_val : [57.88642501831055, 48.50340270996094, 247.94424438476562, 248.96002197265625, -0.0008667701040394604, 68.94886779785156, 225.99880981445312, 49.992576599121094, 229.5895538330078, 114.34349060058594]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[90 / 1000]\n",
      "- TRAIN MAE LOSS : 8.692851246720428\n",
      "- TRAIN MAPE LOSS : 95.95173914269759\n",
      "- TRAIN MSE LOSS : 350.6926398057204\n",
      "- TRAIN R2 SCORE : 0.9385841150550576\n",
      "\n",
      "- TEST MAE LOSS : 9.885144233703613\n",
      "- TEST MAPE LOSS : 21002.19140625\n",
      "- TEST MSE LOSS : 534.7898559570312\n",
      "- TEST R2 SCORE : 0.9103763103485107\n",
      "성능 및 손실 개선이 없어서 90 EPOCH에 학습 중단\n",
      "pre_val : [65.5832748413086, 47.922367095947266, 258.48809814453125, 250.0677490234375, -0.0011998177506029606, 64.02706909179688, 227.44598388671875, 49.33169937133789, 230.3383331298828, 114.58841705322266]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[91 / 1000]\n",
      "- TRAIN MAE LOSS : 8.677913684311447\n",
      "- TRAIN MAPE LOSS : 32.893316050688185\n",
      "- TRAIN MSE LOSS : 348.5767544886449\n",
      "- TRAIN R2 SCORE : 0.9389710122555286\n",
      "\n",
      "- TEST MAE LOSS : 9.8018159866333\n",
      "- TEST MAPE LOSS : 20679.91015625\n",
      "- TEST MSE LOSS : 531.9041137695312\n",
      "- TEST R2 SCORE : 0.9108599424362183\n",
      "성능 및 손실 개선이 없어서 91 EPOCH에 학습 중단\n",
      "pre_val : [56.22610092163086, 49.53257369995117, 256.5634460449219, 245.5948944091797, -0.0011402834206819534, 67.04622650146484, 227.81260681152344, 50.629783630371094, 225.33168029785156, 117.9428939819336]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[92 / 1000]\n",
      "- TRAIN MAE LOSS : 8.603956963132312\n",
      "- TRAIN MAPE LOSS : 155.6195959954365\n",
      "- TRAIN MSE LOSS : 345.8809615203217\n",
      "- TRAIN R2 SCORE : 0.9394418330292602\n",
      "\n",
      "- TEST MAE LOSS : 9.915253639221191\n",
      "- TEST MAPE LOSS : 21288.15234375\n",
      "- TEST MSE LOSS : 538.9855346679688\n",
      "- TEST R2 SCORE : 0.9096732139587402\n",
      "성능 및 손실 개선이 없어서 92 EPOCH에 학습 중단\n",
      "pre_val : [56.91209030151367, 47.81336975097656, 255.13804626464844, 253.25360107421875, 0.0010402639163658023, 71.998291015625, 222.04928588867188, 50.143760681152344, 225.29774475097656, 115.29817962646484]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[93 / 1000]\n",
      "- TRAIN MAE LOSS : 8.546750381776503\n",
      "- TRAIN MAPE LOSS : 48.08557774007477\n",
      "- TRAIN MSE LOSS : 343.9463213636492\n",
      "- TRAIN R2 SCORE : 0.9397776955324453\n",
      "\n",
      "- TEST MAE LOSS : 9.85755443572998\n",
      "- TEST MAPE LOSS : 20550.873046875\n",
      "- TEST MSE LOSS : 537.434814453125\n",
      "- TEST R2 SCORE : 0.9099330902099609\n",
      "성능 및 손실 개선이 없어서 93 EPOCH에 학습 중단\n",
      "pre_val : [64.89559936523438, 48.24047088623047, 256.8227844238281, 248.479248046875, 0.0013734751846641302, 64.8567886352539, 226.7286834716797, 49.66714859008789, 227.907958984375, 124.8676528930664]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[94 / 1000]\n",
      "- TRAIN MAE LOSS : 8.5630054101077\n",
      "- TRAIN MAPE LOSS : 18.45856768138759\n",
      "- TRAIN MSE LOSS : 343.203620887703\n",
      "- TRAIN R2 SCORE : 0.9399079236950908\n",
      "\n",
      "- TEST MAE LOSS : 9.826971054077148\n",
      "- TEST MAPE LOSS : 21423.8125\n",
      "- TEST MSE LOSS : 537.0593872070312\n",
      "- TEST R2 SCORE : 0.909995973110199\n",
      "성능 및 손실 개선이 없어서 94 EPOCH에 학습 중단\n",
      "pre_val : [59.95085525512695, 49.44873809814453, 256.15460205078125, 251.56918334960938, -0.0009757434600032866, 69.31188201904297, 227.15167236328125, 50.74913787841797, 225.88804626464844, 119.01824188232422]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[95 / 1000]\n",
      "- TRAIN MAE LOSS : 8.537456039215302\n",
      "- TRAIN MAPE LOSS : 133.20793280248512\n",
      "- TRAIN MSE LOSS : 340.36185224519744\n",
      "- TRAIN R2 SCORE : 0.9403949313230447\n",
      "\n",
      "- TEST MAE LOSS : 9.908182144165039\n",
      "- TEST MAPE LOSS : 21160.7265625\n",
      "- TEST MSE LOSS : 540.4759521484375\n",
      "- TEST R2 SCORE : 0.9094234108924866\n",
      "성능 및 손실 개선이 없어서 95 EPOCH에 학습 중단\n",
      "pre_val : [59.56826400756836, 51.29155349731445, 253.2641143798828, 252.5979766845703, -0.0006490813684649765, 65.66511535644531, 219.10935974121094, 49.8729248046875, 228.17181396484375, 116.5003433227539]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[96 / 1000]\n",
      "- TRAIN MAE LOSS : 8.52395125235711\n",
      "- TRAIN MAPE LOSS : 303.5305195334304\n",
      "- TRAIN MSE LOSS : 338.3565349850955\n",
      "- TRAIN R2 SCORE : 0.9407297030862395\n",
      "\n",
      "- TEST MAE LOSS : 9.833403587341309\n",
      "- TEST MAPE LOSS : 21240.580078125\n",
      "- TEST MSE LOSS : 536.0039672851562\n",
      "- TEST R2 SCORE : 0.9101728200912476\n",
      "성능 및 손실 개선이 없어서 96 EPOCH에 학습 중단\n",
      "pre_val : [69.63481140136719, 47.87421417236328, 254.0996551513672, 253.9666748046875, 0.0007709905621595681, 64.82301330566406, 220.18170166015625, 49.065364837646484, 226.85121154785156, 122.02093505859375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[97 / 1000]\n",
      "- TRAIN MAE LOSS : 8.483335494995117\n",
      "- TRAIN MAPE LOSS : 19.83500696903655\n",
      "- TRAIN MSE LOSS : 337.92313087143265\n",
      "- TRAIN R2 SCORE : 0.9407855520715247\n",
      "\n",
      "- TEST MAE LOSS : 9.787028312683105\n",
      "- TEST MAPE LOSS : 21084.7265625\n",
      "- TEST MSE LOSS : 536.616455078125\n",
      "- TEST R2 SCORE : 0.9100702404975891\n",
      "성능 및 손실 개선이 없어서 97 EPOCH에 학습 중단\n",
      "pre_val : [62.66631317138672, 48.517242431640625, 254.32534790039062, 251.64398193359375, 0.0009144999203272164, 66.20575714111328, 223.1572265625, 50.71128845214844, 227.4424285888672, 121.54605102539062]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[98 / 1000]\n",
      "- TRAIN MAE LOSS : 8.427969844391296\n",
      "- TRAIN MAPE LOSS : 84.09862880073592\n",
      "- TRAIN MSE LOSS : 333.92187074888005\n",
      "- TRAIN R2 SCORE : 0.941470304719218\n",
      "\n",
      "- TEST MAE LOSS : 9.8047456741333\n",
      "- TEST MAPE LOSS : 21726.68359375\n",
      "- TEST MSE LOSS : 536.1944580078125\n",
      "- TEST R2 SCORE : 0.9101409316062927\n",
      "성능 및 손실 개선이 없어서 98 EPOCH에 학습 중단\n",
      "pre_val : [65.08685302734375, 50.82583999633789, 255.99957275390625, 256.5360107421875, -0.001005064696073532, 64.69628143310547, 215.14683532714844, 51.16352462768555, 226.80886840820312, 119.1003189086914]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[99 / 1000]\n",
      "- TRAIN MAE LOSS : 8.366910068138496\n",
      "- TRAIN MAPE LOSS : 16.605625068055584\n",
      "- TRAIN MSE LOSS : 331.18143267598185\n",
      "- TRAIN R2 SCORE : 0.9419535603890052\n",
      "\n",
      "- TEST MAE LOSS : 9.734376907348633\n",
      "- TEST MAPE LOSS : 21306.041015625\n",
      "- TEST MSE LOSS : 533.671142578125\n",
      "- TEST R2 SCORE : 0.9105638265609741\n",
      "성능 및 손실 개선이 없어서 99 EPOCH에 학습 중단\n",
      "pre_val : [69.96672821044922, 47.45547866821289, 256.0604553222656, 256.0780029296875, -0.0011604424798861146, 64.73246765136719, 218.91966247558594, 51.15763473510742, 227.62466430664062, 120.93368530273438]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[100 / 1000]\n",
      "- TRAIN MAE LOSS : 8.361686598170888\n",
      "- TRAIN MAPE LOSS : 86.64068524529937\n",
      "- TRAIN MSE LOSS : 327.7934470500813\n",
      "- TRAIN R2 SCORE : 0.9425396117463812\n",
      "\n",
      "- TEST MAE LOSS : 9.688509941101074\n",
      "- TEST MAPE LOSS : 21811.173828125\n",
      "- TEST MSE LOSS : 531.3251953125\n",
      "- TEST R2 SCORE : 0.9109569787979126\n",
      "성능 및 손실 개선이 없어서 100 EPOCH에 학습 중단\n",
      "pre_val : [66.21501159667969, 50.13222885131836, 254.81967163085938, 249.89532470703125, -0.0006044834153726697, 67.36445617675781, 217.7208709716797, 52.748619079589844, 226.66912841796875, 117.91934204101562]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[101 / 1000]\n",
      "- TRAIN MAE LOSS : 8.469937327124855\n",
      "- TRAIN MAPE LOSS : 1010.9187849510372\n",
      "- TRAIN MSE LOSS : 330.1107659421267\n",
      "- TRAIN R2 SCORE : 0.942144525184498\n",
      "\n",
      "- TEST MAE LOSS : 9.78882884979248\n",
      "- TEST MAPE LOSS : 21965.681640625\n",
      "- TEST MSE LOSS : 535.726318359375\n",
      "- TEST R2 SCORE : 0.9102193713188171\n",
      "성능 및 손실 개선이 없어서 101 EPOCH에 학습 중단\n",
      "pre_val : [77.21906280517578, 47.55735778808594, 257.87725830078125, 256.7284240722656, 0.0012243553064763546, 62.31943893432617, 218.16831970214844, 51.4337272644043, 227.26101684570312, 120.0648193359375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[102 / 1000]\n",
      "- TRAIN MAE LOSS : 8.344811149677197\n",
      "- TRAIN MAPE LOSS : 45.76972857823113\n",
      "- TRAIN MSE LOSS : 324.7738404526077\n",
      "- TRAIN R2 SCORE : 0.9430633128606356\n",
      "\n",
      "- TEST MAE LOSS : 9.67495059967041\n",
      "- TEST MAPE LOSS : 21820.994140625\n",
      "- TEST MSE LOSS : 532.1668701171875\n",
      "- TEST R2 SCORE : 0.9108158946037292\n",
      "성능 및 손실 개선이 없어서 102 EPOCH에 학습 중단\n",
      "pre_val : [67.02609252929688, 49.86052703857422, 248.9982452392578, 258.41754150390625, -0.0012179779587313533, 64.83619689941406, 210.8898468017578, 50.42570495605469, 226.6873016357422, 113.8093490600586]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[103 / 1000]\n",
      "- TRAIN MAE LOSS : 8.317391080056037\n",
      "- TRAIN MAPE LOSS : 55.639023415278515\n",
      "- TRAIN MSE LOSS : 324.8178901917784\n",
      "- TRAIN R2 SCORE : 0.9430789675579204\n",
      "\n",
      "- TEST MAE LOSS : 9.699801445007324\n",
      "- TEST MAPE LOSS : 21899.634765625\n",
      "- TEST MSE LOSS : 533.117919921875\n",
      "- TEST R2 SCORE : 0.9106565117835999\n",
      "성능 및 손실 개선이 없어서 103 EPOCH에 학습 중단\n",
      "pre_val : [72.91979217529297, 47.75932312011719, 256.8965148925781, 259.0087585449219, -0.0014977502869442105, 64.18090057373047, 218.94064331054688, 51.73080062866211, 225.41226196289062, 120.35865020751953]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[104 / 1000]\n",
      "- TRAIN MAE LOSS : 8.304913892145757\n",
      "- TRAIN MAPE LOSS : 31.559381631762832\n",
      "- TRAIN MSE LOSS : 321.14981630338656\n",
      "- TRAIN R2 SCORE : 0.9437088577563946\n",
      "\n",
      "- TEST MAE LOSS : 9.697126388549805\n",
      "- TEST MAPE LOSS : 22078.7734375\n",
      "- TEST MSE LOSS : 532.3770141601562\n",
      "- TEST R2 SCORE : 0.910780668258667\n",
      "성능 및 손실 개선이 없어서 104 EPOCH에 학습 중단\n",
      "pre_val : [65.8132553100586, 45.935401916503906, 255.6392059326172, 252.35882568359375, -0.0008339440682902932, 67.96732330322266, 207.7265167236328, 50.29653549194336, 226.04112243652344, 111.04682159423828]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[105 / 1000]\n",
      "- TRAIN MAE LOSS : 8.211989336080485\n",
      "- TRAIN MAPE LOSS : 79.86576854609943\n",
      "- TRAIN MSE LOSS : 318.7114557199545\n",
      "- TRAIN R2 SCORE : 0.9441574659547606\n",
      "\n",
      "- TEST MAE LOSS : 9.634186744689941\n",
      "- TEST MAPE LOSS : 22311.95703125\n",
      "- TEST MSE LOSS : 530.775390625\n",
      "- TEST R2 SCORE : 0.9110491275787354\n",
      "성능 및 손실 개선이 없어서 105 EPOCH에 학습 중단\n",
      "pre_val : [66.07157135009766, 51.54375076293945, 251.63943481445312, 251.23150634765625, 0.001451283460482955, 66.3534927368164, 211.3703155517578, 52.955318450927734, 227.28733825683594, 115.93244171142578]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[106 / 1000]\n",
      "- TRAIN MAE LOSS : 8.202670543377216\n",
      "- TRAIN MAPE LOSS : 18.21287349443961\n",
      "- TRAIN MSE LOSS : 316.66204215896715\n",
      "- TRAIN R2 SCORE : 0.9444752798714005\n",
      "\n",
      "- TEST MAE LOSS : 9.558103561401367\n",
      "- TEST MAPE LOSS : 22685.220703125\n",
      "- TEST MSE LOSS : 525.9404296875\n",
      "- TEST R2 SCORE : 0.911859393119812\n",
      "성능 및 손실 개선이 없어서 106 EPOCH에 학습 중단\n",
      "pre_val : [80.5517349243164, 46.45254898071289, 250.9212646484375, 250.71865844726562, 0.0011697163572534919, 64.04058837890625, 214.11660766601562, 50.42649459838867, 227.08731079101562, 114.92162322998047]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[107 / 1000]\n",
      "- TRAIN MAE LOSS : 8.223720012544751\n",
      "- TRAIN MAPE LOSS : 520.8808320026235\n",
      "- TRAIN MSE LOSS : 315.59756676893966\n",
      "- TRAIN R2 SCORE : 0.94466041023081\n",
      "\n",
      "- TEST MAE LOSS : 9.614051818847656\n",
      "- TEST MAPE LOSS : 22152.59375\n",
      "- TEST MSE LOSS : 529.8399047851562\n",
      "- TEST R2 SCORE : 0.9112058877944946\n",
      "성능 및 손실 개선이 없어서 107 EPOCH에 학습 중단\n",
      "pre_val : [66.93452453613281, 49.349891662597656, 257.2774658203125, 248.57025146484375, -0.0009934871923178434, 67.26991271972656, 214.78880310058594, 51.690067291259766, 225.6690216064453, 116.5908203125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[108 / 1000]\n",
      "- TRAIN MAE LOSS : 8.24461234186079\n",
      "- TRAIN MAPE LOSS : 502.45442435726056\n",
      "- TRAIN MSE LOSS : 316.1613233841049\n",
      "- TRAIN R2 SCORE : 0.9445895966616544\n",
      "\n",
      "- TEST MAE LOSS : 9.715625762939453\n",
      "- TEST MAPE LOSS : 22133.05078125\n",
      "- TEST MSE LOSS : 534.7286987304688\n",
      "- TEST R2 SCORE : 0.9103865623474121\n",
      "성능 및 손실 개선이 없어서 108 EPOCH에 학습 중단\n",
      "pre_val : [62.613609313964844, 47.977657318115234, 249.24134826660156, 256.66583251953125, -0.0008769045816734433, 65.9254379272461, 210.6226348876953, 51.327083587646484, 226.99253845214844, 112.24420928955078]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[109 / 1000]\n",
      "- TRAIN MAE LOSS : 8.18099335923895\n",
      "- TRAIN MAPE LOSS : 21.274278121314474\n",
      "- TRAIN MSE LOSS : 313.7637695141772\n",
      "- TRAIN R2 SCORE : 0.9450039866587499\n",
      "\n",
      "- TEST MAE LOSS : 9.70900821685791\n",
      "- TEST MAPE LOSS : 21265.248046875\n",
      "- TEST MSE LOSS : 536.2982788085938\n",
      "- TEST R2 SCORE : 0.9101235270500183\n",
      "성능 및 손실 개선이 없어서 109 EPOCH에 학습 중단\n",
      "pre_val : [69.11953735351562, 44.09779357910156, 253.9253692626953, 250.19424438476562, -0.0008884638664312661, 65.75497436523438, 220.0782928466797, 53.01153564453125, 225.3264923095703, 111.35910034179688]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[110 / 1000]\n",
      "- TRAIN MAE LOSS : 8.135799280113273\n",
      "- TRAIN MAPE LOSS : 154.04563487845857\n",
      "- TRAIN MSE LOSS : 311.1484395151205\n",
      "- TRAIN R2 SCORE : 0.9454427936694005\n",
      "\n",
      "- TEST MAE LOSS : 9.683494567871094\n",
      "- TEST MAPE LOSS : 21581.470703125\n",
      "- TEST MSE LOSS : 536.7040405273438\n",
      "- TEST R2 SCORE : 0.9100555181503296\n",
      "성능 및 손실 개선이 없어서 110 EPOCH에 학습 중단\n",
      "pre_val : [68.26182556152344, 47.34147262573242, 254.22015380859375, 249.76002502441406, -0.0010763556929305196, 66.74734497070312, 210.03282165527344, 53.37016296386719, 226.12701416015625, 111.63077545166016]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[111 / 1000]\n",
      "- TRAIN MAE LOSS : 8.125203272612778\n",
      "- TRAIN MAPE LOSS : 51.427744781140994\n",
      "- TRAIN MSE LOSS : 309.94539840911654\n",
      "- TRAIN R2 SCORE : 0.945679135489297\n",
      "\n",
      "- TEST MAE LOSS : 9.609598159790039\n",
      "- TEST MAPE LOSS : 22063.70703125\n",
      "- TEST MSE LOSS : 531.2452392578125\n",
      "- TEST R2 SCORE : 0.9109703302383423\n",
      "성능 및 손실 개선이 없어서 111 EPOCH에 학습 중단\n",
      "pre_val : [88.32537078857422, 48.54055404663086, 250.20791625976562, 249.21983337402344, -0.0002195141714764759, 65.12767791748047, 214.2635498046875, 52.83665466308594, 227.56919860839844, 116.5348892211914]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[112 / 1000]\n",
      "- TRAIN MAE LOSS : 8.05810916813937\n",
      "- TRAIN MAPE LOSS : 13.74282642522423\n",
      "- TRAIN MSE LOSS : 307.6319576818293\n",
      "- TRAIN R2 SCORE : 0.9460484347977005\n",
      "\n",
      "- TEST MAE LOSS : 9.548255920410156\n",
      "- TEST MAPE LOSS : 21631.490234375\n",
      "- TEST MSE LOSS : 527.8894653320312\n",
      "- TEST R2 SCORE : 0.9115327596664429\n",
      "성능 및 손실 개선이 없어서 112 EPOCH에 학습 중단\n",
      "pre_val : [67.16017150878906, 48.99860382080078, 254.16493225097656, 248.3833465576172, 0.0009556093136779964, 71.26101684570312, 211.60911560058594, 53.10503005981445, 227.03294372558594, 113.4087142944336]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[113 / 1000]\n",
      "- TRAIN MAE LOSS : 8.02293538620422\n",
      "- TRAIN MAPE LOSS : 102.97916484408029\n",
      "- TRAIN MSE LOSS : 304.9449058570062\n",
      "- TRAIN R2 SCORE : 0.9465083966555295\n",
      "\n",
      "- TEST MAE LOSS : 9.559235572814941\n",
      "- TEST MAPE LOSS : 21223.89453125\n",
      "- TEST MSE LOSS : 529.027099609375\n",
      "- TEST R2 SCORE : 0.9113420844078064\n",
      "성능 및 손실 개선이 없어서 113 EPOCH에 학습 중단\n",
      "pre_val : [84.58016967773438, 45.75522994995117, 253.42111206054688, 250.6876678466797, 0.0010784600162878633, 63.50556182861328, 215.0233612060547, 53.89894104003906, 227.68028259277344, 114.49781799316406]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[114 / 1000]\n",
      "- TRAIN MAE LOSS : 8.007419531762183\n",
      "- TRAIN MAPE LOSS : 103.75881321948309\n",
      "- TRAIN MSE LOSS : 303.5655272679896\n",
      "- TRAIN R2 SCORE : 0.9467660133988707\n",
      "\n",
      "- TEST MAE LOSS : 9.521427154541016\n",
      "- TEST MAPE LOSS : 21133.701171875\n",
      "- TEST MSE LOSS : 529.5443115234375\n",
      "- TEST R2 SCORE : 0.911255419254303\n",
      "성능 및 손실 개선이 없어서 114 EPOCH에 학습 중단\n",
      "pre_val : [78.640380859375, 45.79350662231445, 252.42259216308594, 253.54710388183594, -0.000765151169616729, 67.70733642578125, 211.28976440429688, 54.28169250488281, 226.8649139404297, 113.99952697753906]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[115 / 1000]\n",
      "- TRAIN MAE LOSS : 8.06318018653176\n",
      "- TRAIN MAPE LOSS : 372.3642138995689\n",
      "- TRAIN MSE LOSS : 303.53188376580084\n",
      "- TRAIN R2 SCORE : 0.9467560215930005\n",
      "\n",
      "- TEST MAE LOSS : 9.649001121520996\n",
      "- TEST MAPE LOSS : 20925.9375\n",
      "- TEST MSE LOSS : 534.980224609375\n",
      "- TEST R2 SCORE : 0.9103444218635559\n",
      "성능 및 손실 개선이 없어서 115 EPOCH에 학습 중단\n",
      "pre_val : [69.80248260498047, 50.98366165161133, 243.13490295410156, 258.01025390625, -0.0009314666385762393, 66.2341079711914, 211.21571350097656, 53.385948181152344, 226.73822021484375, 111.65055847167969]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[116 / 1000]\n",
      "- TRAIN MAE LOSS : 8.008082366223102\n",
      "- TRAIN MAPE LOSS : 157.6223453695973\n",
      "- TRAIN MSE LOSS : 302.5786186340972\n",
      "- TRAIN R2 SCORE : 0.9469213467377883\n",
      "\n",
      "- TEST MAE LOSS : 9.604941368103027\n",
      "- TEST MAPE LOSS : 20570.728515625\n",
      "- TEST MSE LOSS : 531.2926635742188\n",
      "- TEST R2 SCORE : 0.9109624028205872\n",
      "성능 및 손실 개선이 없어서 116 EPOCH에 학습 중단\n",
      "pre_val : [104.6919937133789, 48.73097229003906, 246.83985900878906, 249.69241333007812, -0.0014059700770303607, 65.36166381835938, 210.22903442382812, 53.01262664794922, 225.66970825195312, 110.0794906616211]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[117 / 1000]\n",
      "- TRAIN MAE LOSS : 8.004592946059221\n",
      "- TRAIN MAPE LOSS : 256.3944594470292\n",
      "- TRAIN MSE LOSS : 300.48510620437304\n",
      "- TRAIN R2 SCORE : 0.9472993725329846\n",
      "\n",
      "- TEST MAE LOSS : 9.528776168823242\n",
      "- TEST MAPE LOSS : 21065.044921875\n",
      "- TEST MSE LOSS : 529.3983764648438\n",
      "- TEST R2 SCORE : 0.9112798571586609\n",
      "성능 및 손실 개선이 없어서 117 EPOCH에 학습 중단\n",
      "pre_val : [88.39141082763672, 47.86091232299805, 249.26222229003906, 253.22003173828125, 0.001360399415716529, 70.20834350585938, 208.3546600341797, 53.49807357788086, 226.93862915039062, 111.1213607788086]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[118 / 1000]\n",
      "- TRAIN MAE LOSS : 7.994299406638512\n",
      "- TRAIN MAPE LOSS : 50.537213898670004\n",
      "- TRAIN MSE LOSS : 300.94390752245494\n",
      "- TRAIN R2 SCORE : 0.9472182939936231\n",
      "\n",
      "- TEST MAE LOSS : 9.714448928833008\n",
      "- TEST MAPE LOSS : 20311.291015625\n",
      "- TEST MSE LOSS : 537.3280639648438\n",
      "- TEST R2 SCORE : 0.9099509716033936\n",
      "성능 및 손실 개선이 없어서 118 EPOCH에 학습 중단\n",
      "pre_val : [101.92073059082031, 49.513275146484375, 247.30160522460938, 249.7417449951172, 0.0014735670993104577, 67.85936737060547, 215.1563720703125, 52.65974807739258, 226.33738708496094, 114.38912963867188]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[119 / 1000]\n",
      "- TRAIN MAE LOSS : 8.032719231585522\n",
      "- TRAIN MAPE LOSS : 47.12072951541914\n",
      "- TRAIN MSE LOSS : 301.9455046444339\n",
      "- TRAIN R2 SCORE : 0.9470468542459127\n",
      "\n",
      "- TEST MAE LOSS : 9.575322151184082\n",
      "- TEST MAPE LOSS : 21520.251953125\n",
      "- TEST MSE LOSS : 528.8211669921875\n",
      "- TEST R2 SCORE : 0.9113765954971313\n",
      "성능 및 손실 개선이 없어서 119 EPOCH에 학습 중단\n",
      "pre_val : [94.44666290283203, 49.28464126586914, 250.22463989257812, 250.66366577148438, -0.0008219463634304702, 69.29817962646484, 206.14866638183594, 52.26581954956055, 226.46180725097656, 110.79080963134766]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[120 / 1000]\n",
      "- TRAIN MAE LOSS : 7.938525187619082\n",
      "- TRAIN MAPE LOSS : 87.88417435556025\n",
      "- TRAIN MSE LOSS : 297.55501011668383\n",
      "- TRAIN R2 SCORE : 0.9478286166124411\n",
      "\n",
      "- TEST MAE LOSS : 9.456119537353516\n",
      "- TEST MAPE LOSS : 21157.107421875\n",
      "- TEST MSE LOSS : 521.1742553710938\n",
      "- TEST R2 SCORE : 0.9126580953598022\n",
      "성능 및 손실 개선이 없어서 120 EPOCH에 학습 중단\n",
      "pre_val : [95.63325500488281, 52.352508544921875, 251.60003662109375, 250.01063537597656, 0.0011052351910620928, 67.24542999267578, 205.7584686279297, 52.03239822387695, 227.35060119628906, 110.5931396484375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[121 / 1000]\n",
      "- TRAIN MAE LOSS : 7.8829867186913125\n",
      "- TRAIN MAPE LOSS : 12.30730123687249\n",
      "- TRAIN MSE LOSS : 295.44313232848697\n",
      "- TRAIN R2 SCORE : 0.9481820472637257\n",
      "\n",
      "- TEST MAE LOSS : 9.467646598815918\n",
      "- TEST MAPE LOSS : 20765.525390625\n",
      "- TEST MSE LOSS : 521.2793579101562\n",
      "- TEST R2 SCORE : 0.9126405119895935\n",
      "성능 및 손실 개선이 없어서 121 EPOCH에 학습 중단\n",
      "pre_val : [110.16564178466797, 51.96675109863281, 250.39955139160156, 252.8242645263672, -0.0010691481875255704, 66.59142303466797, 207.20526123046875, 52.34022903442383, 226.75843811035156, 110.93437194824219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[122 / 1000]\n",
      "- TRAIN MAE LOSS : 7.911567059030066\n",
      "- TRAIN MAPE LOSS : 73.81566597774312\n",
      "- TRAIN MSE LOSS : 294.8010485338331\n",
      "- TRAIN R2 SCORE : 0.9482929868464703\n",
      "\n",
      "- TEST MAE LOSS : 9.4692964553833\n",
      "- TEST MAPE LOSS : 21066.6015625\n",
      "- TEST MSE LOSS : 519.7822875976562\n",
      "- TEST R2 SCORE : 0.9128913879394531\n",
      "성능 및 손실 개선이 없어서 122 EPOCH에 학습 중단\n",
      "pre_val : [85.71620178222656, 52.60952377319336, 248.1356658935547, 250.6080322265625, -0.0008359422208741307, 70.28128051757812, 207.40513610839844, 51.422428131103516, 226.81097412109375, 111.9750747680664]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[123 / 1000]\n",
      "- TRAIN MAE LOSS : 7.833090130932681\n",
      "- TRAIN MAPE LOSS : 81.21244189242488\n",
      "- TRAIN MSE LOSS : 290.06861292805706\n",
      "- TRAIN R2 SCORE : 0.949099999957985\n",
      "\n",
      "- TEST MAE LOSS : 9.570034980773926\n",
      "- TEST MAPE LOSS : 20702.908203125\n",
      "- TEST MSE LOSS : 527.3790283203125\n",
      "- TEST R2 SCORE : 0.9116182923316956\n",
      "성능 및 손실 개선이 없어서 123 EPOCH에 학습 중단\n",
      "pre_val : [93.74163055419922, 53.071292877197266, 248.3728485107422, 250.50518798828125, -0.0014314627042040229, 64.05948638916016, 204.9634552001953, 53.98390579223633, 227.5763397216797, 109.53858947753906]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[124 / 1000]\n",
      "- TRAIN MAE LOSS : 7.829576730861531\n",
      "- TRAIN MAPE LOSS : 28.769856049401778\n",
      "- TRAIN MSE LOSS : 290.4438555758816\n",
      "- TRAIN R2 SCORE : 0.9490438988325479\n",
      "\n",
      "- TEST MAE LOSS : 9.6864652633667\n",
      "- TEST MAPE LOSS : 20153.90234375\n",
      "- TEST MSE LOSS : 534.1249389648438\n",
      "- TEST R2 SCORE : 0.9104877710342407\n",
      "성능 및 손실 개선이 없어서 124 EPOCH에 학습 중단\n",
      "pre_val : [84.1636962890625, 58.67924118041992, 246.7022705078125, 252.13272094726562, 0.0009487594943493605, 68.45460510253906, 203.98622131347656, 51.70469284057617, 227.2054901123047, 109.9708251953125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[125 / 1000]\n",
      "- TRAIN MAE LOSS : 7.811535163959423\n",
      "- TRAIN MAPE LOSS : 79.19561200243818\n",
      "- TRAIN MSE LOSS : 288.08348504179844\n",
      "- TRAIN R2 SCORE : 0.9494530315165753\n",
      "\n",
      "- TEST MAE LOSS : 9.569916725158691\n",
      "- TEST MAPE LOSS : 20452.6640625\n",
      "- TEST MSE LOSS : 528.4539794921875\n",
      "- TEST R2 SCORE : 0.9114381074905396\n",
      "성능 및 손실 개선이 없어서 125 EPOCH에 학습 중단\n",
      "pre_val : [92.9675521850586, 59.20675277709961, 248.4574737548828, 254.5116729736328, -0.0011051964247599244, 71.07290649414062, 204.02796936035156, 52.037960052490234, 227.31900024414062, 111.5355224609375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[126 / 1000]\n",
      "- TRAIN MAE LOSS : 7.783091538435929\n",
      "- TRAIN MAPE LOSS : 12.779810032476703\n",
      "- TRAIN MSE LOSS : 287.84790087239725\n",
      "- TRAIN R2 SCORE : 0.9494947764423344\n",
      "\n",
      "- TEST MAE LOSS : 9.520747184753418\n",
      "- TEST MAPE LOSS : 19970.462890625\n",
      "- TEST MSE LOSS : 523.9024047851562\n",
      "- TEST R2 SCORE : 0.912200927734375\n",
      "성능 및 손실 개선이 없어서 126 EPOCH에 학습 중단\n",
      "pre_val : [96.2122573852539, 58.8592529296875, 244.2127685546875, 250.87757873535156, 0.001273419475182891, 68.12798309326172, 207.5919189453125, 53.68791961669922, 228.25299072265625, 112.19075012207031]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[127 / 1000]\n",
      "- TRAIN MAE LOSS : 7.804966455006099\n",
      "- TRAIN MAPE LOSS : 86.52337898038901\n",
      "- TRAIN MSE LOSS : 286.36518834841\n",
      "- TRAIN R2 SCORE : 0.9497585298298122\n",
      "\n",
      "- TEST MAE LOSS : 9.543121337890625\n",
      "- TEST MAPE LOSS : 20702.69140625\n",
      "- TEST MSE LOSS : 527.1431884765625\n",
      "- TEST R2 SCORE : 0.9116578102111816\n",
      "성능 및 손실 개선이 없어서 127 EPOCH에 학습 중단\n",
      "pre_val : [99.02214813232422, 56.04801559448242, 246.71058654785156, 254.6309051513672, -0.0010558918584138155, 70.03034973144531, 204.0064697265625, 52.618106842041016, 227.8968963623047, 110.03822326660156]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[128 / 1000]\n",
      "- TRAIN MAE LOSS : 7.773505858908166\n",
      "- TRAIN MAPE LOSS : 49.644599489729096\n",
      "- TRAIN MSE LOSS : 285.31001789813274\n",
      "- TRAIN R2 SCORE : 0.9499451735303118\n",
      "\n",
      "- TEST MAE LOSS : 9.482855796813965\n",
      "- TEST MAPE LOSS : 20735.96875\n",
      "- TEST MSE LOSS : 522.7335205078125\n",
      "- TEST R2 SCORE : 0.9123967885971069\n",
      "성능 및 손실 개선이 없어서 128 EPOCH에 학습 중단\n",
      "pre_val : [106.81198120117188, 53.06956100463867, 244.6258544921875, 249.36463928222656, 0.0014139378909021616, 67.72774505615234, 204.9700164794922, 51.8173828125, 226.8108673095703, 110.43555450439453]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[129 / 1000]\n",
      "- TRAIN MAE LOSS : 7.771452496735366\n",
      "- TRAIN MAPE LOSS : 238.0190621112829\n",
      "- TRAIN MSE LOSS : 284.1780164961381\n",
      "- TRAIN R2 SCORE : 0.9501354340406565\n",
      "\n",
      "- TEST MAE LOSS : 9.555249214172363\n",
      "- TEST MAPE LOSS : 19703.6484375\n",
      "- TEST MSE LOSS : 526.349365234375\n",
      "- TEST R2 SCORE : 0.9117908477783203\n",
      "성능 및 손실 개선이 없어서 129 EPOCH에 학습 중단\n",
      "pre_val : [96.52790069580078, 59.49814224243164, 243.48617553710938, 250.96690368652344, -0.0006072738906368613, 71.205078125, 204.9922637939453, 53.732059478759766, 227.91567993164062, 108.5997085571289]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[130 / 1000]\n",
      "- TRAIN MAE LOSS : 7.792782554493084\n",
      "- TRAIN MAPE LOSS : 110.77085461902973\n",
      "- TRAIN MSE LOSS : 285.1469257344066\n",
      "- TRAIN R2 SCORE : 0.9499608687754277\n",
      "\n",
      "- TEST MAE LOSS : 9.469915390014648\n",
      "- TEST MAPE LOSS : 20095.4765625\n",
      "- TEST MSE LOSS : 519.7590942382812\n",
      "- TEST R2 SCORE : 0.9128952622413635\n",
      "성능 및 손실 개선이 없어서 130 EPOCH에 학습 중단\n",
      "pre_val : [98.9177474975586, 56.335086822509766, 243.1537628173828, 251.12997436523438, -0.001568614155985415, 71.59882354736328, 207.83016967773438, 54.66752624511719, 228.94944763183594, 110.2955551147461]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[131 / 1000]\n",
      "- TRAIN MAE LOSS : 7.754618391557173\n",
      "- TRAIN MAPE LOSS : 317.89606203965633\n",
      "- TRAIN MSE LOSS : 283.58608014140094\n",
      "- TRAIN R2 SCORE : 0.9502351755028838\n",
      "\n",
      "- TEST MAE LOSS : 9.45669174194336\n",
      "- TEST MAPE LOSS : 20533.2421875\n",
      "- TEST MSE LOSS : 520.6827392578125\n",
      "- TEST R2 SCORE : 0.9127404689788818\n",
      "성능 및 손실 개선이 없어서 131 EPOCH에 학습 중단\n",
      "pre_val : [98.27791595458984, 56.05415725708008, 239.55807495117188, 250.32887268066406, -0.00014320423360913992, 73.40193176269531, 207.09686279296875, 54.67477035522461, 227.1690673828125, 110.50028991699219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[132 / 1000]\n",
      "- TRAIN MAE LOSS : 7.51821965310957\n",
      "- TRAIN MAPE LOSS : 90.1896312814925\n",
      "- TRAIN MSE LOSS : 273.24966281917546\n",
      "- TRAIN R2 SCORE : 0.9520082771194565\n",
      "\n",
      "- TEST MAE LOSS : 9.31160831451416\n",
      "- TEST MAPE LOSS : 20536.373046875\n",
      "- TEST MSE LOSS : 516.8511962890625\n",
      "- TEST R2 SCORE : 0.9133825898170471\n",
      "성능 및 손실 개선이 없어서 132 EPOCH에 학습 중단\n",
      "pre_val : [97.70943450927734, 56.32688903808594, 238.8206024169922, 250.11766052246094, -0.00013225524162407964, 73.28397369384766, 206.6343994140625, 54.64288330078125, 227.06442260742188, 110.51475524902344]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[133 / 1000]\n",
      "- TRAIN MAE LOSS : 7.418795268585632\n",
      "- TRAIN MAPE LOSS : 57.20081224818069\n",
      "- TRAIN MSE LOSS : 268.7734358167315\n",
      "- TRAIN R2 SCORE : 0.9527952734407011\n",
      "\n",
      "- TEST MAE LOSS : 9.29625415802002\n",
      "- TEST MAPE LOSS : 20434.54296875\n",
      "- TEST MSE LOSS : 516.1918334960938\n",
      "- TEST R2 SCORE : 0.9134930968284607\n",
      "성능 및 손실 개선이 없어서 133 EPOCH에 학습 중단\n",
      "pre_val : [97.64830780029297, 56.52920913696289, 238.38363647460938, 249.80355834960938, 8.40435313875787e-05, 73.1295394897461, 206.29727172851562, 54.55466079711914, 226.98867797851562, 110.49517059326172]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[134 / 1000]\n",
      "- TRAIN MAE LOSS : 7.380271896615729\n",
      "- TRAIN MAPE LOSS : 40.31027309631082\n",
      "- TRAIN MSE LOSS : 266.917311939693\n",
      "- TRAIN R2 SCORE : 0.9531247049611765\n",
      "\n",
      "- TEST MAE LOSS : 9.278553009033203\n",
      "- TEST MAPE LOSS : 20387.119140625\n",
      "- TEST MSE LOSS : 515.19677734375\n",
      "- TEST R2 SCORE : 0.9136598706245422\n",
      "성능 및 손실 개선이 없어서 134 EPOCH에 학습 중단\n",
      "pre_val : [98.01809692382812, 57.33506393432617, 237.96578979492188, 249.66653442382812, 0.00015912807430140674, 72.97215270996094, 206.0373992919922, 54.688541412353516, 226.8685760498047, 110.50257873535156]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[135 / 1000]\n",
      "- TRAIN MAE LOSS : 7.351705757221142\n",
      "- TRAIN MAPE LOSS : 31.465998321690343\n",
      "- TRAIN MSE LOSS : 265.6393625480812\n",
      "- TRAIN R2 SCORE : 0.953350251921407\n",
      "\n",
      "- TEST MAE LOSS : 9.266861915588379\n",
      "- TEST MAPE LOSS : 20305.470703125\n",
      "- TEST MSE LOSS : 514.7094116210938\n",
      "- TEST R2 SCORE : 0.9137415289878845\n",
      "성능 및 손실 개선이 없어서 135 EPOCH에 학습 중단\n",
      "pre_val : [98.00714111328125, 57.42795944213867, 237.8621063232422, 249.66989135742188, -0.00012632302241399884, 73.09214782714844, 205.6800537109375, 54.60979461669922, 226.73468017578125, 110.52609252929688]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[136 / 1000]\n",
      "- TRAIN MAE LOSS : 7.334054931427215\n",
      "- TRAIN MAPE LOSS : 23.724713282062563\n",
      "- TRAIN MSE LOSS : 264.7613808766612\n",
      "- TRAIN R2 SCORE : 0.9535037423013807\n",
      "\n",
      "- TEST MAE LOSS : 9.255504608154297\n",
      "- TEST MAPE LOSS : 20315.65625\n",
      "- TEST MSE LOSS : 513.9135131835938\n",
      "- TEST R2 SCORE : 0.9138749241828918\n",
      "성능 및 손실 개선이 없어서 136 EPOCH에 학습 중단\n",
      "pre_val : [98.3161849975586, 58.36036682128906, 237.87559509277344, 249.4877471923828, 6.335990474326536e-05, 72.88072204589844, 205.3571014404297, 54.72405242919922, 226.63589477539062, 110.58196258544922]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[137 / 1000]\n",
      "- TRAIN MAE LOSS : 7.318121080598631\n",
      "- TRAIN MAPE LOSS : 18.074704092701936\n",
      "- TRAIN MSE LOSS : 263.904705015596\n",
      "- TRAIN R2 SCORE : 0.953655030660696\n",
      "\n",
      "- TEST MAE LOSS : 9.250299453735352\n",
      "- TEST MAPE LOSS : 20264.6015625\n",
      "- TEST MSE LOSS : 513.6044921875\n",
      "- TEST R2 SCORE : 0.9139267206192017\n",
      "성능 및 손실 개선이 없어서 137 EPOCH에 학습 중단\n",
      "pre_val : [98.5082778930664, 58.794456481933594, 237.86895751953125, 249.47682189941406, 0.00015674263704568148, 73.25914001464844, 205.4807891845703, 54.678890228271484, 226.69142150878906, 110.41859436035156]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[138 / 1000]\n",
      "- TRAIN MAE LOSS : 7.304372259486805\n",
      "- TRAIN MAPE LOSS : 14.977707153546747\n",
      "- TRAIN MSE LOSS : 263.3020454246681\n",
      "- TRAIN R2 SCORE : 0.9537603053513106\n",
      "\n",
      "- TEST MAE LOSS : 9.240371704101562\n",
      "- TEST MAPE LOSS : 20285.263671875\n",
      "- TEST MSE LOSS : 512.8881225585938\n",
      "- TEST R2 SCORE : 0.9140467643737793\n",
      "성능 및 손실 개선이 없어서 138 EPOCH에 학습 중단\n",
      "pre_val : [98.67243957519531, 58.86835479736328, 237.9229278564453, 249.3816375732422, -6.099950041971169e-06, 72.9338607788086, 205.28372192382812, 54.74824905395508, 226.76104736328125, 110.36585998535156]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[139 / 1000]\n",
      "- TRAIN MAE LOSS : 7.295431269398936\n",
      "- TRAIN MAPE LOSS : 10.516433684640935\n",
      "- TRAIN MSE LOSS : 262.64536630056955\n",
      "- TRAIN R2 SCORE : 0.9538747789142848\n",
      "\n",
      "- TEST MAE LOSS : 9.242135047912598\n",
      "- TEST MAPE LOSS : 20323.48828125\n",
      "- TEST MSE LOSS : 512.8182983398438\n",
      "- TEST R2 SCORE : 0.9140584468841553\n",
      "성능 및 손실 개선이 없어서 139 EPOCH에 학습 중단\n",
      "pre_val : [99.13905334472656, 59.6644401550293, 237.9164581298828, 249.54161071777344, 0.0001603137206984684, 72.96834564208984, 205.0231475830078, 54.74554443359375, 226.71142578125, 110.5182876586914]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[140 / 1000]\n",
      "- TRAIN MAE LOSS : 7.283499804610139\n",
      "- TRAIN MAPE LOSS : 8.166786996682625\n",
      "- TRAIN MSE LOSS : 262.08989178210703\n",
      "- TRAIN R2 SCORE : 0.9539740104441876\n",
      "\n",
      "- TEST MAE LOSS : 9.239150047302246\n",
      "- TEST MAPE LOSS : 20281.986328125\n",
      "- TEST MSE LOSS : 512.7872924804688\n",
      "- TEST R2 SCORE : 0.9140636920928955\n",
      "성능 및 손실 개선이 없어서 140 EPOCH에 학습 중단\n",
      "pre_val : [99.08157348632812, 59.830318450927734, 237.93228149414062, 249.35400390625, 0.0001680170389590785, 73.2077865600586, 205.0507049560547, 54.65513610839844, 226.58912658691406, 110.3287353515625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[141 / 1000]\n",
      "- TRAIN MAE LOSS : 7.279116067953043\n",
      "- TRAIN MAPE LOSS : 5.717562877968266\n",
      "- TRAIN MSE LOSS : 261.7124693863875\n",
      "- TRAIN R2 SCORE : 0.9540402307043543\n",
      "\n",
      "- TEST MAE LOSS : 9.228736877441406\n",
      "- TEST MAPE LOSS : 20346.365234375\n",
      "- TEST MSE LOSS : 512.1405639648438\n",
      "- TEST R2 SCORE : 0.9141720533370972\n",
      "성능 및 손실 개선이 없어서 141 EPOCH에 학습 중단\n",
      "pre_val : [99.40343475341797, 60.52103805541992, 238.0749969482422, 249.56521606445312, 0.00012373867502901703, 73.0499267578125, 205.0359649658203, 55.02701950073242, 226.69688415527344, 110.51460266113281]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[142 / 1000]\n",
      "- TRAIN MAE LOSS : 7.269352884626055\n",
      "- TRAIN MAPE LOSS : 2.3133026300990704\n",
      "- TRAIN MSE LOSS : 261.1605426585591\n",
      "- TRAIN R2 SCORE : 0.9541376864159857\n",
      "\n",
      "- TEST MAE LOSS : 9.239348411560059\n",
      "- TEST MAPE LOSS : 20314.29296875\n",
      "- TEST MSE LOSS : 512.6184692382812\n",
      "- TEST R2 SCORE : 0.914091944694519\n",
      "성능 및 손실 개선이 없어서 142 EPOCH에 학습 중단\n",
      "pre_val : [101.55992126464844, 60.77985382080078, 238.1113739013672, 249.3567352294922, -0.0001237153628608212, 73.0661849975586, 205.4723358154297, 54.69331359863281, 227.08462524414062, 110.4797134399414]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[143 / 1000]\n",
      "- TRAIN MAE LOSS : 7.263933333216848\n",
      "- TRAIN MAPE LOSS : 4.61105752139502\n",
      "- TRAIN MSE LOSS : 260.8557994100931\n",
      "- TRAIN R2 SCORE : 0.9541905286095359\n",
      "\n",
      "- TEST MAE LOSS : 9.21433162689209\n",
      "- TEST MAPE LOSS : 20435.91796875\n",
      "- TEST MSE LOSS : 511.2452392578125\n",
      "- TEST R2 SCORE : 0.9143220782279968\n",
      "성능 및 손실 개선이 없어서 143 EPOCH에 학습 중단\n",
      "pre_val : [100.50611114501953, 61.89463806152344, 237.83224487304688, 249.34213256835938, 0.00017572566866874695, 73.2365493774414, 204.95753479003906, 55.00624084472656, 226.7808837890625, 110.46829223632812]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[144 / 1000]\n",
      "- TRAIN MAE LOSS : 7.253443605583031\n",
      "- TRAIN MAPE LOSS : 6.028770240646351\n",
      "- TRAIN MSE LOSS : 260.2623259196248\n",
      "- TRAIN R2 SCORE : 0.9542957449626256\n",
      "\n",
      "- TEST MAE LOSS : 9.2327880859375\n",
      "- TEST MAPE LOSS : 20343.185546875\n",
      "- TEST MSE LOSS : 512.523681640625\n",
      "- TEST R2 SCORE : 0.9141078591346741\n",
      "성능 및 손실 개선이 없어서 144 EPOCH에 학습 중단\n",
      "pre_val : [100.89501190185547, 61.78530502319336, 237.76666259765625, 249.37753295898438, 0.00015657884068787098, 73.2937240600586, 205.0687713623047, 55.1296501159668, 226.70504760742188, 110.32386779785156]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[145 / 1000]\n",
      "- TRAIN MAE LOSS : 7.2517251215447915\n",
      "- TRAIN MAPE LOSS : 5.491056992613769\n",
      "- TRAIN MSE LOSS : 260.0365303082233\n",
      "- TRAIN R2 SCORE : 0.9543338873002912\n",
      "\n",
      "- TEST MAE LOSS : 9.229296684265137\n",
      "- TEST MAPE LOSS : 20397.1875\n",
      "- TEST MSE LOSS : 512.0211181640625\n",
      "- TEST R2 SCORE : 0.9141920804977417\n",
      "성능 및 손실 개선이 없어서 145 EPOCH에 학습 중단\n",
      "pre_val : [102.44685363769531, 61.90038299560547, 237.7991485595703, 249.25811767578125, -0.000164014330948703, 73.1520004272461, 205.43719482421875, 54.938289642333984, 227.13829040527344, 110.32270050048828]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[146 / 1000]\n",
      "- TRAIN MAE LOSS : 7.248007284444529\n",
      "- TRAIN MAPE LOSS : 2.5731712329330354\n",
      "- TRAIN MSE LOSS : 259.6869611278614\n",
      "- TRAIN R2 SCORE : 0.9543958092069292\n",
      "\n",
      "- TEST MAE LOSS : 9.214371681213379\n",
      "- TEST MAPE LOSS : 20500.33984375\n",
      "- TEST MSE LOSS : 511.1749267578125\n",
      "- TEST R2 SCORE : 0.9143338799476624\n",
      "성능 및 손실 개선이 없어서 146 EPOCH에 학습 중단\n",
      "pre_val : [101.8087387084961, 63.02536392211914, 237.7696075439453, 249.25845336914062, 9.233339369529858e-05, 73.43799591064453, 205.060791015625, 55.36233901977539, 226.80271911621094, 110.34375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[147 / 1000]\n",
      "- TRAIN MAE LOSS : 7.236318745513063\n",
      "- TRAIN MAPE LOSS : 8.539350401348063\n",
      "- TRAIN MSE LOSS : 259.1920444221763\n",
      "- TRAIN R2 SCORE : 0.9544835760710123\n",
      "\n",
      "- TEST MAE LOSS : 9.228914260864258\n",
      "- TEST MAPE LOSS : 20471.205078125\n",
      "- TEST MSE LOSS : 512.240966796875\n",
      "- TEST R2 SCORE : 0.9141552448272705\n",
      "성능 및 손실 개선이 없어서 147 EPOCH에 학습 중단\n",
      "pre_val : [100.95719146728516, 62.36599349975586, 237.33517456054688, 249.48989868164062, -0.00014973311044741422, 73.27123260498047, 204.99728393554688, 55.012840270996094, 226.83567810058594, 110.18819427490234]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[148 / 1000]\n",
      "- TRAIN MAE LOSS : 7.240588833468777\n",
      "- TRAIN MAPE LOSS : 12.800214472593336\n",
      "- TRAIN MSE LOSS : 258.94635106813655\n",
      "- TRAIN R2 SCORE : 0.9545256499143747\n",
      "\n",
      "- TEST MAE LOSS : 9.224416732788086\n",
      "- TEST MAPE LOSS : 20558.05859375\n",
      "- TEST MSE LOSS : 511.7496643066406\n",
      "- TEST R2 SCORE : 0.9142375588417053\n",
      "성능 및 손실 개선이 없어서 148 EPOCH에 학습 중단\n",
      "pre_val : [102.5459976196289, 63.48564147949219, 237.7925262451172, 249.64268493652344, -0.00013375087291933596, 73.06300354003906, 205.2802276611328, 55.16548538208008, 227.13845825195312, 110.36922454833984]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[149 / 1000]\n",
      "- TRAIN MAE LOSS : 7.237354681241762\n",
      "- TRAIN MAPE LOSS : 4.223106222571089\n",
      "- TRAIN MSE LOSS : 258.9224498316625\n",
      "- TRAIN R2 SCORE : 0.9545290176018135\n",
      "\n",
      "- TEST MAE LOSS : 9.228347778320312\n",
      "- TEST MAPE LOSS : 20560.6953125\n",
      "- TEST MSE LOSS : 512.03125\n",
      "- TEST R2 SCORE : 0.9141903519630432\n",
      "성능 및 손실 개선이 없어서 149 EPOCH에 학습 중단\n",
      "pre_val : [101.3350830078125, 63.331844329833984, 236.96844482421875, 249.4296417236328, -0.00011963805445702747, 73.5953140258789, 205.1832275390625, 55.24275207519531, 226.91493225097656, 110.13261413574219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[150 / 1000]\n",
      "- TRAIN MAE LOSS : 7.234519833051241\n",
      "- TRAIN MAPE LOSS : 8.570844392997923\n",
      "- TRAIN MSE LOSS : 258.7844624360625\n",
      "- TRAIN R2 SCORE : 0.9545522848542753\n",
      "\n",
      "- TEST MAE LOSS : 9.228127479553223\n",
      "- TEST MAPE LOSS : 20543.91015625\n",
      "- TEST MSE LOSS : 512.0753784179688\n",
      "- TEST R2 SCORE : 0.9141829609870911\n",
      "성능 및 손실 개선이 없어서 150 EPOCH에 학습 중단\n",
      "pre_val : [102.00019073486328, 64.12146759033203, 237.5328826904297, 248.9354705810547, 0.0001607255544513464, 73.34371948242188, 204.94615173339844, 55.53411865234375, 226.83351135253906, 110.2796859741211]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[151 / 1000]\n",
      "- TRAIN MAE LOSS : 7.227677738082993\n",
      "- TRAIN MAPE LOSS : 3.285952300566372\n",
      "- TRAIN MSE LOSS : 258.3780147883275\n",
      "- TRAIN R2 SCORE : 0.9546251151778481\n",
      "\n",
      "- TEST MAE LOSS : 9.229199409484863\n",
      "- TEST MAPE LOSS : 20553.69140625\n",
      "- TEST MSE LOSS : 512.2295532226562\n",
      "- TEST R2 SCORE : 0.9141571521759033\n",
      "성능 및 손실 개선이 없어서 151 EPOCH에 학습 중단\n",
      "pre_val : [103.03435516357422, 64.29354095458984, 237.3677520751953, 249.2726287841797, 0.00015868284390307963, 73.3963623046875, 205.29249572753906, 55.107093811035156, 227.24066162109375, 110.3725357055664]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[152 / 1000]\n",
      "- TRAIN MAE LOSS : 7.2261351590056515\n",
      "- TRAIN MAPE LOSS : 5.213990742633497\n",
      "- TRAIN MSE LOSS : 258.16108758139444\n",
      "- TRAIN R2 SCORE : 0.9546639090651399\n",
      "\n",
      "- TEST MAE LOSS : 9.223618507385254\n",
      "- TEST MAPE LOSS : 20576.54296875\n",
      "- TEST MSE LOSS : 511.6954345703125\n",
      "- TEST R2 SCORE : 0.914246678352356\n",
      "성능 및 손실 개선이 없어서 152 EPOCH에 학습 중단\n",
      "pre_val : [102.0114517211914, 64.60891723632812, 237.30471801757812, 248.86537170410156, 0.0001517102209618315, 73.65918731689453, 204.95687866210938, 55.42794418334961, 226.8566436767578, 110.209716796875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[153 / 1000]\n",
      "- TRAIN MAE LOSS : 7.219676953829252\n",
      "- TRAIN MAPE LOSS : 6.130589533273677\n",
      "- TRAIN MSE LOSS : 257.7653547177615\n",
      "- TRAIN R2 SCORE : 0.9547332755669014\n",
      "\n",
      "- TEST MAE LOSS : 9.2298583984375\n",
      "- TEST MAPE LOSS : 20597.77734375\n",
      "- TEST MSE LOSS : 512.293212890625\n",
      "- TEST R2 SCORE : 0.9141464829444885\n",
      "성능 및 손실 개선이 없어서 153 EPOCH에 학습 중단\n",
      "pre_val : [101.84919738769531, 64.76101684570312, 237.1698760986328, 248.93458557128906, -0.00015605943917762488, 73.4464111328125, 205.10438537597656, 55.518653869628906, 226.91238403320312, 110.15039825439453]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[154 / 1000]\n",
      "- TRAIN MAE LOSS : 7.21745012003225\n",
      "- TRAIN MAPE LOSS : 3.5509313959185476\n",
      "- TRAIN MSE LOSS : 257.6062454341008\n",
      "- TRAIN R2 SCORE : 0.9547621246984789\n",
      "\n",
      "- TEST MAE LOSS : 9.220891952514648\n",
      "- TEST MAPE LOSS : 20688.83984375\n",
      "- TEST MSE LOSS : 511.4594421386719\n",
      "- TEST R2 SCORE : 0.914286196231842\n",
      "성능 및 손실 개선이 없어서 154 EPOCH에 학습 중단\n",
      "pre_val : [102.30058288574219, 65.94242858886719, 238.16253662109375, 249.62083435058594, -4.1007706386153586e-07, 73.60272979736328, 205.23260498046875, 55.73573303222656, 227.1759033203125, 110.34626770019531]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[155 / 1000]\n",
      "- TRAIN MAE LOSS : 7.2072794506766575\n",
      "- TRAIN MAPE LOSS : 6.722489782122152\n",
      "- TRAIN MSE LOSS : 256.51311953191157\n",
      "- TRAIN R2 SCORE : 0.9549551931961433\n",
      "\n",
      "- TEST MAE LOSS : 9.214825630187988\n",
      "- TEST MAPE LOSS : 20723.142578125\n",
      "- TEST MSE LOSS : 511.27740478515625\n",
      "- TEST R2 SCORE : 0.914316713809967\n",
      "성능 및 손실 개선이 없어서 155 EPOCH에 학습 중단\n",
      "pre_val : [102.31550598144531, 66.27801513671875, 238.13577270507812, 249.49093627929688, 8.066281225183047e-06, 73.57456970214844, 205.20423889160156, 55.756439208984375, 227.20700073242188, 110.38748931884766]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[156 / 1000]\n",
      "- TRAIN MAE LOSS : 7.199009014876572\n",
      "- TRAIN MAPE LOSS : 5.43286902528178\n",
      "- TRAIN MSE LOSS : 256.2489938023707\n",
      "- TRAIN R2 SCORE : 0.9549994819481056\n",
      "\n",
      "- TEST MAE LOSS : 9.210981369018555\n",
      "- TEST MAPE LOSS : 20733.42578125\n",
      "- TEST MSE LOSS : 511.073486328125\n",
      "- TEST R2 SCORE : 0.9143508672714233\n",
      "성능 및 손실 개선이 없어서 156 EPOCH에 학습 중단\n",
      "pre_val : [102.32633972167969, 66.36504364013672, 238.0461883544922, 249.38363647460938, 2.665810643520672e-05, 73.62406158447266, 205.18582153320312, 55.72921371459961, 227.21435546875, 110.41089630126953]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[157 / 1000]\n",
      "- TRAIN MAE LOSS : 7.196040244869419\n",
      "- TRAIN MAPE LOSS : 4.670853981612237\n",
      "- TRAIN MSE LOSS : 256.11837703197983\n",
      "- TRAIN R2 SCORE : 0.9550223036412593\n",
      "\n",
      "- TEST MAE LOSS : 9.210209846496582\n",
      "- TEST MAPE LOSS : 20730.662109375\n",
      "- TEST MSE LOSS : 510.99658203125\n",
      "- TEST R2 SCORE : 0.9143637418746948\n",
      "성능 및 손실 개선이 없어서 157 EPOCH에 학습 중단\n",
      "pre_val : [102.34734344482422, 66.5569839477539, 237.99313354492188, 249.31024169921875, 2.121128636645153e-05, 73.61058044433594, 205.19387817382812, 55.737144470214844, 227.2329559326172, 110.4292984008789]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[158 / 1000]\n",
      "- TRAIN MAE LOSS : 7.193910336194339\n",
      "- TRAIN MAPE LOSS : 3.505478695813384\n",
      "- TRAIN MSE LOSS : 256.01327537856736\n",
      "- TRAIN R2 SCORE : 0.9550410434249398\n",
      "\n",
      "- TEST MAE LOSS : 9.207969665527344\n",
      "- TEST MAPE LOSS : 20745.09375\n",
      "- TEST MSE LOSS : 510.8658142089844\n",
      "- TEST R2 SCORE : 0.9143856763839722\n",
      "성능 및 손실 개선이 없어서 158 EPOCH에 학습 중단\n",
      "pre_val : [102.29981994628906, 66.5810317993164, 237.92779541015625, 249.22950744628906, 1.4986272617534269e-05, 73.6488265991211, 205.19699096679688, 55.72107696533203, 227.24777221679688, 110.4244384765625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[159 / 1000]\n",
      "- TRAIN MAE LOSS : 7.192252391134942\n",
      "- TRAIN MAPE LOSS : 2.883168769215683\n",
      "- TRAIN MSE LOSS : 255.93636166605916\n",
      "- TRAIN R2 SCORE : 0.9550547988097985\n",
      "\n",
      "- TEST MAE LOSS : 9.207893371582031\n",
      "- TEST MAPE LOSS : 20738.744140625\n",
      "- TEST MSE LOSS : 510.83551025390625\n",
      "- TEST R2 SCORE : 0.9143907427787781\n",
      "성능 및 손실 개선이 없어서 159 EPOCH에 학습 중단\n",
      "pre_val : [102.31217193603516, 66.64373016357422, 237.8572235107422, 249.2172088623047, 9.596677045919932e-06, 73.64261627197266, 205.22927856445312, 55.71403121948242, 227.26710510253906, 110.4040756225586]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[160 / 1000]\n",
      "- TRAIN MAE LOSS : 7.191127293460019\n",
      "- TRAIN MAPE LOSS : 1.801401309462694\n",
      "- TRAIN MSE LOSS : 255.86741012893356\n",
      "- TRAIN R2 SCORE : 0.9550672015610274\n",
      "\n",
      "- TEST MAE LOSS : 9.206290245056152\n",
      "- TEST MAPE LOSS : 20745.21484375\n",
      "- TEST MSE LOSS : 510.7099304199219\n",
      "- TEST R2 SCORE : 0.9144117832183838\n",
      "성능 및 손실 개선이 없어서 160 EPOCH에 학습 중단\n",
      "pre_val : [102.33179473876953, 66.78704833984375, 237.8293914794922, 249.13653564453125, -4.290713491172937e-07, 73.66736602783203, 205.1773681640625, 55.691741943359375, 227.25001525878906, 110.40110778808594]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[161 / 1000]\n",
      "- TRAIN MAE LOSS : 7.189665686867454\n",
      "- TRAIN MAPE LOSS : 0.9568676097779633\n",
      "- TRAIN MSE LOSS : 255.80036116593368\n",
      "- TRAIN R2 SCORE : 0.9550795617303648\n",
      "\n",
      "- TEST MAE LOSS : 9.206158638000488\n",
      "- TEST MAPE LOSS : 20737.505859375\n",
      "- TEST MSE LOSS : 510.71490478515625\n",
      "- TEST R2 SCORE : 0.9144109487533569\n",
      "성능 및 손실 개선이 없어서 161 EPOCH에 학습 중단\n",
      "pre_val : [102.1834945678711, 66.74668884277344, 237.72166442871094, 249.0729522705078, 1.862835415522568e-05, 73.65015411376953, 205.13116455078125, 55.6768798828125, 227.21421813964844, 110.38855743408203]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[162 / 1000]\n",
      "- TRAIN MAE LOSS : 7.188946660715383\n",
      "- TRAIN MAPE LOSS : 1.210935392014526\n",
      "- TRAIN MSE LOSS : 255.75166758077128\n",
      "- TRAIN R2 SCORE : 0.9550880591519229\n",
      "\n",
      "- TEST MAE LOSS : 9.20595645904541\n",
      "- TEST MAPE LOSS : 20739.041015625\n",
      "- TEST MSE LOSS : 510.702392578125\n",
      "- TEST R2 SCORE : 0.9144130945205688\n",
      "성능 및 손실 개선이 없어서 162 EPOCH에 학습 중단\n",
      "pre_val : [102.10604858398438, 66.77996063232422, 237.73974609375, 249.0436553955078, 1.4398543498828076e-05, 73.63365173339844, 205.10763549804688, 55.6873893737793, 227.1992645263672, 110.39153289794922]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[163 / 1000]\n",
      "- TRAIN MAE LOSS : 7.188210108296855\n",
      "- TRAIN MAPE LOSS : 0.6242203820163345\n",
      "- TRAIN MSE LOSS : 255.70028908042642\n",
      "- TRAIN R2 SCORE : 0.9550974826879435\n",
      "\n",
      "- TEST MAE LOSS : 9.205531120300293\n",
      "- TEST MAPE LOSS : 20744.306640625\n",
      "- TEST MSE LOSS : 510.6717529296875\n",
      "- TEST R2 SCORE : 0.9144182205200195\n",
      "성능 및 손실 개선이 없어서 163 EPOCH에 학습 중단\n",
      "pre_val : [102.19246673583984, 66.71571350097656, 237.7337646484375, 249.08392333984375, 8.189474101527594e-06, 73.6334457397461, 205.1136932373047, 55.674320220947266, 227.2222442626953, 110.39369201660156]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[164 / 1000]\n",
      "- TRAIN MAE LOSS : 7.187301363311447\n",
      "- TRAIN MAPE LOSS : 1.104043646582461\n",
      "- TRAIN MSE LOSS : 255.66051701632412\n",
      "- TRAIN R2 SCORE : 0.9551046496171217\n",
      "\n",
      "- TEST MAE LOSS : 9.204168319702148\n",
      "- TEST MAPE LOSS : 20749.701171875\n",
      "- TEST MSE LOSS : 510.61688232421875\n",
      "- TEST R2 SCORE : 0.9144273996353149\n",
      "성능 및 손실 개선이 없어서 164 EPOCH에 학습 중단\n",
      "pre_val : [102.09822082519531, 66.86824798583984, 237.70205688476562, 248.96652221679688, 2.6754945793072693e-05, 73.66778564453125, 205.09014892578125, 55.664005279541016, 227.17955017089844, 110.39207458496094]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[165 / 1000]\n",
      "- TRAIN MAE LOSS : 7.186172273209045\n",
      "- TRAIN MAPE LOSS : 0.8898742465362265\n",
      "- TRAIN MSE LOSS : 255.60695028985296\n",
      "- TRAIN R2 SCORE : 0.9551144374333895\n",
      "\n",
      "- TEST MAE LOSS : 9.20452880859375\n",
      "- TEST MAPE LOSS : 20751.25\n",
      "- TEST MSE LOSS : 510.6354675292969\n",
      "- TEST R2 SCORE : 0.9144243001937866\n",
      "성능 및 손실 개선이 없어서 165 EPOCH에 학습 중단\n",
      "pre_val : [102.14030456542969, 66.79297637939453, 237.69509887695312, 249.0373992919922, 1.7690492768451804e-06, 73.62464904785156, 205.09542846679688, 55.6842041015625, 227.22215270996094, 110.39171600341797]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[166 / 1000]\n",
      "- TRAIN MAE LOSS : 7.185857746017563\n",
      "- TRAIN MAPE LOSS : 0.8042219197796984\n",
      "- TRAIN MSE LOSS : 255.57350791130867\n",
      "- TRAIN R2 SCORE : 0.9551203267724364\n",
      "\n",
      "- TEST MAE LOSS : 9.20409870147705\n",
      "- TEST MAPE LOSS : 20755.03125\n",
      "- TEST MSE LOSS : 510.593994140625\n",
      "- TEST R2 SCORE : 0.9144312143325806\n",
      "성능 및 손실 개선이 없어서 166 EPOCH에 학습 중단\n",
      "pre_val : [102.08753204345703, 66.88607788085938, 237.66000366210938, 248.9399871826172, 8.705441359779797e-06, 73.67461395263672, 205.07342529296875, 55.67315673828125, 227.1916046142578, 110.39159393310547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[167 / 1000]\n",
      "- TRAIN MAE LOSS : 7.185501638025671\n",
      "- TRAIN MAPE LOSS : 1.172799757751864\n",
      "- TRAIN MSE LOSS : 255.53054661197262\n",
      "- TRAIN R2 SCORE : 0.9551280586035935\n",
      "\n",
      "- TEST MAE LOSS : 9.20468521118164\n",
      "- TEST MAPE LOSS : 20750.736328125\n",
      "- TEST MSE LOSS : 510.6261291503906\n",
      "- TEST R2 SCORE : 0.9144258499145508\n",
      "성능 및 손실 개선이 없어서 167 EPOCH에 학습 중단\n",
      "pre_val : [102.09493255615234, 66.88536071777344, 237.6127471923828, 248.95339965820312, 1.108142350858543e-05, 73.598876953125, 205.036865234375, 55.700130462646484, 227.1738739013672, 110.3792724609375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[168 / 1000]\n",
      "- TRAIN MAE LOSS : 7.184629457180317\n",
      "- TRAIN MAPE LOSS : 0.9335768217525698\n",
      "- TRAIN MSE LOSS : 255.48328067326045\n",
      "- TRAIN R2 SCORE : 0.9551363329120449\n",
      "\n",
      "- TEST MAE LOSS : 9.204023361206055\n",
      "- TEST MAPE LOSS : 20754.623046875\n",
      "- TEST MSE LOSS : 510.5991516113281\n",
      "- TEST R2 SCORE : 0.9144303798675537\n",
      "성능 및 손실 개선이 없어서 168 EPOCH에 학습 중단\n",
      "pre_val : [102.15445709228516, 66.9515380859375, 237.64004516601562, 248.9557647705078, 3.618807795646717e-06, 73.65144348144531, 205.06661987304688, 55.69462585449219, 227.21812438964844, 110.40524291992188]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[169 / 1000]\n",
      "- TRAIN MAE LOSS : 7.184061133644797\n",
      "- TRAIN MAPE LOSS : 0.7764068466190484\n",
      "- TRAIN MSE LOSS : 255.44554080989812\n",
      "- TRAIN R2 SCORE : 0.9551432586216426\n",
      "\n",
      "- TEST MAE LOSS : 9.203619003295898\n",
      "- TEST MAPE LOSS : 20764.240234375\n",
      "- TEST MSE LOSS : 510.5941162109375\n",
      "- TEST R2 SCORE : 0.9144312143325806\n",
      "성능 및 손실 개선이 없어서 169 EPOCH에 학습 중단\n",
      "pre_val : [102.05914306640625, 66.92814636230469, 237.5861358642578, 248.93333435058594, 1.1382996490283404e-05, 73.60649871826172, 205.04815673828125, 55.71636962890625, 227.1780548095703, 110.37779235839844]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[170 / 1000]\n",
      "- TRAIN MAE LOSS : 7.182706521907886\n",
      "- TRAIN MAPE LOSS : 1.3701386608475155\n",
      "- TRAIN MSE LOSS : 255.39852215053318\n",
      "- TRAIN R2 SCORE : 0.9551515538709147\n",
      "\n",
      "- TEST MAE LOSS : 9.20326042175293\n",
      "- TEST MAPE LOSS : 20757.8984375\n",
      "- TEST MSE LOSS : 510.5741271972656\n",
      "- TEST R2 SCORE : 0.914434552192688\n",
      "성능 및 손실 개선이 없어서 170 EPOCH에 학습 중단\n",
      "pre_val : [102.00691223144531, 66.9935302734375, 237.57345581054688, 248.89146423339844, -1.6929689081734978e-06, 73.65888214111328, 205.03726196289062, 55.681297302246094, 227.1670684814453, 110.3976058959961]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[171 / 1000]\n",
      "- TRAIN MAE LOSS : 7.182635718325635\n",
      "- TRAIN MAPE LOSS : 0.49807587136911763\n",
      "- TRAIN MSE LOSS : 255.36040287417964\n",
      "- TRAIN R2 SCORE : 0.9551588956959598\n",
      "\n",
      "- TEST MAE LOSS : 9.203997611999512\n",
      "- TEST MAPE LOSS : 20761.126953125\n",
      "- TEST MSE LOSS : 510.62811279296875\n",
      "- TEST R2 SCORE : 0.9144254922866821\n",
      "성능 및 손실 개선이 없어서 171 EPOCH에 학습 중단\n",
      "pre_val : [102.0999526977539, 66.96190643310547, 237.60501098632812, 248.967529296875, 8.74690795171773e-06, 73.6226806640625, 205.06219482421875, 55.70784378051758, 227.18849182128906, 110.40215301513672]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[172 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1819531059932045\n",
      "- TRAIN MAPE LOSS : 1.0910397415576907\n",
      "- TRAIN MSE LOSS : 255.33190545142114\n",
      "- TRAIN R2 SCORE : 0.9551635557788235\n",
      "\n",
      "- TEST MAE LOSS : 9.202316284179688\n",
      "- TEST MAPE LOSS : 20769.93359375\n",
      "- TEST MSE LOSS : 510.5462341308594\n",
      "- TEST R2 SCORE : 0.9144392609596252\n",
      "성능 및 손실 개선이 없어서 172 EPOCH에 학습 중단\n",
      "pre_val : [101.96685791015625, 66.9184341430664, 237.53900146484375, 248.89883422851562, -9.431704484086367e-08, 73.6848373413086, 205.08126831054688, 55.688812255859375, 227.1790313720703, 110.38899993896484]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[173 / 1000]\n",
      "- TRAIN MAE LOSS : 7.181983040362805\n",
      "- TRAIN MAPE LOSS : 0.967148462991406\n",
      "- TRAIN MSE LOSS : 255.29297746831722\n",
      "- TRAIN R2 SCORE : 0.955170567935997\n",
      "\n",
      "- TEST MAE LOSS : 9.204106330871582\n",
      "- TEST MAPE LOSS : 20764.734375\n",
      "- TEST MSE LOSS : 510.62371826171875\n",
      "- TEST R2 SCORE : 0.9144262671470642\n",
      "성능 및 손실 개선이 없어서 173 EPOCH에 학습 중단\n",
      "pre_val : [102.08184051513672, 67.03580474853516, 237.57679748535156, 248.92849731445312, 8.792498192633502e-06, 73.59933471679688, 205.04171752929688, 55.70616912841797, 227.19061279296875, 110.39140319824219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[174 / 1000]\n",
      "- TRAIN MAE LOSS : 7.180702833362393\n",
      "- TRAIN MAPE LOSS : 0.7623635996091408\n",
      "- TRAIN MSE LOSS : 255.2671170945601\n",
      "- TRAIN R2 SCORE : 0.9551752916249362\n",
      "\n",
      "- TEST MAE LOSS : 9.201421737670898\n",
      "- TEST MAPE LOSS : 20775.328125\n",
      "- TEST MSE LOSS : 510.5169982910156\n",
      "- TEST R2 SCORE : 0.9144441485404968\n",
      "성능 및 손실 개선이 없어서 174 EPOCH에 학습 중단\n",
      "pre_val : [101.95287322998047, 66.95240783691406, 237.53599548339844, 248.87950134277344, -8.3376799011603e-06, 73.6873779296875, 205.0778045654297, 55.70013427734375, 227.16812133789062, 110.3943099975586]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[175 / 1000]\n",
      "- TRAIN MAE LOSS : 7.180546325270113\n",
      "- TRAIN MAPE LOSS : 1.3843716522373937\n",
      "- TRAIN MSE LOSS : 255.22989255464995\n",
      "- TRAIN R2 SCORE : 0.9551817556694671\n",
      "\n",
      "- TEST MAE LOSS : 9.20291805267334\n",
      "- TEST MAPE LOSS : 20768.970703125\n",
      "- TEST MSE LOSS : 510.5733642578125\n",
      "- TEST R2 SCORE : 0.9144346714019775\n",
      "성능 및 손실 개선이 없어서 175 EPOCH에 학습 중단\n",
      "pre_val : [101.90286254882812, 67.15750885009766, 237.51771545410156, 248.87606811523438, 1.8221251593786292e-05, 73.624267578125, 205.0323944091797, 55.74614715576172, 227.15728759765625, 110.36727142333984]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[176 / 1000]\n",
      "- TRAIN MAE LOSS : 7.179816006747159\n",
      "- TRAIN MAPE LOSS : 1.0904694677034874\n",
      "- TRAIN MSE LOSS : 255.19639025388065\n",
      "- TRAIN R2 SCORE : 0.9551877751050295\n",
      "\n",
      "- TEST MAE LOSS : 9.203067779541016\n",
      "- TEST MAPE LOSS : 20773.322265625\n",
      "- TEST MSE LOSS : 510.60357666015625\n",
      "- TEST R2 SCORE : 0.9144296050071716\n",
      "성능 및 손실 개선이 없어서 176 EPOCH에 학습 중단\n",
      "pre_val : [102.01371002197266, 67.02718353271484, 237.56243896484375, 248.92083740234375, 1.337755406893848e-06, 73.68797302246094, 205.11285400390625, 55.69638442993164, 227.1902313232422, 110.39559936523438]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[177 / 1000]\n",
      "- TRAIN MAE LOSS : 7.179717702598839\n",
      "- TRAIN MAPE LOSS : 0.6203398145255926\n",
      "- TRAIN MSE LOSS : 255.17846189325505\n",
      "- TRAIN R2 SCORE : 0.955191082004067\n",
      "\n",
      "- TEST MAE LOSS : 9.20140552520752\n",
      "- TEST MAPE LOSS : 20784.55859375\n",
      "- TEST MSE LOSS : 510.5248107910156\n",
      "- TEST R2 SCORE : 0.9144428372383118\n",
      "성능 및 손실 개선이 없어서 177 EPOCH에 학습 중단\n",
      "pre_val : [101.93629455566406, 67.19115447998047, 237.50286865234375, 248.84486389160156, 1.7675201888778247e-05, 73.62031555175781, 205.04635620117188, 55.74681091308594, 227.15460205078125, 110.37149047851562]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[178 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1784282530937995\n",
      "- TRAIN MAPE LOSS : 1.3877495855249309\n",
      "- TRAIN MSE LOSS : 255.12932467907459\n",
      "- TRAIN R2 SCORE : 0.9551995032650608\n",
      "\n",
      "- TEST MAE LOSS : 9.202025413513184\n",
      "- TEST MAPE LOSS : 20784.787109375\n",
      "- TEST MSE LOSS : 510.5476989746094\n",
      "- TEST R2 SCORE : 0.9144389629364014\n",
      "성능 및 손실 개선이 없어서 178 EPOCH에 학습 중단\n",
      "pre_val : [101.86859130859375, 67.08412170410156, 237.4932403564453, 248.83082580566406, 1.7728229067870416e-05, 73.65824127197266, 205.050048828125, 55.715538024902344, 227.1667938232422, 110.38783264160156]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[179 / 1000]\n",
      "- TRAIN MAE LOSS : 7.178432340421876\n",
      "- TRAIN MAPE LOSS : 0.72878161151926\n",
      "- TRAIN MSE LOSS : 255.11139575451404\n",
      "- TRAIN R2 SCORE : 0.9552028676179739\n",
      "\n",
      "- TEST MAE LOSS : 9.201615333557129\n",
      "- TEST MAPE LOSS : 20782.16015625\n",
      "- TEST MSE LOSS : 510.56414794921875\n",
      "- TEST R2 SCORE : 0.9144362211227417\n",
      "성능 및 손실 개선이 없어서 179 EPOCH에 학습 중단\n",
      "pre_val : [102.0035171508789, 67.21063995361328, 237.5177001953125, 248.89767456054688, 4.941016868542647e-06, 73.59151458740234, 205.0601806640625, 55.742271423339844, 227.18612670898438, 110.37853240966797]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[180 / 1000]\n",
      "- TRAIN MAE LOSS : 7.177265539969597\n",
      "- TRAIN MAPE LOSS : 0.8502076609953717\n",
      "- TRAIN MSE LOSS : 255.07616988388807\n",
      "- TRAIN R2 SCORE : 0.9552090212015005\n",
      "\n",
      "- TEST MAE LOSS : 9.201031684875488\n",
      "- TEST MAPE LOSS : 20788.544921875\n",
      "- TEST MSE LOSS : 510.5578308105469\n",
      "- TEST R2 SCORE : 0.9144372940063477\n",
      "성능 및 손실 개선이 없어서 180 EPOCH에 학습 중단\n",
      "pre_val : [101.8692855834961, 67.126708984375, 237.48895263671875, 248.83216857910156, 7.619244115630863e-06, 73.6714859008789, 205.06809997558594, 55.72919845581055, 227.164306640625, 110.37418365478516]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[181 / 1000]\n",
      "- TRAIN MAE LOSS : 7.177646964880136\n",
      "- TRAIN MAPE LOSS : 1.263797207647687\n",
      "- TRAIN MSE LOSS : 255.05422790153878\n",
      "- TRAIN R2 SCORE : 0.9552127862810255\n",
      "\n",
      "- TEST MAE LOSS : 9.202119827270508\n",
      "- TEST MAPE LOSS : 20786.677734375\n",
      "- TEST MSE LOSS : 510.58544921875\n",
      "- TEST R2 SCORE : 0.9144326448440552\n",
      "성능 및 손실 개선이 없어서 181 EPOCH에 학습 중단\n",
      "pre_val : [101.9170913696289, 67.18628692626953, 237.46780395507812, 248.84083557128906, 3.1159845548245357e-07, 73.58646392822266, 205.01234436035156, 55.735198974609375, 227.1558837890625, 110.36604309082031]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[182 / 1000]\n",
      "- TRAIN MAE LOSS : 7.176491455931764\n",
      "- TRAIN MAPE LOSS : 0.6969805272184052\n",
      "- TRAIN MSE LOSS : 255.02344777994222\n",
      "- TRAIN R2 SCORE : 0.9552182290770791\n",
      "\n",
      "- TEST MAE LOSS : 9.200318336486816\n",
      "- TEST MAPE LOSS : 20795.099609375\n",
      "- TEST MSE LOSS : 510.5199279785156\n",
      "- TEST R2 SCORE : 0.9144436120986938\n",
      "성능 및 손실 개선이 없어서 182 EPOCH에 학습 중단\n",
      "pre_val : [101.98031616210938, 67.1705322265625, 237.52301025390625, 248.88551330566406, 1.4591651051887311e-05, 73.67378997802734, 205.0762481689453, 55.707733154296875, 227.19046020507812, 110.39630889892578]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[183 / 1000]\n",
      "- TRAIN MAE LOSS : 7.176655161997655\n",
      "- TRAIN MAPE LOSS : 1.0231489387107688\n",
      "- TRAIN MSE LOSS : 254.99751879765438\n",
      "- TRAIN R2 SCORE : 0.9552228525801972\n",
      "\n",
      "- TEST MAE LOSS : 9.20108699798584\n",
      "- TEST MAPE LOSS : 20795.333984375\n",
      "- TEST MSE LOSS : 510.539794921875\n",
      "- TEST R2 SCORE : 0.9144403338432312\n",
      "성능 및 손실 개선이 없어서 183 EPOCH에 학습 중단\n",
      "pre_val : [101.9197006225586, 67.2761001586914, 237.45816040039062, 248.82923889160156, 2.304030567756854e-05, 73.58875274658203, 205.03562927246094, 55.74333190917969, 227.1634979248047, 110.36454772949219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[184 / 1000]\n",
      "- TRAIN MAE LOSS : 7.175336515786764\n",
      "- TRAIN MAPE LOSS : 1.0073883781457071\n",
      "- TRAIN MSE LOSS : 254.96057825848771\n",
      "- TRAIN R2 SCORE : 0.9552295314515388\n",
      "\n",
      "- TEST MAE LOSS : 9.20036792755127\n",
      "- TEST MAPE LOSS : 20803.58203125\n",
      "- TEST MSE LOSS : 510.51641845703125\n",
      "- TEST R2 SCORE : 0.9144442081451416\n",
      "성능 및 손실 개선이 없어서 184 EPOCH에 학습 중단\n",
      "pre_val : [102.02647399902344, 67.26290130615234, 237.5106658935547, 248.830810546875, -3.203914729965618e-06, 73.67166137695312, 205.0581817626953, 55.731483459472656, 227.1746826171875, 110.38948059082031]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[185 / 1000]\n",
      "- TRAIN MAE LOSS : 7.176213572575496\n",
      "- TRAIN MAPE LOSS : 0.7274601872041301\n",
      "- TRAIN MSE LOSS : 254.94410136883076\n",
      "- TRAIN R2 SCORE : 0.9552322179120737\n",
      "\n",
      "- TEST MAE LOSS : 9.201661109924316\n",
      "- TEST MAPE LOSS : 20798.177734375\n",
      "- TEST MSE LOSS : 510.575439453125\n",
      "- TEST R2 SCORE : 0.9144343137741089\n",
      "성능 및 손실 개선이 없어서 185 EPOCH에 학습 중단\n",
      "pre_val : [101.94967651367188, 67.28145599365234, 237.4637451171875, 248.79971313476562, 1.5034418083814671e-06, 73.57282257080078, 205.0491485595703, 55.7457160949707, 227.1739044189453, 110.3685531616211]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[186 / 1000]\n",
      "- TRAIN MAE LOSS : 7.174738718379627\n",
      "- TRAIN MAPE LOSS : 1.26397191885468\n",
      "- TRAIN MSE LOSS : 254.90884070443107\n",
      "- TRAIN R2 SCORE : 0.9552386279206176\n",
      "\n",
      "- TEST MAE LOSS : 9.199474334716797\n",
      "- TEST MAPE LOSS : 20816.91796875\n",
      "- TEST MSE LOSS : 510.4915466308594\n",
      "- TEST R2 SCORE : 0.9144483804702759\n",
      "성능 및 손실 개선이 없어서 186 EPOCH에 학습 중단\n",
      "pre_val : [101.85387420654297, 67.27149963378906, 237.44094848632812, 248.7911376953125, 1.7154721717815846e-05, 73.67842864990234, 205.03652954101562, 55.74784851074219, 227.15286254882812, 110.35575866699219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[187 / 1000]\n",
      "- TRAIN MAE LOSS : 7.175043505688647\n",
      "- TRAIN MAPE LOSS : 1.0270515720864068\n",
      "- TRAIN MSE LOSS : 254.87979699621667\n",
      "- TRAIN R2 SCORE : 0.9552436301091334\n",
      "\n",
      "- TEST MAE LOSS : 9.201689720153809\n",
      "- TEST MAPE LOSS : 20806.033203125\n",
      "- TEST MSE LOSS : 510.58740234375\n",
      "- TEST R2 SCORE : 0.9144323468208313\n",
      "성능 및 손실 개선이 없어서 187 EPOCH에 학습 중단\n",
      "pre_val : [101.98684692382812, 67.3314437866211, 237.50674438476562, 248.82614135742188, 1.3080830285616685e-06, 73.63607025146484, 205.07362365722656, 55.75294876098633, 227.1878204345703, 110.37138366699219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[188 / 1000]\n",
      "- TRAIN MAE LOSS : 7.174066989671934\n",
      "- TRAIN MAPE LOSS : 0.5979752180954585\n",
      "- TRAIN MSE LOSS : 254.86225295220223\n",
      "- TRAIN R2 SCORE : 0.9552470222052994\n",
      "\n",
      "- TEST MAE LOSS : 9.199466705322266\n",
      "- TEST MAPE LOSS : 20822.0390625\n",
      "- TEST MSE LOSS : 510.5380859375\n",
      "- TEST R2 SCORE : 0.9144406318664551\n",
      "성능 및 손실 개선이 없어서 188 EPOCH에 학습 중단\n",
      "pre_val : [101.86566162109375, 67.35368347167969, 237.41139221191406, 248.82186889648438, 1.7369453416904435e-05, 73.6374282836914, 205.06304931640625, 55.754093170166016, 227.15939331054688, 110.34921264648438]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[189 / 1000]\n",
      "- TRAIN MAE LOSS : 7.17384364408213\n",
      "- TRAIN MAPE LOSS : 1.4920731972527879\n",
      "- TRAIN MSE LOSS : 254.82785479032077\n",
      "- TRAIN R2 SCORE : 0.955252786766399\n",
      "\n",
      "- TEST MAE LOSS : 9.20083999633789\n",
      "- TEST MAPE LOSS : 20818.953125\n",
      "- TEST MSE LOSS : 510.5467224121094\n",
      "- TEST R2 SCORE : 0.9144391417503357\n",
      "성능 및 손실 개선이 없어서 189 EPOCH에 학습 중단\n",
      "pre_val : [101.8822021484375, 67.40109252929688, 237.45924377441406, 248.79043579101562, 7.811401701474097e-06, 73.64372253417969, 205.05950927734375, 55.761695861816406, 227.15098571777344, 110.3560791015625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[190 / 1000]\n",
      "- TRAIN MAE LOSS : 7.17372013865651\n",
      "- TRAIN MAPE LOSS : 0.5960513446261207\n",
      "- TRAIN MSE LOSS : 254.80915397964156\n",
      "- TRAIN R2 SCORE : 0.9552564299856866\n",
      "\n",
      "- TEST MAE LOSS : 9.200081825256348\n",
      "- TEST MAPE LOSS : 20822.822265625\n",
      "- TEST MSE LOSS : 510.54376220703125\n",
      "- TEST R2 SCORE : 0.9144396781921387\n",
      "성능 및 손실 개선이 없어서 190 EPOCH에 학습 중단\n",
      "pre_val : [102.00040435791016, 67.34127807617188, 237.47499084472656, 248.84616088867188, -5.747498562413966e-06, 73.65997314453125, 205.08389282226562, 55.728919982910156, 227.18817138671875, 110.34979248046875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[191 / 1000]\n",
      "- TRAIN MAE LOSS : 7.173433574663176\n",
      "- TRAIN MAPE LOSS : 1.1435779317494457\n",
      "- TRAIN MSE LOSS : 254.78408250128473\n",
      "- TRAIN R2 SCORE : 0.9552604752987415\n",
      "\n",
      "- TEST MAE LOSS : 9.20011043548584\n",
      "- TEST MAPE LOSS : 20826.470703125\n",
      "- TEST MSE LOSS : 510.4973449707031\n",
      "- TEST R2 SCORE : 0.9144474267959595\n",
      "성능 및 손실 개선이 없어서 191 EPOCH에 학습 중단\n",
      "pre_val : [101.92935943603516, 67.35917663574219, 237.41928100585938, 248.75877380371094, 9.186636816593818e-06, 73.67390441894531, 205.06861877441406, 55.74971389770508, 227.16693115234375, 110.35711669921875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[192 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1733227829833135\n",
      "- TRAIN MAPE LOSS : 1.0263154643325956\n",
      "- TRAIN MSE LOSS : 254.75153128403883\n",
      "- TRAIN R2 SCORE : 0.9552663362776482\n",
      "\n",
      "- TEST MAE LOSS : 9.201570510864258\n",
      "- TEST MAPE LOSS : 20820.55859375\n",
      "- TEST MSE LOSS : 510.5930480957031\n",
      "- TEST R2 SCORE : 0.9144313931465149\n",
      "성능 및 손실 개선이 없어서 192 EPOCH에 학습 중단\n",
      "pre_val : [101.96760559082031, 67.37920379638672, 237.45777893066406, 248.85372924804688, 1.248801163455937e-05, 73.6173095703125, 205.07008361816406, 55.76772689819336, 227.1796417236328, 110.3371810913086]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[193 / 1000]\n",
      "- TRAIN MAE LOSS : 7.17235603652634\n",
      "- TRAIN MAPE LOSS : 0.8056440064951882\n",
      "- TRAIN MSE LOSS : 254.73258891499125\n",
      "- TRAIN R2 SCORE : 0.9552696869923518\n",
      "\n",
      "- TEST MAE LOSS : 9.198836326599121\n",
      "- TEST MAPE LOSS : 20832.392578125\n",
      "- TEST MSE LOSS : 510.4906921386719\n",
      "- TEST R2 SCORE : 0.9144485592842102\n",
      "성능 및 손실 개선이 없어서 193 EPOCH에 학습 중단\n",
      "pre_val : [102.01876068115234, 67.40953063964844, 237.42788696289062, 248.74658203125, 2.4056384063442238e-05, 73.68112182617188, 205.05905151367188, 55.73628616333008, 227.1610565185547, 110.3421401977539]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[194 / 1000]\n",
      "- TRAIN MAE LOSS : 7.172102365693846\n",
      "- TRAIN MAPE LOSS : 1.3888151489187788\n",
      "- TRAIN MSE LOSS : 254.70514239491283\n",
      "- TRAIN R2 SCORE : 0.9552746251913218\n",
      "\n",
      "- TEST MAE LOSS : 9.201382637023926\n",
      "- TEST MAPE LOSS : 20824.240234375\n",
      "- TEST MSE LOSS : 510.5957946777344\n",
      "- TEST R2 SCORE : 0.9144309163093567\n",
      "성능 및 손실 개선이 없어서 194 EPOCH에 학습 중단\n",
      "pre_val : [101.93133544921875, 67.4014892578125, 237.40542602539062, 248.7829132080078, 1.8783977793646045e-05, 73.63545989990234, 205.05337524414062, 55.763004302978516, 227.14942932128906, 110.32511138916016]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[195 / 1000]\n",
      "- TRAIN MAE LOSS : 7.172371382946735\n",
      "- TRAIN MAPE LOSS : 1.0111623037174031\n",
      "- TRAIN MSE LOSS : 254.68302041647317\n",
      "- TRAIN R2 SCORE : 0.9552784529265824\n",
      "\n",
      "- TEST MAE LOSS : 9.199261665344238\n",
      "- TEST MAPE LOSS : 20845.515625\n",
      "- TEST MSE LOSS : 510.491943359375\n",
      "- TEST R2 SCORE : 0.9144483208656311\n",
      "성능 및 손실 개선이 없어서 195 EPOCH에 학습 중단\n",
      "pre_val : [102.07415771484375, 67.48184967041016, 237.4793701171875, 248.8135223388672, 9.584669896867126e-06, 73.66754150390625, 205.0892791748047, 55.75865936279297, 227.17417907714844, 110.34738159179688]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[196 / 1000]\n",
      "- TRAIN MAE LOSS : 7.171637287273273\n",
      "- TRAIN MAPE LOSS : 0.6966080942947964\n",
      "- TRAIN MSE LOSS : 254.65550321725698\n",
      "- TRAIN R2 SCORE : 0.9552833881578245\n",
      "\n",
      "- TEST MAE LOSS : 9.201095581054688\n",
      "- TEST MAPE LOSS : 20831.5859375\n",
      "- TEST MSE LOSS : 510.5813293457031\n",
      "- TEST R2 SCORE : 0.9144333600997925\n",
      "성능 및 손실 개선이 없어서 196 EPOCH에 학습 중단\n",
      "pre_val : [101.9648666381836, 67.47393035888672, 237.4266357421875, 248.7755889892578, 9.008191227621865e-06, 73.63335418701172, 205.07278442382812, 55.8043212890625, 227.15135192871094, 110.32848358154297]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[197 / 1000]\n",
      "- TRAIN MAE LOSS : 7.171436698753517\n",
      "- TRAIN MAPE LOSS : 1.367459065167533\n",
      "- TRAIN MSE LOSS : 254.6373680642935\n",
      "- TRAIN R2 SCORE : 0.955286502021176\n",
      "\n",
      "- TEST MAE LOSS : 9.199834823608398\n",
      "- TEST MAPE LOSS : 20845.158203125\n",
      "- TEST MSE LOSS : 510.5377502441406\n",
      "- TEST R2 SCORE : 0.9144406318664551\n",
      "성능 및 손실 개선이 없어서 197 EPOCH에 학습 중단\n",
      "pre_val : [101.97634887695312, 67.46637725830078, 237.45175170898438, 248.80039978027344, 9.718995897856075e-06, 73.6334457397461, 205.07284545898438, 55.79676818847656, 227.15609741210938, 110.333984375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[198 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170496478447547\n",
      "- TRAIN MAPE LOSS : 0.5648339437781931\n",
      "- TRAIN MSE LOSS : 254.4978330214707\n",
      "- TRAIN R2 SCORE : 0.9553111151381806\n",
      "\n",
      "- TEST MAE LOSS : 9.199311256408691\n",
      "- TEST MAPE LOSS : 20846.60546875\n",
      "- TEST MSE LOSS : 510.50335693359375\n",
      "- TEST R2 SCORE : 0.9144464135169983\n",
      "성능 및 손실 개선이 없어서 198 EPOCH에 학습 중단\n",
      "pre_val : [101.99392700195312, 67.45953369140625, 237.4766082763672, 248.82501220703125, 8.295577572425827e-06, 73.63552856445312, 205.0761260986328, 55.78733825683594, 227.1620330810547, 110.33760070800781]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[199 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170122660990361\n",
      "- TRAIN MAPE LOSS : 0.5667597299272363\n",
      "- TRAIN MSE LOSS : 254.49003168492885\n",
      "- TRAIN R2 SCORE : 0.9553125032344898\n",
      "\n",
      "- TEST MAE LOSS : 9.198737144470215\n",
      "- TEST MAPE LOSS : 20848.228515625\n",
      "- TEST MSE LOSS : 510.467529296875\n",
      "- TEST R2 SCORE : 0.9144524335861206\n",
      "성능 및 손실 개선이 없어서 199 EPOCH에 학습 중단\n",
      "pre_val : [101.98656463623047, 67.43881225585938, 237.4860076904297, 248.83432006835938, 8.539823284081649e-06, 73.63356018066406, 205.07470703125, 55.77781677246094, 227.1645965576172, 110.34031677246094]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[200 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16973776330481\n",
      "- TRAIN MAPE LOSS : 0.49770542727171124\n",
      "- TRAIN MSE LOSS : 254.48208793586784\n",
      "- TRAIN R2 SCORE : 0.9553138847784562\n",
      "\n",
      "- TEST MAE LOSS : 9.198339462280273\n",
      "- TEST MAPE LOSS : 20848.998046875\n",
      "- TEST MSE LOSS : 510.4446716308594\n",
      "- TEST R2 SCORE : 0.9144562482833862\n",
      "성능 및 손실 개선이 없어서 200 EPOCH에 학습 중단\n",
      "pre_val : [101.99498748779297, 67.4231185913086, 237.49671936035156, 248.84339904785156, 9.835905075306073e-06, 73.63054656982422, 205.0769805908203, 55.77330780029297, 227.1699981689453, 110.34392547607422]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[201 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169472852920319\n",
      "- TRAIN MAPE LOSS : 0.44404423109145014\n",
      "- TRAIN MSE LOSS : 254.4769999444068\n",
      "- TRAIN R2 SCORE : 0.9553147641428701\n",
      "\n",
      "- TEST MAE LOSS : 9.19791316986084\n",
      "- TEST MAPE LOSS : 20850.486328125\n",
      "- TEST MSE LOSS : 510.4197998046875\n",
      "- TEST R2 SCORE : 0.9144604206085205\n",
      "성능 및 손실 개선이 없어서 201 EPOCH에 학습 중단\n",
      "pre_val : [101.98995971679688, 67.4095687866211, 237.5061492919922, 248.8524627685547, 1.0820055649674032e-05, 73.63005828857422, 205.07376098632812, 55.767032623291016, 227.17015075683594, 110.34658813476562]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[202 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169213043559681\n",
      "- TRAIN MAPE LOSS : 0.4422442620898877\n",
      "- TRAIN MSE LOSS : 254.47078064445014\n",
      "- TRAIN R2 SCORE : 0.9553158424284075\n",
      "\n",
      "- TEST MAE LOSS : 9.1975679397583\n",
      "- TEST MAPE LOSS : 20851.392578125\n",
      "- TEST MSE LOSS : 510.3975524902344\n",
      "- TEST R2 SCORE : 0.9144641757011414\n",
      "성능 및 손실 개선이 없어서 202 EPOCH에 학습 중단\n",
      "pre_val : [101.98324584960938, 67.41544342041016, 237.50437927246094, 248.84515380859375, 8.62963315739762e-06, 73.62507629394531, 205.0685272216797, 55.76234817504883, 227.1709747314453, 110.34668731689453]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[203 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168937536986558\n",
      "- TRAIN MAPE LOSS : 0.3760028448914523\n",
      "- TRAIN MSE LOSS : 254.46500502312935\n",
      "- TRAIN R2 SCORE : 0.9553168750142718\n",
      "\n",
      "- TEST MAE LOSS : 9.197335243225098\n",
      "- TEST MAPE LOSS : 20852.59765625\n",
      "- TEST MSE LOSS : 510.3860778808594\n",
      "- TEST R2 SCORE : 0.9144660830497742\n",
      "성능 및 손실 개선이 없어서 203 EPOCH에 학습 중단\n",
      "pre_val : [101.98538970947266, 67.40345001220703, 237.5147247314453, 248.86004638671875, 8.52833818498766e-06, 73.62346649169922, 205.0759735107422, 55.76309585571289, 227.1777801513672, 110.35265350341797]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[204 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168871632555982\n",
      "- TRAIN MAPE LOSS : 0.40523759264472897\n",
      "- TRAIN MSE LOSS : 254.4616697959633\n",
      "- TRAIN R2 SCORE : 0.9553174318633713\n",
      "\n",
      "- TEST MAE LOSS : 9.197078704833984\n",
      "- TEST MAPE LOSS : 20855.048828125\n",
      "- TEST MSE LOSS : 510.363037109375\n",
      "- TEST R2 SCORE : 0.9144699573516846\n",
      "성능 및 손실 개선이 없어서 204 EPOCH에 학습 중단\n",
      "pre_val : [101.9707260131836, 67.40814208984375, 237.514892578125, 248.85250854492188, 9.340732503915206e-06, 73.61561584472656, 205.0679473876953, 55.76179122924805, 227.1742706298828, 110.34938049316406]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[205 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1686177322414375\n",
      "- TRAIN MAPE LOSS : 0.4047726089522972\n",
      "- TRAIN MSE LOSS : 254.4554635833527\n",
      "- TRAIN R2 SCORE : 0.9553185336406415\n",
      "\n",
      "- TEST MAE LOSS : 9.196833610534668\n",
      "- TEST MAPE LOSS : 20854.875\n",
      "- TEST MSE LOSS : 510.3531799316406\n",
      "- TEST R2 SCORE : 0.9144715666770935\n",
      "성능 및 손실 개선이 없어서 205 EPOCH에 학습 중단\n",
      "pre_val : [101.98018646240234, 67.40019226074219, 237.52418518066406, 248.86647033691406, 1.0213285349891521e-05, 73.6180419921875, 205.0728759765625, 55.755271911621094, 227.17897033691406, 110.35301208496094]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[206 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168571324381795\n",
      "- TRAIN MAPE LOSS : 0.3610466691528584\n",
      "- TRAIN MSE LOSS : 254.45243971711272\n",
      "- TRAIN R2 SCORE : 0.9553190538266322\n",
      "\n",
      "- TEST MAE LOSS : 9.196734428405762\n",
      "- TEST MAPE LOSS : 20855.90234375\n",
      "- TEST MSE LOSS : 510.3366394042969\n",
      "- TEST R2 SCORE : 0.914474368095398\n",
      "성능 및 손실 개선이 없어서 206 EPOCH에 학습 중단\n",
      "pre_val : [101.96499633789062, 67.4046859741211, 237.5230255126953, 248.8619384765625, 9.893323294818401e-06, 73.61520385742188, 205.0675506591797, 55.75423049926758, 227.17596435546875, 110.35160064697266]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[207 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168415000088565\n",
      "- TRAIN MAPE LOSS : 0.4338964523411506\n",
      "- TRAIN MSE LOSS : 254.44742924723593\n",
      "- TRAIN R2 SCORE : 0.9553199546320456\n",
      "\n",
      "- TEST MAE LOSS : 9.196578025817871\n",
      "- TEST MAPE LOSS : 20856.43359375\n",
      "- TEST MSE LOSS : 510.3306579589844\n",
      "- TEST R2 SCORE : 0.9144753813743591\n",
      "성능 및 손실 개선이 없어서 207 EPOCH에 학습 중단\n",
      "pre_val : [101.95552062988281, 67.39116668701172, 237.5187530517578, 248.85415649414062, 1.0110295079357456e-05, 73.61647033691406, 205.06875610351562, 55.752471923828125, 227.17633056640625, 110.35712432861328]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[208 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168422747725374\n",
      "- TRAIN MAPE LOSS : 0.3908986684200647\n",
      "- TRAIN MSE LOSS : 254.44434284023473\n",
      "- TRAIN R2 SCORE : 0.9553204957588569\n",
      "\n",
      "- TEST MAE LOSS : 9.196630477905273\n",
      "- TEST MAPE LOSS : 20857.478515625\n",
      "- TEST MSE LOSS : 510.3238525390625\n",
      "- TEST R2 SCORE : 0.9144765138626099\n",
      "성능 및 손실 개선이 없어서 208 EPOCH에 학습 중단\n",
      "pre_val : [101.95518493652344, 67.39916229248047, 237.52610778808594, 248.8584747314453, 9.613750080461614e-06, 73.6138916015625, 205.0677947998047, 55.74888610839844, 227.1769561767578, 110.3521728515625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[209 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16831587024502\n",
      "- TRAIN MAPE LOSS : 0.3570506297692761\n",
      "- TRAIN MSE LOSS : 254.44035728774705\n",
      "- TRAIN R2 SCORE : 0.9553212179337348\n",
      "\n",
      "- TEST MAE LOSS : 9.19637680053711\n",
      "- TEST MAPE LOSS : 20858.025390625\n",
      "- TEST MSE LOSS : 510.3111267089844\n",
      "- TEST R2 SCORE : 0.9144786596298218\n",
      "성능 및 손실 개선이 없어서 209 EPOCH에 학습 중단\n",
      "pre_val : [101.94222259521484, 67.398193359375, 237.52468872070312, 248.85633850097656, 9.236224286723882e-06, 73.617431640625, 205.0712432861328, 55.750064849853516, 227.1786651611328, 110.35840606689453]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[210 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1682806609227105\n",
      "- TRAIN MAPE LOSS : 0.43070388528642123\n",
      "- TRAIN MSE LOSS : 254.4364409349348\n",
      "- TRAIN R2 SCORE : 0.9553218994607459\n",
      "\n",
      "- TEST MAE LOSS : 9.196434020996094\n",
      "- TEST MAPE LOSS : 20859.314453125\n",
      "- TEST MSE LOSS : 510.30511474609375\n",
      "- TEST R2 SCORE : 0.9144796133041382\n",
      "성능 및 손실 개선이 없어서 210 EPOCH에 학습 중단\n",
      "pre_val : [101.93448638916016, 67.38787841796875, 237.52171325683594, 248.85182189941406, 8.046252332860604e-06, 73.6230697631836, 205.0697021484375, 55.744483947753906, 227.1759490966797, 110.35643768310547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[211 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1683663903083\n",
      "- TRAIN MAPE LOSS : 0.3583654550879777\n",
      "- TRAIN MSE LOSS : 254.43338534855343\n",
      "- TRAIN R2 SCORE : 0.9553224427549989\n",
      "\n",
      "- TEST MAE LOSS : 9.19659423828125\n",
      "- TEST MAPE LOSS : 20858.810546875\n",
      "- TEST MSE LOSS : 510.3077697753906\n",
      "- TEST R2 SCORE : 0.9144791960716248\n",
      "성능 및 손실 개선이 없어서 211 EPOCH에 학습 중단\n",
      "pre_val : [101.93924713134766, 67.40918731689453, 237.53082275390625, 248.8568115234375, 9.444380339118652e-06, 73.62645721435547, 205.07470703125, 55.74519729614258, 227.17860412597656, 110.36213684082031]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[212 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168344063992267\n",
      "- TRAIN MAPE LOSS : 0.3939096550669495\n",
      "- TRAIN MSE LOSS : 254.4299701920089\n",
      "- TRAIN R2 SCORE : 0.9553230452870989\n",
      "\n",
      "- TEST MAE LOSS : 9.196540832519531\n",
      "- TEST MAPE LOSS : 20860.234375\n",
      "- TEST MSE LOSS : 510.30511474609375\n",
      "- TEST R2 SCORE : 0.9144796133041382\n",
      "성능 및 손실 개선이 없어서 212 EPOCH에 학습 중단\n",
      "pre_val : [101.9265365600586, 67.39496612548828, 237.5221710205078, 248.85203552246094, 1.0492102774151135e-05, 73.61919403076172, 205.07080078125, 55.74618148803711, 227.17601013183594, 110.35797882080078]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[213 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168267558771413\n",
      "- TRAIN MAPE LOSS : 0.39810755990497715\n",
      "- TRAIN MSE LOSS : 254.4280381214702\n",
      "- TRAIN R2 SCORE : 0.9553233624838449\n",
      "\n",
      "- TEST MAE LOSS : 9.19637393951416\n",
      "- TEST MAPE LOSS : 20860.16015625\n",
      "- TEST MSE LOSS : 510.29425048828125\n",
      "- TEST R2 SCORE : 0.9144814610481262\n",
      "성능 및 손실 개선이 없어서 213 EPOCH에 학습 중단\n",
      "pre_val : [101.91899108886719, 67.41231536865234, 237.5259552001953, 248.8470001220703, 1.1171810911037028e-05, 73.62490844726562, 205.06846618652344, 55.74413299560547, 227.17434692382812, 110.36138153076172]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[214 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168260281436093\n",
      "- TRAIN MAPE LOSS : 0.36610772300850264\n",
      "- TRAIN MSE LOSS : 254.42301058575825\n",
      "- TRAIN R2 SCORE : 0.955324285480526\n",
      "\n",
      "- TEST MAE LOSS : 9.196537017822266\n",
      "- TEST MAPE LOSS : 20860.240234375\n",
      "- TEST MSE LOSS : 510.2983093261719\n",
      "- TEST R2 SCORE : 0.9144808053970337\n",
      "성능 및 손실 개선이 없어서 214 EPOCH에 학습 중단\n",
      "pre_val : [101.91839599609375, 67.40926361083984, 237.5286102294922, 248.8474884033203, 9.247683919966221e-06, 73.6189193725586, 205.06748962402344, 55.743099212646484, 227.1748504638672, 110.35963439941406]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[215 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1682497663431235\n",
      "- TRAIN MAPE LOSS : 0.37522545088108605\n",
      "- TRAIN MSE LOSS : 254.42249945633895\n",
      "- TRAIN R2 SCORE : 0.955324366759587\n",
      "\n",
      "- TEST MAE LOSS : 9.196295738220215\n",
      "- TEST MAPE LOSS : 20861.328125\n",
      "- TEST MSE LOSS : 510.2880859375\n",
      "- TEST R2 SCORE : 0.9144824743270874\n",
      "성능 및 손실 개선이 없어서 215 EPOCH에 학습 중단\n",
      "pre_val : [101.90950775146484, 67.41584777832031, 237.53155517578125, 248.85125732421875, 1.0148641194973607e-05, 73.62792205810547, 205.0729522705078, 55.74230194091797, 227.1767120361328, 110.3624496459961]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[216 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168220780846123\n",
      "- TRAIN MAPE LOSS : 0.41246147341557315\n",
      "- TRAIN MSE LOSS : 254.41733416097148\n",
      "- TRAIN R2 SCORE : 0.9553252950581638\n",
      "\n",
      "- TEST MAE LOSS : 9.196541786193848\n",
      "- TEST MAPE LOSS : 20862.021484375\n",
      "- TEST MSE LOSS : 510.2914123535156\n",
      "- TEST R2 SCORE : 0.9144819378852844\n",
      "성능 및 손실 개선이 없어서 216 EPOCH에 학습 중단\n",
      "pre_val : [101.9087142944336, 67.39640045166016, 237.53048706054688, 248.8526611328125, 9.641101314628031e-06, 73.62188720703125, 205.07310485839844, 55.74175262451172, 227.1776123046875, 110.36051940917969]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[217 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1682331113882\n",
      "- TRAIN MAPE LOSS : 0.3389376847013518\n",
      "- TRAIN MSE LOSS : 254.41585624268004\n",
      "- TRAIN R2 SCORE : 0.9553255041162451\n",
      "\n",
      "- TEST MAE LOSS : 9.19616413116455\n",
      "- TEST MAPE LOSS : 20861.82421875\n",
      "- TEST MSE LOSS : 510.2746887207031\n",
      "- TEST R2 SCORE : 0.9144847393035889\n",
      "성능 및 손실 개선이 없어서 217 EPOCH에 학습 중단\n",
      "pre_val : [101.89492797851562, 67.4150619506836, 237.53250122070312, 248.8473663330078, 1.0595818821457215e-05, 73.6268539428711, 205.0724639892578, 55.74190902709961, 227.1771697998047, 110.36268615722656]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[218 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168071426978478\n",
      "- TRAIN MAPE LOSS : 0.43739676890256524\n",
      "- TRAIN MSE LOSS : 254.41088687176472\n",
      "- TRAIN R2 SCORE : 0.9553264528554636\n",
      "\n",
      "- TEST MAE LOSS : 9.19646167755127\n",
      "- TEST MAPE LOSS : 20861.76171875\n",
      "- TEST MSE LOSS : 510.2890930175781\n",
      "- TEST R2 SCORE : 0.9144823551177979\n",
      "성능 및 손실 개선이 없어서 218 EPOCH에 학습 중단\n",
      "pre_val : [101.88861846923828, 67.40251159667969, 237.52891540527344, 248.84640502929688, 9.41311736823991e-06, 73.61988067626953, 205.07260131835938, 55.742366790771484, 227.1756134033203, 110.3616714477539]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[219 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168140266391781\n",
      "- TRAIN MAPE LOSS : 0.35625213612470175\n",
      "- TRAIN MSE LOSS : 254.40974775834516\n",
      "- TRAIN R2 SCORE : 0.955326603392621\n",
      "\n",
      "- TEST MAE LOSS : 9.196449279785156\n",
      "- TEST MAPE LOSS : 20862.1171875\n",
      "- TEST MSE LOSS : 510.2852478027344\n",
      "- TEST R2 SCORE : 0.9144829511642456\n",
      "성능 및 손실 개선이 없어서 219 EPOCH에 학습 중단\n",
      "pre_val : [101.89550018310547, 67.42467498779297, 237.53607177734375, 248.85011291503906, 7.806158464518376e-06, 73.62371826171875, 205.07131958007812, 55.73950958251953, 227.1768035888672, 110.36177825927734]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[220 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16810128325349\n",
      "- TRAIN MAPE LOSS : 0.3778004552955394\n",
      "- TRAIN MSE LOSS : 254.4063300515555\n",
      "- TRAIN R2 SCORE : 0.9553272613278636\n",
      "\n",
      "- TEST MAE LOSS : 9.196392059326172\n",
      "- TEST MAPE LOSS : 20862.30078125\n",
      "- TEST MSE LOSS : 510.28387451171875\n",
      "- TEST R2 SCORE : 0.9144831895828247\n",
      "성능 및 손실 개선이 없어서 220 EPOCH에 학습 중단\n",
      "pre_val : [101.89619445800781, 67.42443084716797, 237.5358123779297, 248.85023498535156, 1.820330339796783e-06, 73.6244888305664, 205.07144165039062, 55.73978042602539, 227.1761932373047, 110.36203002929688]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[221 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168130389193555\n",
      "- TRAIN MAPE LOSS : 0.3869260948203452\n",
      "- TRAIN MSE LOSS : 254.39092029438152\n",
      "- TRAIN R2 SCORE : 0.9553299020887255\n",
      "\n",
      "- TEST MAE LOSS : 9.196442604064941\n",
      "- TEST MAPE LOSS : 20862.494140625\n",
      "- TEST MSE LOSS : 510.2832946777344\n",
      "- TEST R2 SCORE : 0.9144833087921143\n",
      "성능 및 손실 개선이 없어서 221 EPOCH에 학습 중단\n",
      "pre_val : [101.89649963378906, 67.42422485351562, 237.535888671875, 248.85055541992188, 1.8308998050997616e-06, 73.62519836425781, 205.07171630859375, 55.74016189575195, 227.1756134033203, 110.36216735839844]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[222 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168171958056363\n",
      "- TRAIN MAPE LOSS : 0.37520211814375193\n",
      "- TRAIN MSE LOSS : 254.39053550293394\n",
      "- TRAIN R2 SCORE : 0.9553299724805605\n",
      "\n",
      "- TEST MAE LOSS : 9.196483612060547\n",
      "- TEST MAPE LOSS : 20862.677734375\n",
      "- TEST MSE LOSS : 510.2823791503906\n",
      "- TEST R2 SCORE : 0.9144834280014038\n",
      "성능 및 손실 개선이 없어서 222 EPOCH에 학습 중단\n",
      "pre_val : [101.89741516113281, 67.42379760742188, 237.5357208251953, 248.85079956054688, 1.8131172510038596e-06, 73.62567138671875, 205.07162475585938, 55.74044418334961, 227.17489624023438, 110.36207580566406]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[223 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168209011371319\n",
      "- TRAIN MAPE LOSS : 0.3650036869922301\n",
      "- TRAIN MSE LOSS : 254.39016219932716\n",
      "- TRAIN R2 SCORE : 0.9553300404548645\n",
      "\n",
      "- TEST MAE LOSS : 9.196516990661621\n",
      "- TEST MAPE LOSS : 20862.845703125\n",
      "- TEST MSE LOSS : 510.2813415527344\n",
      "- TEST R2 SCORE : 0.9144836068153381\n",
      "성능 및 손실 개선이 없어서 223 EPOCH에 학습 중단\n",
      "pre_val : [101.8984375, 67.42471313476562, 237.53579711914062, 248.85081481933594, 1.731681322780787e-06, 73.62611389160156, 205.0713653564453, 55.74057388305664, 227.17404174804688, 110.36193084716797]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[224 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1682378142030085\n",
      "- TRAIN MAPE LOSS : 0.3570366117847966\n",
      "- TRAIN MSE LOSS : 254.3896850687307\n",
      "- TRAIN R2 SCORE : 0.9553301287531019\n",
      "\n",
      "- TEST MAE LOSS : 9.196541786193848\n",
      "- TEST MAPE LOSS : 20863.060546875\n",
      "- TEST MSE LOSS : 510.27984619140625\n",
      "- TEST R2 SCORE : 0.914483904838562\n",
      "성능 및 손실 개선이 없어서 224 EPOCH에 학습 중단\n",
      "pre_val : [101.89856719970703, 67.42611694335938, 237.5359649658203, 248.85092163085938, 1.841547373260255e-06, 73.62692260742188, 205.0709228515625, 55.74087142944336, 227.173095703125, 110.36193084716797]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[225 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168276955931336\n",
      "- TRAIN MAPE LOSS : 0.3491948905774763\n",
      "- TRAIN MSE LOSS : 254.3892151759221\n",
      "- TRAIN R2 SCORE : 0.9553302121662594\n",
      "\n",
      "- TEST MAE LOSS : 9.196603775024414\n",
      "- TEST MAPE LOSS : 20863.091796875\n",
      "- TEST MSE LOSS : 510.2804870605469\n",
      "- TEST R2 SCORE : 0.9144837856292725\n",
      "성능 및 손실 개선이 없어서 225 EPOCH에 학습 중단\n",
      "pre_val : [101.8995132446289, 67.42750549316406, 237.5366668701172, 248.8512725830078, 1.8711165239437832e-06, 73.62703704833984, 205.07044982910156, 55.741310119628906, 227.17233276367188, 110.36188507080078]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[226 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168316918819935\n",
      "- TRAIN MAPE LOSS : 0.34392808023188914\n",
      "- TRAIN MSE LOSS : 254.3889287865912\n",
      "- TRAIN R2 SCORE : 0.9553302654853234\n",
      "\n",
      "- TEST MAE LOSS : 9.196624755859375\n",
      "- TEST MAPE LOSS : 20863.294921875\n",
      "- TEST MSE LOSS : 510.2790222167969\n",
      "- TEST R2 SCORE : 0.9144840240478516\n",
      "성능 및 손실 개선이 없어서 226 EPOCH에 학습 중단\n",
      "pre_val : [101.8989028930664, 67.42818450927734, 237.5357666015625, 248.85049438476562, 1.8403138710709754e-06, 73.6283187866211, 205.07012939453125, 55.74119567871094, 227.17156982421875, 110.36194610595703]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[227 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168362145123782\n",
      "- TRAIN MAPE LOSS : 0.3361594027317279\n",
      "- TRAIN MSE LOSS : 254.38854264906237\n",
      "- TRAIN R2 SCORE : 0.9553303372443139\n",
      "\n",
      "- TEST MAE LOSS : 9.196695327758789\n",
      "- TEST MAPE LOSS : 20863.341796875\n",
      "- TEST MSE LOSS : 510.2799377441406\n",
      "- TEST R2 SCORE : 0.9144838452339172\n",
      "성능 및 손실 개선이 없어서 227 EPOCH에 학습 중단\n",
      "pre_val : [101.89959716796875, 67.42957305908203, 237.53582763671875, 248.8499755859375, 1.7279203348152805e-06, 73.62808227539062, 205.0692138671875, 55.741371154785156, 227.17050170898438, 110.36151885986328]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[228 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168398558076445\n",
      "- TRAIN MAPE LOSS : 0.3324161414171641\n",
      "- TRAIN MSE LOSS : 254.38820207822573\n",
      "- TRAIN R2 SCORE : 0.9553303985328941\n",
      "\n",
      "- TEST MAE LOSS : 9.196724891662598\n",
      "- TEST MAPE LOSS : 20863.40234375\n",
      "- TEST MSE LOSS : 510.2790832519531\n",
      "- TEST R2 SCORE : 0.9144840240478516\n",
      "성능 및 손실 개선이 없어서 228 EPOCH에 학습 중단\n",
      "pre_val : [101.89989471435547, 67.43231964111328, 237.5358428955078, 248.8498077392578, 1.7015883031490375e-06, 73.6294174194336, 205.0687713623047, 55.741546630859375, 227.16986083984375, 110.36197662353516]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[229 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168444985676478\n",
      "- TRAIN MAPE LOSS : 0.3249986502543821\n",
      "- TRAIN MSE LOSS : 254.38789892663488\n",
      "- TRAIN R2 SCORE : 0.9553304575706696\n",
      "\n",
      "- TEST MAE LOSS : 9.19678783416748\n",
      "- TEST MAPE LOSS : 20863.494140625\n",
      "- TEST MSE LOSS : 510.27984619140625\n",
      "- TEST R2 SCORE : 0.914483904838562\n",
      "성능 및 손실 개선이 없어서 229 EPOCH에 학습 중단\n",
      "pre_val : [101.89979553222656, 67.43212127685547, 237.53582763671875, 248.84988403320312, 1.833537339734903e-06, 73.63024139404297, 205.0684814453125, 55.74131393432617, 227.16903686523438, 110.36198425292969]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[230 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168488742921736\n",
      "- TRAIN MAPE LOSS : 0.32056832590251116\n",
      "- TRAIN MSE LOSS : 254.38753015958346\n",
      "- TRAIN R2 SCORE : 0.9553305209933461\n",
      "\n",
      "- TEST MAE LOSS : 9.196834564208984\n",
      "- TEST MAPE LOSS : 20863.640625\n",
      "- TEST MSE LOSS : 510.27996826171875\n",
      "- TEST R2 SCORE : 0.9144838452339172\n",
      "성능 및 손실 개선이 없어서 230 EPOCH에 학습 중단\n",
      "pre_val : [101.90133666992188, 67.43326568603516, 237.53587341308594, 248.84942626953125, 1.96745577341062e-06, 73.63072204589844, 205.06826782226562, 55.7411994934082, 227.16900634765625, 110.36209106445312]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[231 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168530312784902\n",
      "- TRAIN MAPE LOSS : 0.3183170374665227\n",
      "- TRAIN MSE LOSS : 254.3872169542646\n",
      "- TRAIN R2 SCORE : 0.9553305801811752\n",
      "\n",
      "- TEST MAE LOSS : 9.196866989135742\n",
      "- TEST MAPE LOSS : 20863.60546875\n",
      "- TEST MSE LOSS : 510.27935791015625\n",
      "- TEST R2 SCORE : 0.9144839644432068\n",
      "성능 및 손실 개선이 없어서 231 EPOCH에 학습 중단\n",
      "pre_val : [101.90172576904297, 67.43406677246094, 237.53590393066406, 248.84930419921875, 9.405262062500697e-07, 73.63108825683594, 205.06814575195312, 55.741355895996094, 227.16893005371094, 110.36215209960938]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[232 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168559023650376\n",
      "- TRAIN MAPE LOSS : 0.3222378301818471\n",
      "- TRAIN MSE LOSS : 254.3854931725989\n",
      "- TRAIN R2 SCORE : 0.9553308810720911\n",
      "\n",
      "- TEST MAE LOSS : 9.196891784667969\n",
      "- TEST MAPE LOSS : 20863.603515625\n",
      "- TEST MSE LOSS : 510.27984619140625\n",
      "- TEST R2 SCORE : 0.914483904838562\n",
      "성능 및 손실 개선이 없어서 232 EPOCH에 학습 중단\n",
      "pre_val : [101.90219116210938, 67.43478393554688, 237.53585815429688, 248.84913635253906, 9.220149195243721e-07, 73.6314468383789, 205.06808471679688, 55.74151611328125, 227.1688232421875, 110.36227416992188]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[233 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168577276176506\n",
      "- TRAIN MAPE LOSS : 0.3207534671580041\n",
      "- TRAIN MSE LOSS : 254.38548721153418\n",
      "- TRAIN R2 SCORE : 0.9553308821891571\n",
      "\n",
      "- TEST MAE LOSS : 9.196914672851562\n",
      "- TEST MAPE LOSS : 20863.61328125\n",
      "- TEST MSE LOSS : 510.2803955078125\n",
      "- TEST R2 SCORE : 0.9144837856292725\n",
      "성능 및 손실 개선이 없어서 233 EPOCH에 학습 중단\n",
      "pre_val : [101.90258026123047, 67.43547058105469, 237.53585815429688, 248.84896850585938, 8.660152843731339e-07, 73.63180541992188, 205.06797790527344, 55.74167251586914, 227.16871643066406, 110.36234283447266]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[234 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1685956734877365\n",
      "- TRAIN MAPE LOSS : 0.3192662719923716\n",
      "- TRAIN MSE LOSS : 254.38547918519774\n",
      "- TRAIN R2 SCORE : 0.9553308834896221\n",
      "\n",
      "- TEST MAE LOSS : 9.196934700012207\n",
      "- TEST MAPE LOSS : 20863.619140625\n",
      "- TEST MSE LOSS : 510.2808532714844\n",
      "- TEST R2 SCORE : 0.9144837260246277\n",
      "성능 및 손실 개선이 없어서 234 EPOCH에 학습 중단\n",
      "pre_val : [101.90296173095703, 67.43634033203125, 237.5358428955078, 248.84884643554688, 9.008770120999543e-07, 73.63212585449219, 205.06790161132812, 55.74188232421875, 227.1686553955078, 110.36241912841797]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[235 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168613152137169\n",
      "- TRAIN MAPE LOSS : 0.3180082185774833\n",
      "- TRAIN MSE LOSS : 254.38546957696235\n",
      "- TRAIN R2 SCORE : 0.9553308852735933\n",
      "\n",
      "- TEST MAE LOSS : 9.1969575881958\n",
      "- TEST MAPE LOSS : 20863.630859375\n",
      "- TEST MSE LOSS : 510.2812805175781\n",
      "- TEST R2 SCORE : 0.9144836664199829\n",
      "성능 및 손실 개선이 없어서 235 EPOCH에 학습 중단\n",
      "pre_val : [101.90331268310547, 67.43709564208984, 237.53578186035156, 248.84869384765625, 9.269675729228766e-07, 73.63240814208984, 205.06784057617188, 55.742042541503906, 227.16859436035156, 110.36248016357422]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[236 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168630356088385\n",
      "- TRAIN MAPE LOSS : 0.31688110790834145\n",
      "- TRAIN MSE LOSS : 254.38545307719625\n",
      "- TRAIN R2 SCORE : 0.9553308883080116\n",
      "\n",
      "- TEST MAE LOSS : 9.196976661682129\n",
      "- TEST MAPE LOSS : 20863.650390625\n",
      "- TEST MSE LOSS : 510.2816162109375\n",
      "- TEST R2 SCORE : 0.9144836068153381\n",
      "성능 및 손실 개선이 없어서 236 EPOCH에 학습 중단\n",
      "pre_val : [101.9037094116211, 67.43787384033203, 237.53567504882812, 248.84841918945312, 9.102618605538737e-07, 73.63279724121094, 205.06771850585938, 55.742210388183594, 227.1685333251953, 110.362548828125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[237 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16864722765409\n",
      "- TRAIN MAPE LOSS : 0.316189238999586\n",
      "- TRAIN MSE LOSS : 254.38542557883096\n",
      "- TRAIN R2 SCORE : 0.9553308937933062\n",
      "\n",
      "- TEST MAE LOSS : 9.196998596191406\n",
      "- TEST MAPE LOSS : 20863.650390625\n",
      "- TEST MSE LOSS : 510.2821044921875\n",
      "- TEST R2 SCORE : 0.9144834876060486\n",
      "성능 및 손실 개선이 없어서 237 EPOCH에 학습 중단\n",
      "pre_val : [101.904052734375, 67.43860626220703, 237.53567504882812, 248.8483428955078, 9.666380265116459e-07, 73.63302612304688, 205.06761169433594, 55.74235153198242, 227.16842651367188, 110.3625717163086]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[238 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168663626984283\n",
      "- TRAIN MAPE LOSS : 0.31559933322709754\n",
      "- TRAIN MSE LOSS : 254.38540712850076\n",
      "- TRAIN R2 SCORE : 0.9553308967443613\n",
      "\n",
      "- TEST MAE LOSS : 9.197014808654785\n",
      "- TEST MAPE LOSS : 20863.6640625\n",
      "- TEST MSE LOSS : 510.28240966796875\n",
      "- TEST R2 SCORE : 0.9144834280014038\n",
      "성능 및 손실 개선이 없어서 238 EPOCH에 학습 중단\n",
      "pre_val : [101.90441131591797, 67.43942260742188, 237.5355682373047, 248.8480987548828, 9.950845196726732e-07, 73.63331604003906, 205.06753540039062, 55.742496490478516, 227.1683807373047, 110.36263275146484]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[239 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168679684525603\n",
      "- TRAIN MAPE LOSS : 0.31461454705393815\n",
      "- TRAIN MSE LOSS : 254.38538925064194\n",
      "- TRAIN R2 SCORE : 0.9553309004623574\n",
      "\n",
      "- TEST MAE LOSS : 9.19703483581543\n",
      "- TEST MAPE LOSS : 20863.67578125\n",
      "- TEST MSE LOSS : 510.2828063964844\n",
      "- TEST R2 SCORE : 0.914483368396759\n",
      "성능 및 손실 개선이 없어서 239 EPOCH에 학습 중단\n",
      "pre_val : [101.9047622680664, 67.44005584716797, 237.53558349609375, 248.8480224609375, 9.303554406869807e-07, 73.63367462158203, 205.0675048828125, 55.74265670776367, 227.16831970214844, 110.36268615722656]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[240 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1686959660136615\n",
      "- TRAIN MAPE LOSS : 0.3140618333512253\n",
      "- TRAIN MSE LOSS : 254.3853609274484\n",
      "- TRAIN R2 SCORE : 0.9553309054974909\n",
      "\n",
      "- TEST MAE LOSS : 9.197053909301758\n",
      "- TEST MAPE LOSS : 20863.68359375\n",
      "- TEST MSE LOSS : 510.28314208984375\n",
      "- TEST R2 SCORE : 0.9144833087921143\n",
      "성능 및 손실 개선이 없어서 240 EPOCH에 학습 중단\n",
      "pre_val : [101.90524291992188, 67.44090270996094, 237.5354461669922, 248.84779357910156, 9.331881756224902e-07, 73.63394165039062, 205.0674285888672, 55.742774963378906, 227.1682891845703, 110.36276245117188]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[241 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168712010416951\n",
      "- TRAIN MAPE LOSS : 0.31460782363802403\n",
      "- TRAIN MSE LOSS : 254.38533632398486\n",
      "- TRAIN R2 SCORE : 0.955330910065791\n",
      "\n",
      "- TEST MAE LOSS : 9.197072982788086\n",
      "- TEST MAPE LOSS : 20863.6875\n",
      "- TEST MSE LOSS : 510.283447265625\n",
      "- TEST R2 SCORE : 0.9144832491874695\n",
      "성능 및 손실 개선이 없어서 241 EPOCH에 학습 중단\n",
      "pre_val : [101.90558624267578, 67.44170379638672, 237.53550720214844, 248.84768676757812, 8.96950155038212e-07, 73.63423919677734, 205.0673370361328, 55.742942810058594, 227.16819763183594, 110.36277770996094]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[242 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168728040415091\n",
      "- TRAIN MAPE LOSS : 0.31388089092982396\n",
      "- TRAIN MSE LOSS : 254.38531568513883\n",
      "- TRAIN R2 SCORE : 0.9553309143506563\n",
      "\n",
      "- TEST MAE LOSS : 9.197091102600098\n",
      "- TEST MAPE LOSS : 20863.6953125\n",
      "- TEST MSE LOSS : 510.2838439941406\n",
      "- TEST R2 SCORE : 0.9144831895828247\n",
      "성능 및 손실 개선이 없어서 242 EPOCH에 학습 중단\n",
      "pre_val : [101.90599060058594, 67.4424057006836, 237.53538513183594, 248.84751892089844, 9.174829074254376e-07, 73.63455200195312, 205.0673065185547, 55.74307632446289, 227.16819763183594, 110.36286926269531]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[243 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1687444348101845\n",
      "- TRAIN MAPE LOSS : 0.31446418585164565\n",
      "- TRAIN MSE LOSS : 254.38529508737417\n",
      "- TRAIN R2 SCORE : 0.955330918535486\n",
      "\n",
      "- TEST MAE LOSS : 9.197113037109375\n",
      "- TEST MAPE LOSS : 20863.6953125\n",
      "- TEST MSE LOSS : 510.2842712402344\n",
      "- TEST R2 SCORE : 0.9144831299781799\n",
      "성능 및 손실 개선이 없어서 243 EPOCH에 학습 중단\n",
      "pre_val : [101.90636444091797, 67.44309997558594, 237.53541564941406, 248.847412109375, 8.982250392364222e-07, 73.63483428955078, 205.0672149658203, 55.74319076538086, 227.16810607910156, 110.36288452148438]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[244 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168760655276425\n",
      "- TRAIN MAPE LOSS : 0.3140528216588122\n",
      "- TRAIN MSE LOSS : 254.38527301174778\n",
      "- TRAIN R2 SCORE : 0.9553309223368451\n",
      "\n",
      "- TEST MAE LOSS : 9.197129249572754\n",
      "- TEST MAPE LOSS : 20863.708984375\n",
      "- TEST MSE LOSS : 510.2845153808594\n",
      "- TEST R2 SCORE : 0.9144830703735352\n",
      "성능 및 손실 개선이 없어서 244 EPOCH에 학습 중단\n",
      "pre_val : [101.9068603515625, 67.44383239746094, 237.5352783203125, 248.8472442626953, 9.865111678664107e-07, 73.6351318359375, 205.06719970703125, 55.743309020996094, 227.16812133789062, 110.36293029785156]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[245 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168776369895134\n",
      "- TRAIN MAPE LOSS : 0.3141966851930935\n",
      "- TRAIN MSE LOSS : 254.3852485827466\n",
      "- TRAIN R2 SCORE : 0.9553309271552346\n",
      "\n",
      "- TEST MAE LOSS : 9.197148323059082\n",
      "- TEST MAPE LOSS : 20863.720703125\n",
      "- TEST MSE LOSS : 510.2848815917969\n",
      "- TEST R2 SCORE : 0.9144830107688904\n",
      "성능 및 손실 개선이 없어서 245 EPOCH에 학습 중단\n",
      "pre_val : [101.9072265625, 67.44463348388672, 237.53530883789062, 248.8470916748047, 8.899062322598184e-07, 73.6353988647461, 205.06712341308594, 55.74351501464844, 227.16806030273438, 110.36297607421875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[246 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168792737213882\n",
      "- TRAIN MAPE LOSS : 0.31431296219984134\n",
      "- TRAIN MSE LOSS : 254.38522601200984\n",
      "- TRAIN R2 SCORE : 0.9553309313400642\n",
      "\n",
      "- TEST MAE LOSS : 9.19716739654541\n",
      "- TEST MAPE LOSS : 20863.720703125\n",
      "- TEST MSE LOSS : 510.2852478027344\n",
      "- TEST R2 SCORE : 0.9144829511642456\n",
      "성능 및 손실 개선이 없어서 246 EPOCH에 학습 중단\n",
      "pre_val : [101.90770721435547, 67.44540405273438, 237.53517150878906, 248.84690856933594, 1.0304677289241226e-06, 73.63570404052734, 205.0670623779297, 55.74360656738281, 227.1680145263672, 110.36300659179688]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[247 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168808632763949\n",
      "- TRAIN MAPE LOSS : 0.3142167585707836\n",
      "- TRAIN MSE LOSS : 254.3852045397992\n",
      "- TRAIN R2 SCORE : 0.9553309352748044\n",
      "\n",
      "- TEST MAE LOSS : 9.197186470031738\n",
      "- TEST MAPE LOSS : 20863.732421875\n",
      "- TEST MSE LOSS : 510.28558349609375\n",
      "- TEST R2 SCORE : 0.9144828915596008\n",
      "성능 및 손실 개선이 없어서 247 EPOCH에 학습 중단\n",
      "pre_val : [101.90801239013672, 67.44596862792969, 237.5351104736328, 248.84669494628906, 9.231494004779961e-07, 73.63597106933594, 205.06700134277344, 55.743778228759766, 227.16798400878906, 110.36307525634766]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[248 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168824464624579\n",
      "- TRAIN MAPE LOSS : 0.31408053445649314\n",
      "- TRAIN MSE LOSS : 254.38518648214273\n",
      "- TRAIN R2 SCORE : 0.9553309382258596\n",
      "\n",
      "- TEST MAE LOSS : 9.19720458984375\n",
      "- TEST MAPE LOSS : 20863.736328125\n",
      "- TEST MSE LOSS : 510.28594970703125\n",
      "- TEST R2 SCORE : 0.914482831954956\n",
      "성능 및 손실 개선이 없어서 248 EPOCH에 학습 중단\n",
      "pre_val : [101.90843963623047, 67.44685363769531, 237.5350799560547, 248.84657287597656, 9.851825097939582e-07, 73.63630676269531, 205.0669403076172, 55.743896484375, 227.16793823242188, 110.36311340332031]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[249 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168840677954934\n",
      "- TRAIN MAPE LOSS : 0.3142996738142484\n",
      "- TRAIN MSE LOSS : 254.38515299443597\n",
      "- TRAIN R2 SCORE : 0.9553309450949822\n",
      "\n",
      "- TEST MAE LOSS : 9.197225570678711\n",
      "- TEST MAPE LOSS : 20863.7421875\n",
      "- TEST MSE LOSS : 510.2864074707031\n",
      "- TEST R2 SCORE : 0.9144827723503113\n",
      "성능 및 손실 개선이 없어서 249 EPOCH에 학습 중단\n",
      "pre_val : [101.90870666503906, 67.4475326538086, 237.53497314453125, 248.84634399414062, 9.393052096129395e-07, 73.63652038574219, 205.06686401367188, 55.744083404541016, 227.16787719726562, 110.36312866210938]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[250 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1688565390926975\n",
      "- TRAIN MAPE LOSS : 0.31431352720237693\n",
      "- TRAIN MSE LOSS : 254.38514615145596\n",
      "- TRAIN R2 SCORE : 0.9553309464621377\n",
      "\n",
      "- TEST MAE LOSS : 9.197243690490723\n",
      "- TEST MAPE LOSS : 20863.75390625\n",
      "- TEST MSE LOSS : 510.2867126464844\n",
      "- TEST R2 SCORE : 0.9144827127456665\n",
      "성능 및 손실 개선이 없어서 250 EPOCH에 학습 중단\n",
      "pre_val : [101.90921783447266, 67.44822692871094, 237.5349578857422, 248.8462677001953, 9.62094759415777e-07, 73.63687896728516, 205.06683349609375, 55.74418640136719, 227.16781616210938, 110.36317443847656]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[251 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168872568423931\n",
      "- TRAIN MAPE LOSS : 0.3138489449706736\n",
      "- TRAIN MSE LOSS : 254.38511624476294\n",
      "- TRAIN R2 SCORE : 0.9553309519641049\n",
      "\n",
      "- TEST MAE LOSS : 9.19726276397705\n",
      "- TEST MAPE LOSS : 20863.75390625\n",
      "- TEST MSE LOSS : 510.2871398925781\n",
      "- TEST R2 SCORE : 0.9144826531410217\n",
      "성능 및 손실 개선이 없어서 251 EPOCH에 학습 중단\n",
      "pre_val : [101.90939331054688, 67.4488525390625, 237.53482055664062, 248.8460235595703, 9.069823363461182e-07, 73.6370849609375, 205.06675720214844, 55.74435806274414, 227.1678009033203, 110.36322784423828]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[252 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168888022482812\n",
      "- TRAIN MAPE LOSS : 0.31460754714176786\n",
      "- TRAIN MSE LOSS : 254.38510435197736\n",
      "- TRAIN R2 SCORE : 0.955330954248255\n",
      "\n",
      "- TEST MAE LOSS : 9.197281837463379\n",
      "- TEST MAPE LOSS : 20863.755859375\n",
      "- TEST MSE LOSS : 510.2874450683594\n",
      "- TEST R2 SCORE : 0.914482593536377\n",
      "성능 및 손실 개선이 없어서 252 EPOCH에 학습 중단\n",
      "pre_val : [101.9100570678711, 67.44974517822266, 237.53485107421875, 248.84597778320312, 1.0565599950496107e-06, 73.63735961914062, 205.0667266845703, 55.7445068359375, 227.16775512695312, 110.36325073242188]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[253 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168904092895401\n",
      "- TRAIN MAPE LOSS : 0.3137923273579641\n",
      "- TRAIN MSE LOSS : 254.38508202772874\n",
      "- TRAIN R2 SCORE : 0.9553309585998109\n",
      "\n",
      "- TEST MAE LOSS : 9.197299003601074\n",
      "- TEST MAPE LOSS : 20863.771484375\n",
      "- TEST MSE LOSS : 510.2877502441406\n",
      "- TEST R2 SCORE : 0.9144825339317322\n",
      "성능 및 손실 개선이 없어서 253 EPOCH에 학습 중단\n",
      "pre_val : [101.9102554321289, 67.45030212402344, 237.5347442626953, 248.845703125, 9.431079206478898e-07, 73.63768768310547, 205.06663513183594, 55.7446403503418, 227.16770935058594, 110.36331939697266]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[254 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16892012149304\n",
      "- TRAIN MAPE LOSS : 0.3144416322022468\n",
      "- TRAIN MSE LOSS : 254.38505101450673\n",
      "- TRAIN R2 SCORE : 0.9553309638183434\n",
      "\n",
      "- TEST MAE LOSS : 9.197319030761719\n",
      "- TEST MAPE LOSS : 20863.767578125\n",
      "- TEST MSE LOSS : 510.2881774902344\n",
      "- TEST R2 SCORE : 0.9144824743270874\n",
      "성능 및 손실 개선이 없어서 254 EPOCH에 학습 중단\n",
      "pre_val : [101.91075134277344, 67.45120239257812, 237.53469848632812, 248.8456573486328, 9.260860451831832e-07, 73.6379165649414, 205.06661987304688, 55.74477767944336, 227.16769409179688, 110.36334228515625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[255 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168935975028084\n",
      "- TRAIN MAPE LOSS : 0.31392616878908414\n",
      "- TRAIN MSE LOSS : 254.3850476346316\n",
      "- TRAIN R2 SCORE : 0.9553309653855704\n",
      "\n",
      "- TEST MAE LOSS : 9.19733715057373\n",
      "- TEST MAPE LOSS : 20863.78515625\n",
      "- TEST MSE LOSS : 510.2884826660156\n",
      "- TEST R2 SCORE : 0.9144824147224426\n",
      "성능 및 손실 개선이 없어서 255 EPOCH에 학습 중단\n",
      "pre_val : [101.91111755371094, 67.45185852050781, 237.53463745117188, 248.84532165527344, 8.877924528860603e-07, 73.6382064819336, 205.0664825439453, 55.744903564453125, 227.1676025390625, 110.36334228515625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[256 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168951501712932\n",
      "- TRAIN MAPE LOSS : 0.31441081431310075\n",
      "- TRAIN MSE LOSS : 254.38501050188825\n",
      "- TRAIN R2 SCORE : 0.9553309720046037\n",
      "\n",
      "- TEST MAE LOSS : 9.197356224060059\n",
      "- TEST MAPE LOSS : 20863.78125\n",
      "- TEST MSE LOSS : 510.28887939453125\n",
      "- TEST R2 SCORE : 0.9144823551177979\n",
      "성능 및 손실 개선이 없어서 256 EPOCH에 학습 중단\n",
      "pre_val : [101.91143035888672, 67.45256042480469, 237.53453063964844, 248.84523010253906, 9.379666607856052e-07, 73.63850402832031, 205.06649780273438, 55.74507522583008, 227.1676025390625, 110.36344909667969]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[257 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168968188812682\n",
      "- TRAIN MAPE LOSS : 0.31379500966701473\n",
      "- TRAIN MSE LOSS : 254.38499924773103\n",
      "- TRAIN R2 SCORE : 0.9553309739386285\n",
      "\n",
      "- TEST MAE LOSS : 9.19737720489502\n",
      "- TEST MAPE LOSS : 20863.798828125\n",
      "- TEST MSE LOSS : 510.289306640625\n",
      "- TEST R2 SCORE : 0.9144822955131531\n",
      "성능 및 손실 개선이 없어서 257 EPOCH에 학습 중단\n",
      "pre_val : [101.91192626953125, 67.45333099365234, 237.53453063964844, 248.84510803222656, 9.532874400974833e-07, 73.63880157470703, 205.06643676757812, 55.745208740234375, 227.1675567626953, 110.36346435546875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[258 / 1000]\n",
      "- TRAIN MAE LOSS : 7.168984281766665\n",
      "- TRAIN MAPE LOSS : 0.3144454429986385\n",
      "- TRAIN MSE LOSS : 254.38497750288957\n",
      "- TRAIN R2 SCORE : 0.9553309778566961\n",
      "\n",
      "- TEST MAE LOSS : 9.197395324707031\n",
      "- TEST MAPE LOSS : 20863.798828125\n",
      "- TEST MSE LOSS : 510.28973388671875\n",
      "- TEST R2 SCORE : 0.9144822359085083\n",
      "성능 및 손실 개선이 없어서 258 EPOCH에 학습 중단\n",
      "pre_val : [101.91217803955078, 67.4540786743164, 237.53440856933594, 248.84487915039062, 8.737257530810894e-07, 73.63902282714844, 205.06631469726562, 55.745365142822266, 227.16749572753906, 110.36348724365234]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[259 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16899961398198\n",
      "- TRAIN MAPE LOSS : 0.3138919706647838\n",
      "- TRAIN MSE LOSS : 254.3849611391721\n",
      "- TRAIN R2 SCORE : 0.9553309805576617\n",
      "\n",
      "- TEST MAE LOSS : 9.19741153717041\n",
      "- TEST MAPE LOSS : 20863.802734375\n",
      "- TEST MSE LOSS : 510.2900085449219\n",
      "- TEST R2 SCORE : 0.9144821763038635\n",
      "성능 및 손실 개선이 없어서 259 EPOCH에 학습 중단\n",
      "pre_val : [101.91268920898438, 67.45477294921875, 237.534423828125, 248.8447723388672, 9.575741160006146e-07, 73.63933563232422, 205.0663299560547, 55.745487213134766, 227.16748046875, 110.3635482788086]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[260 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16901573527943\n",
      "- TRAIN MAPE LOSS : 0.3142305084677426\n",
      "- TRAIN MSE LOSS : 254.38493197674518\n",
      "- TRAIN R2 SCORE : 0.9553309861596647\n",
      "\n",
      "- TEST MAE LOSS : 9.197432518005371\n",
      "- TEST MAPE LOSS : 20863.806640625\n",
      "- TEST MSE LOSS : 510.2903747558594\n",
      "- TEST R2 SCORE : 0.9144821166992188\n",
      "성능 및 손실 개선이 없어서 260 EPOCH에 학습 중단\n",
      "pre_val : [101.9129409790039, 67.4554443359375, 237.5343475341797, 248.8445281982422, 8.930943522500456e-07, 73.63959503173828, 205.06625366210938, 55.74560546875, 227.16741943359375, 110.36357116699219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[261 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169032130208048\n",
      "- TRAIN MAPE LOSS : 0.3140649921030223\n",
      "- TRAIN MSE LOSS : 254.3849176276147\n",
      "- TRAIN R2 SCORE : 0.9553309890273568\n",
      "\n",
      "- TEST MAE LOSS : 9.197450637817383\n",
      "- TEST MAPE LOSS : 20863.806640625\n",
      "- TEST MSE LOSS : 510.290771484375\n",
      "- TEST R2 SCORE : 0.914482057094574\n",
      "성능 및 손실 개선이 없어서 261 EPOCH에 학습 중단\n",
      "pre_val : [101.91341400146484, 67.45623779296875, 237.5343017578125, 248.8444061279297, 9.423646361028659e-07, 73.63983917236328, 205.066162109375, 55.74578857421875, 227.16737365722656, 110.36359405517578]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[262 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169047387729991\n",
      "- TRAIN MAPE LOSS : 0.31400798769576566\n",
      "- TRAIN MSE LOSS : 254.38489737343954\n",
      "- TRAIN R2 SCORE : 0.9553309928453886\n",
      "\n",
      "- TEST MAE LOSS : 9.197468757629395\n",
      "- TEST MAPE LOSS : 20863.8203125\n",
      "- TEST MSE LOSS : 510.2911071777344\n",
      "- TEST R2 SCORE : 0.9144819974899292\n",
      "성능 및 손실 개선이 없어서 262 EPOCH에 학습 중단\n",
      "pre_val : [101.91371154785156, 67.45692443847656, 237.53419494628906, 248.84423828125, 9.502560942564742e-07, 73.64019012451172, 205.06614685058594, 55.74587631225586, 227.16738891601562, 110.3636474609375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[263 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169063394119689\n",
      "- TRAIN MAPE LOSS : 0.31413838784542536\n",
      "- TRAIN MSE LOSS : 254.38487845734284\n",
      "- TRAIN R2 SCORE : 0.955330996229932\n",
      "\n",
      "- TEST MAE LOSS : 9.197488784790039\n",
      "- TEST MAPE LOSS : 20863.830078125\n",
      "- TEST MSE LOSS : 510.2915344238281\n",
      "- TEST R2 SCORE : 0.9144819378852844\n",
      "성능 및 손실 개선이 없어서 263 EPOCH에 학습 중단\n",
      "pre_val : [101.91421508789062, 67.4576416015625, 237.5341796875, 248.84402465820312, 9.132942295764224e-07, 73.64048767089844, 205.06607055664062, 55.74606704711914, 227.16729736328125, 110.36370849609375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[264 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169079847269125\n",
      "- TRAIN MAPE LOSS : 0.3140870299060028\n",
      "- TRAIN MSE LOSS : 254.38485727536928\n",
      "- TRAIN R2 SCORE : 0.9553309997478565\n",
      "\n",
      "- TEST MAE LOSS : 9.197507858276367\n",
      "- TEST MAPE LOSS : 20863.83203125\n",
      "- TEST MSE LOSS : 510.2919006347656\n",
      "- TEST R2 SCORE : 0.9144818782806396\n",
      "성능 및 손실 개선이 없어서 264 EPOCH에 학습 중단\n",
      "pre_val : [101.91451263427734, 67.4583740234375, 237.5340576171875, 248.8437957763672, 9.037671588885132e-07, 73.64070892333984, 205.06597900390625, 55.74619674682617, 227.16725158691406, 110.36373901367188]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[265 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169095397495723\n",
      "- TRAIN MAPE LOSS : 0.3140949169468213\n",
      "- TRAIN MSE LOSS : 254.3848330853869\n",
      "- TRAIN R2 SCORE : 0.9553310045829186\n",
      "\n",
      "- TEST MAE LOSS : 9.197525024414062\n",
      "- TEST MAPE LOSS : 20863.8359375\n",
      "- TEST MSE LOSS : 510.2922058105469\n",
      "- TEST R2 SCORE : 0.9144818186759949\n",
      "성능 및 손실 개선이 없어서 265 EPOCH에 학습 중단\n",
      "pre_val : [101.91490173339844, 67.45904541015625, 237.53404235839844, 248.84373474121094, 9.294227538703126e-07, 73.64102172851562, 205.06597900390625, 55.74633026123047, 227.16720581054688, 110.36380004882812]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[266 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16911157961492\n",
      "- TRAIN MAPE LOSS : 0.3139342109390072\n",
      "- TRAIN MSE LOSS : 254.38482110296928\n",
      "- TRAIN R2 SCORE : 0.9553310068003781\n",
      "\n",
      "- TEST MAE LOSS : 9.197546005249023\n",
      "- TEST MAPE LOSS : 20863.841796875\n",
      "- TEST MSE LOSS : 510.2926330566406\n",
      "- TEST R2 SCORE : 0.9144817590713501\n",
      "성능 및 손실 개선이 없어서 266 EPOCH에 학습 중단\n",
      "pre_val : [101.91523742675781, 67.45987701416016, 237.53396606445312, 248.84349060058594, 9.107480991588091e-07, 73.64130401611328, 205.06591796875, 55.74646759033203, 227.16717529296875, 110.36384582519531]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[267 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169128121596116\n",
      "- TRAIN MAPE LOSS : 0.31435182172153797\n",
      "- TRAIN MSE LOSS : 254.38480448102618\n",
      "- TRAIN R2 SCORE : 0.9553310094179807\n",
      "\n",
      "- TEST MAE LOSS : 9.197566032409668\n",
      "- TEST MAPE LOSS : 20863.8515625\n",
      "- TEST MSE LOSS : 510.2930908203125\n",
      "- TEST R2 SCORE : 0.9144816398620605\n",
      "성능 및 손실 개선이 없어서 267 EPOCH에 학습 중단\n",
      "pre_val : [101.9157485961914, 67.46056365966797, 237.53392028808594, 248.84339904785156, 9.407298193764291e-07, 73.6416015625, 205.06588745117188, 55.74663162231445, 227.16717529296875, 110.36389923095703]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[268 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169143947454599\n",
      "- TRAIN MAPE LOSS : 0.3136156558177688\n",
      "- TRAIN MSE LOSS : 254.3847853797966\n",
      "- TRAIN R2 SCORE : 0.9553310139362629\n",
      "\n",
      "- TEST MAE LOSS : 9.197583198547363\n",
      "- TEST MAPE LOSS : 20863.86328125\n",
      "- TEST MSE LOSS : 510.2933654785156\n",
      "- TEST R2 SCORE : 0.9144816398620605\n",
      "성능 및 손실 개선이 없어서 268 EPOCH에 학습 중단\n",
      "pre_val : [101.91596984863281, 67.4612045288086, 237.53379821777344, 248.84315490722656, 8.626033149994328e-07, 73.6418228149414, 205.06578063964844, 55.746734619140625, 227.16709899902344, 110.36389923095703]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[269 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1691595940489865\n",
      "- TRAIN MAPE LOSS : 0.3145007326266357\n",
      "- TRAIN MSE LOSS : 254.38475507296047\n",
      "- TRAIN R2 SCORE : 0.9553310188713607\n",
      "\n",
      "- TEST MAE LOSS : 9.197601318359375\n",
      "- TEST MAPE LOSS : 20863.857421875\n",
      "- TEST MSE LOSS : 510.293701171875\n",
      "- TEST R2 SCORE : 0.9144815802574158\n",
      "성능 및 손실 개선이 없어서 269 EPOCH에 학습 중단\n",
      "pre_val : [101.91651153564453, 67.46202850341797, 237.53384399414062, 248.8430633544922, 9.409063750354107e-07, 73.64217376708984, 205.0657501220703, 55.74690246582031, 227.1670684814453, 110.3639907836914]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[270 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169175775634659\n",
      "- TRAIN MAPE LOSS : 0.31367139631113805\n",
      "- TRAIN MSE LOSS : 254.3847471319879\n",
      "- TRAIN R2 SCORE : 0.9553310209387665\n",
      "\n",
      "- TEST MAE LOSS : 9.197622299194336\n",
      "- TEST MAPE LOSS : 20863.87109375\n",
      "- TEST MSE LOSS : 510.29412841796875\n",
      "- TEST R2 SCORE : 0.9144814610481262\n",
      "성능 및 손실 개선이 없어서 270 EPOCH에 학습 중단\n",
      "pre_val : [101.91680908203125, 67.46268463134766, 237.53375244140625, 248.84286499023438, 9.498827466813964e-07, 73.64244842529297, 205.06570434570312, 55.74705123901367, 227.16702270507812, 110.36399841308594]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[271 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169191995367304\n",
      "- TRAIN MAPE LOSS : 0.31441846284520375\n",
      "- TRAIN MSE LOSS : 254.3847189869914\n",
      "- TRAIN R2 SCORE : 0.955331025940555\n",
      "\n",
      "- TEST MAE LOSS : 9.197641372680664\n",
      "- TEST MAPE LOSS : 20863.87890625\n",
      "- TEST MSE LOSS : 510.2945556640625\n",
      "- TEST R2 SCORE : 0.9144814014434814\n",
      "성능 및 손실 개선이 없어서 271 EPOCH에 학습 중단\n",
      "pre_val : [101.91710662841797, 67.46334075927734, 237.5336151123047, 248.8426513671875, 8.443329306828673e-07, 73.64271545410156, 205.0655975341797, 55.74717330932617, 227.1669921875, 110.36405944824219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[272 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169208389495636\n",
      "- TRAIN MAPE LOSS : 0.3138547905727283\n",
      "- TRAIN MSE LOSS : 254.38471194127223\n",
      "- TRAIN R2 SCORE : 0.955331027907925\n",
      "\n",
      "- TEST MAE LOSS : 9.19765853881836\n",
      "- TEST MAPE LOSS : 20863.890625\n",
      "- TEST MSE LOSS : 510.2948303222656\n",
      "- TEST R2 SCORE : 0.9144813418388367\n",
      "성능 및 손실 개선이 없어서 272 EPOCH에 학습 중단\n",
      "pre_val : [101.91755676269531, 67.46410369873047, 237.5335693359375, 248.84249877929688, 9.703109071779181e-07, 73.64298248291016, 205.06553649902344, 55.74729919433594, 227.1669158935547, 110.36407470703125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[273 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169223308629923\n",
      "- TRAIN MAPE LOSS : 0.31424891010916733\n",
      "- TRAIN MSE LOSS : 254.38467896734917\n",
      "- TRAIN R2 SCORE : 0.9553310332264934\n",
      "\n",
      "- TEST MAE LOSS : 9.19767951965332\n",
      "- TEST MAPE LOSS : 20863.8828125\n",
      "- TEST MSE LOSS : 510.2952880859375\n",
      "- TEST R2 SCORE : 0.9144812822341919\n",
      "성능 및 손실 개선이 없어서 273 EPOCH에 학습 중단\n",
      "pre_val : [101.91796875, 67.46477508544922, 237.5335693359375, 248.84234619140625, 8.386859917663969e-07, 73.6432876586914, 205.06552124023438, 55.74745178222656, 227.16693115234375, 110.3641357421875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[274 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169240606147926\n",
      "- TRAIN MAPE LOSS : 0.3137488448255129\n",
      "- TRAIN MSE LOSS : 254.38467519533384\n",
      "- TRAIN R2 SCORE : 0.9553310343102142\n",
      "\n",
      "- TEST MAE LOSS : 9.197698593139648\n",
      "- TEST MAPE LOSS : 20863.888671875\n",
      "- TEST MSE LOSS : 510.2956237792969\n",
      "- TEST R2 SCORE : 0.9144812226295471\n",
      "성능 및 손실 개선이 없어서 274 EPOCH에 학습 중단\n",
      "pre_val : [101.9182357788086, 67.46551513671875, 237.53346252441406, 248.8421630859375, 9.820977311392198e-07, 73.64359283447266, 205.06544494628906, 55.74754333496094, 227.1668701171875, 110.36416625976562]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[275 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169256261212009\n",
      "- TRAIN MAPE LOSS : 0.3143589051750365\n",
      "- TRAIN MSE LOSS : 254.38464921484461\n",
      "- TRAIN R2 SCORE : 0.9553310393286751\n",
      "\n",
      "- TEST MAE LOSS : 9.19771671295166\n",
      "- TEST MAPE LOSS : 20863.89453125\n",
      "- TEST MSE LOSS : 510.2960205078125\n",
      "- TEST R2 SCORE : 0.9144811630249023\n",
      "성능 및 손실 개선이 없어서 275 EPOCH에 학습 중단\n",
      "pre_val : [101.91865539550781, 67.46633911132812, 237.53343200683594, 248.84201049804688, 9.025487770486507e-07, 73.64378356933594, 205.06536865234375, 55.74775314331055, 227.1667938232422, 110.36417388916016]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[276 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169270813948625\n",
      "- TRAIN MAPE LOSS : 0.31386463995059055\n",
      "- TRAIN MSE LOSS : 254.38462635813895\n",
      "- TRAIN R2 SCORE : 0.955331043413469\n",
      "\n",
      "- TEST MAE LOSS : 9.197734832763672\n",
      "- TEST MAPE LOSS : 20863.8984375\n",
      "- TEST MSE LOSS : 510.29638671875\n",
      "- TEST R2 SCORE : 0.9144811034202576\n",
      "성능 및 손실 개선이 없어서 276 EPOCH에 학습 중단\n",
      "pre_val : [101.91899108886719, 67.46688079833984, 237.53338623046875, 248.84185791015625, 8.899196473066695e-07, 73.64409637451172, 205.06536865234375, 55.747894287109375, 227.16680908203125, 110.36426544189453]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[277 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16928753819499\n",
      "- TRAIN MAPE LOSS : 0.3139948021990436\n",
      "- TRAIN MSE LOSS : 254.38461738853186\n",
      "- TRAIN R2 SCORE : 0.9553310442804457\n",
      "\n",
      "- TEST MAE LOSS : 9.19775390625\n",
      "- TEST MAPE LOSS : 20863.90625\n",
      "- TEST MSE LOSS : 510.2967224121094\n",
      "- TEST R2 SCORE : 0.9144810438156128\n",
      "성능 및 손실 개선이 없어서 277 EPOCH에 학습 중단\n",
      "pre_val : [101.91934204101562, 67.46775817871094, 237.53330993652344, 248.8417205810547, 9.351882681585266e-07, 73.64436340332031, 205.06524658203125, 55.74805450439453, 227.1667022705078, 110.36427307128906]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[278 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169302864008016\n",
      "- TRAIN MAPE LOSS : 0.3140589696028224\n",
      "- TRAIN MSE LOSS : 254.38458344572908\n",
      "- TRAIN R2 SCORE : 0.9553310514830209\n",
      "\n",
      "- TEST MAE LOSS : 9.197772979736328\n",
      "- TEST MAPE LOSS : 20863.91796875\n",
      "- TEST MSE LOSS : 510.297119140625\n",
      "- TEST R2 SCORE : 0.914480984210968\n",
      "성능 및 손실 개선이 없어서 278 EPOCH에 학습 중단\n",
      "pre_val : [101.91974639892578, 67.4684066772461, 237.53323364257812, 248.8415069580078, 9.387767931912094e-07, 73.64460754394531, 205.06521606445312, 55.74821853637695, 227.1667022705078, 110.36431884765625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[279 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169318922749766\n",
      "- TRAIN MAPE LOSS : 0.3139377595260218\n",
      "- TRAIN MSE LOSS : 254.38458524477232\n",
      "- TRAIN R2 SCORE : 0.9553310511495684\n",
      "\n",
      "- TEST MAE LOSS : 9.19779109954834\n",
      "- TEST MAPE LOSS : 20863.91796875\n",
      "- TEST MSE LOSS : 510.2975158691406\n",
      "- TEST R2 SCORE : 0.9144809246063232\n",
      "성능 및 손실 개선이 없어서 279 EPOCH에 학습 중단\n",
      "pre_val : [101.92007446289062, 67.46908569335938, 237.53323364257812, 248.84136962890625, 9.048957281265757e-07, 73.64494323730469, 205.06515502929688, 55.74832534790039, 227.1666259765625, 110.3643798828125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[280 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1693353119430006\n",
      "- TRAIN MAPE LOSS : 0.3140002058092114\n",
      "- TRAIN MSE LOSS : 254.38455203236398\n",
      "- TRAIN R2 SCORE : 0.955331056634863\n",
      "\n",
      "- TEST MAE LOSS : 9.1978120803833\n",
      "- TEST MAPE LOSS : 20863.923828125\n",
      "- TEST MSE LOSS : 510.2979431152344\n",
      "- TEST R2 SCORE : 0.9144808650016785\n",
      "성능 및 손실 개선이 없어서 280 EPOCH에 학습 중단\n",
      "pre_val : [101.92056274414062, 67.46981811523438, 237.53318786621094, 248.8412322998047, 9.612207350073732e-07, 73.64523315429688, 205.0651092529297, 55.74848556518555, 227.16659545898438, 110.36444091796875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[281 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1693522575351745\n",
      "- TRAIN MAPE LOSS : 0.31403733178295873\n",
      "- TRAIN MSE LOSS : 254.3845571429913\n",
      "- TRAIN R2 SCORE : 0.9553310560013031\n",
      "\n",
      "- TEST MAE LOSS : 9.197830200195312\n",
      "- TEST MAPE LOSS : 20863.93359375\n",
      "- TEST MSE LOSS : 510.2982482910156\n",
      "- TEST R2 SCORE : 0.9144808053970337\n",
      "성능 및 손실 개선이 없어서 281 EPOCH에 학습 중단\n",
      "pre_val : [101.92083740234375, 67.47065734863281, 237.53306579589844, 248.8410186767578, 8.235647328547202e-07, 73.64546966552734, 205.06500244140625, 55.74864196777344, 227.1665496826172, 110.36445617675781]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[282 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169367772749254\n",
      "- TRAIN MAPE LOSS : 0.3138828009554556\n",
      "- TRAIN MSE LOSS : 254.38452537803383\n",
      "- TRAIN R2 SCORE : 0.9553310620868123\n",
      "\n",
      "- TEST MAE LOSS : 9.197851181030273\n",
      "- TEST MAPE LOSS : 20863.927734375\n",
      "- TEST MSE LOSS : 510.2987365722656\n",
      "- TEST R2 SCORE : 0.9144806861877441\n",
      "성능 및 손실 개선이 없어서 282 EPOCH에 학습 중단\n",
      "pre_val : [101.92119598388672, 67.47118377685547, 237.53306579589844, 248.84092712402344, 9.245227374776732e-07, 73.64579010009766, 205.06500244140625, 55.748779296875, 227.16653442382812, 110.36454772949219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[283 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169384528073397\n",
      "- TRAIN MAPE LOSS : 0.3139513218538328\n",
      "- TRAIN MSE LOSS : 254.38452721228967\n",
      "- TRAIN R2 SCORE : 0.9553310620868123\n",
      "\n",
      "- TEST MAE LOSS : 9.197869300842285\n",
      "- TEST MAPE LOSS : 20863.939453125\n",
      "- TEST MSE LOSS : 510.2991027832031\n",
      "- TEST R2 SCORE : 0.9144806265830994\n",
      "성능 및 손실 개선이 없어서 283 EPOCH에 학습 중단\n",
      "pre_val : [101.9215087890625, 67.47187805175781, 237.5330047607422, 248.84075927734375, 9.068681947610457e-07, 73.64595794677734, 205.06488037109375, 55.748931884765625, 227.1664581298828, 110.364501953125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[284 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169399324897286\n",
      "- TRAIN MAPE LOSS : 0.314080617561207\n",
      "- TRAIN MSE LOSS : 254.38449301072768\n",
      "- TRAIN R2 SCORE : 0.9553310679722499\n",
      "\n",
      "- TEST MAE LOSS : 9.197885513305664\n",
      "- TEST MAPE LOSS : 20863.943359375\n",
      "- TEST MSE LOSS : 510.2994384765625\n",
      "- TEST R2 SCORE : 0.9144805669784546\n",
      "성능 및 손실 개선이 없어서 284 EPOCH에 학습 중단\n",
      "pre_val : [101.92194366455078, 67.47264099121094, 237.53297424316406, 248.84063720703125, 9.349703304906143e-07, 73.64635467529297, 205.06491088867188, 55.74909210205078, 227.16644287109375, 110.36461639404297]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[285 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169415871146676\n",
      "- TRAIN MAPE LOSS : 0.3136842180314389\n",
      "- TRAIN MSE LOSS : 254.38448239199766\n",
      "- TRAIN R2 SCORE : 0.9553310703064178\n",
      "\n",
      "- TEST MAE LOSS : 9.197907447814941\n",
      "- TEST MAPE LOSS : 20863.951171875\n",
      "- TEST MSE LOSS : 510.29986572265625\n",
      "- TEST R2 SCORE : 0.9144805073738098\n",
      "성능 및 손실 개선이 없어서 285 EPOCH에 학습 중단\n",
      "pre_val : [101.92227935791016, 67.47331237792969, 237.53286743164062, 248.84039306640625, 8.950951269071084e-07, 73.64656829833984, 205.0648193359375, 55.74922180175781, 227.1664276123047, 110.36463165283203]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[286 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169431851527074\n",
      "- TRAIN MAPE LOSS : 0.31443608068242357\n",
      "- TRAIN MSE LOSS : 254.38446276364627\n",
      "- TRAIN R2 SCORE : 0.9553310738910328\n",
      "\n",
      "- TEST MAE LOSS : 9.19792652130127\n",
      "- TEST MAPE LOSS : 20863.951171875\n",
      "- TEST MSE LOSS : 510.30029296875\n",
      "- TEST R2 SCORE : 0.914480447769165\n",
      "성능 및 손실 개선이 없어서 286 EPOCH에 학습 중단\n",
      "pre_val : [101.9227294921875, 67.47409057617188, 237.53282165527344, 248.84030151367188, 9.356065220345045e-07, 73.64682006835938, 205.0647430419922, 55.74935531616211, 227.16636657714844, 110.36466217041016]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[287 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169447594622632\n",
      "- TRAIN MAPE LOSS : 0.3136302808088648\n",
      "- TRAIN MSE LOSS : 254.38445414029636\n",
      "- TRAIN R2 SCORE : 0.9553310756583314\n",
      "\n",
      "- TEST MAE LOSS : 9.197942733764648\n",
      "- TEST MAPE LOSS : 20863.96484375\n",
      "- TEST MSE LOSS : 510.3005676269531\n",
      "- TEST R2 SCORE : 0.9144803881645203\n",
      "성능 및 손실 개선이 없어서 287 EPOCH에 학습 중단\n",
      "pre_val : [101.9229965209961, 67.47466278076172, 237.53274536132812, 248.84007263183594, 9.018862101584091e-07, 73.6471176147461, 205.064697265625, 55.74952697753906, 227.16635131835938, 110.36470794677734]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[288 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169463491839962\n",
      "- TRAIN MAPE LOSS : 0.31429573230757996\n",
      "- TRAIN MSE LOSS : 254.38442806110515\n",
      "- TRAIN R2 SCORE : 0.9553310802266314\n",
      "\n",
      "- TEST MAE LOSS : 9.197964668273926\n",
      "- TEST MAPE LOSS : 20863.962890625\n",
      "- TEST MSE LOSS : 510.3010559082031\n",
      "- TEST R2 SCORE : 0.9144803285598755\n",
      "성능 및 손실 개선이 없어서 288 EPOCH에 학습 중단\n",
      "pre_val : [101.92333221435547, 67.47551727294922, 237.5326385498047, 248.83990478515625, 9.34086301640491e-07, 73.64735412597656, 205.0646209716797, 55.749698638916016, 227.16627502441406, 110.36473846435547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[289 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169479315230896\n",
      "- TRAIN MAPE LOSS : 0.3137943567700319\n",
      "- TRAIN MSE LOSS : 254.38442092628745\n",
      "- TRAIN R2 SCORE : 0.9553310806267745\n",
      "\n",
      "- TEST MAE LOSS : 9.197980880737305\n",
      "- TEST MAPE LOSS : 20863.97265625\n",
      "- TEST MSE LOSS : 510.30133056640625\n",
      "- TEST R2 SCORE : 0.9144802689552307\n",
      "성능 및 손실 개선이 없어서 289 EPOCH에 학습 중단\n",
      "pre_val : [101.9237289428711, 67.4761734008789, 237.53256225585938, 248.83969116210938, 9.293978564528516e-07, 73.64771270751953, 205.0645294189453, 55.749778747558594, 227.166259765625, 110.36478424072266]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[290 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169495714294327\n",
      "- TRAIN MAPE LOSS : 0.3141642604690123\n",
      "- TRAIN MSE LOSS : 254.38439893922606\n",
      "- TRAIN R2 SCORE : 0.955331085445164\n",
      "\n",
      "- TEST MAE LOSS : 9.198001861572266\n",
      "- TEST MAPE LOSS : 20863.97265625\n",
      "- TEST MSE LOSS : 510.30181884765625\n",
      "- TEST R2 SCORE : 0.9144802093505859\n",
      "성능 및 손실 개선이 없어서 290 EPOCH에 학습 중단\n",
      "pre_val : [101.92401885986328, 67.4768295288086, 237.5325927734375, 248.83963012695312, 8.486048272970947e-07, 73.64794158935547, 205.06448364257812, 55.749977111816406, 227.16619873046875, 110.3648452758789]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[291 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169511519678823\n",
      "- TRAIN MAPE LOSS : 0.3137303627766929\n",
      "- TRAIN MSE LOSS : 254.38438552482978\n",
      "- TRAIN R2 SCORE : 0.9553310870790815\n",
      "\n",
      "- TEST MAE LOSS : 9.198020935058594\n",
      "- TEST MAPE LOSS : 20863.97265625\n",
      "- TEST MSE LOSS : 510.30224609375\n",
      "- TEST R2 SCORE : 0.9144801497459412\n",
      "성능 및 손실 개선이 없어서 291 EPOCH에 학습 중단\n",
      "pre_val : [101.9244613647461, 67.47746276855469, 237.5325164794922, 248.8394012451172, 9.397761004947824e-07, 73.64814758300781, 205.0644073486328, 55.7501106262207, 227.1661834716797, 110.36485290527344]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[292 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169527129926881\n",
      "- TRAIN MAPE LOSS : 0.3141997358869839\n",
      "- TRAIN MSE LOSS : 254.38437274479367\n",
      "- TRAIN R2 SCORE : 0.9553310909971491\n",
      "\n",
      "- TEST MAE LOSS : 9.198037147521973\n",
      "- TEST MAPE LOSS : 20863.978515625\n",
      "- TEST MSE LOSS : 510.3025207519531\n",
      "- TEST R2 SCORE : 0.9144800901412964\n",
      "성능 및 손실 개선이 없어서 292 EPOCH에 학습 중단\n",
      "pre_val : [101.92475891113281, 67.47830963134766, 237.53245544433594, 248.8393096923828, 9.195227903546765e-07, 73.64849090576172, 205.06439208984375, 55.750240325927734, 227.16610717773438, 110.36491394042969]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[293 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1695432576266205\n",
      "- TRAIN MAPE LOSS : 0.31368870096763113\n",
      "- TRAIN MSE LOSS : 254.38434989555734\n",
      "- TRAIN R2 SCORE : 0.9553310946317819\n",
      "\n",
      "- TEST MAE LOSS : 9.19805908203125\n",
      "- TEST MAPE LOSS : 20863.994140625\n",
      "- TEST MSE LOSS : 510.302978515625\n",
      "- TEST R2 SCORE : 0.9144799709320068\n",
      "성능 및 손실 개선이 없어서 293 EPOCH에 학습 중단\n",
      "pre_val : [101.9251480102539, 67.47884368896484, 237.5323944091797, 248.8391571044922, 9.305471166953794e-07, 73.64872741699219, 205.06434631347656, 55.75040817260742, 227.16610717773438, 110.3649673461914]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[294 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169560050497522\n",
      "- TRAIN MAPE LOSS : 0.31410704200709616\n",
      "- TRAIN MSE LOSS : 254.38434586798394\n",
      "- TRAIN R2 SCORE : 0.955331095031925\n",
      "\n",
      "- TEST MAE LOSS : 9.198077201843262\n",
      "- TEST MAPE LOSS : 20863.998046875\n",
      "- TEST MSE LOSS : 510.3032531738281\n",
      "- TEST R2 SCORE : 0.9144799709320068\n",
      "성능 및 손실 개선이 없어서 294 EPOCH에 학습 중단\n",
      "pre_val : [101.92549896240234, 67.47969818115234, 237.53231811523438, 248.83889770507812, 8.92292973730946e-07, 73.64901733398438, 205.064208984375, 55.75050354003906, 227.16603088378906, 110.36497497558594]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[295 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1695749736999295\n",
      "- TRAIN MAPE LOSS : 0.31392863012016653\n",
      "- TRAIN MSE LOSS : 254.38431869080017\n",
      "- TRAIN R2 SCORE : 0.955331100767309\n",
      "\n",
      "- TEST MAE LOSS : 9.19809627532959\n",
      "- TEST MAPE LOSS : 20863.99609375\n",
      "- TEST MSE LOSS : 510.3037414550781\n",
      "- TEST R2 SCORE : 0.9144798517227173\n",
      "성능 및 손실 개선이 없어서 295 EPOCH에 학습 중단\n",
      "pre_val : [101.92587280273438, 67.48043060302734, 237.53231811523438, 248.83883666992188, 9.89946784102358e-07, 73.6492919921875, 205.06422424316406, 55.750728607177734, 227.166015625, 110.36504364013672]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[296 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169591485336944\n",
      "- TRAIN MAPE LOSS : 0.31379725002429704\n",
      "- TRAIN MSE LOSS : 254.38430573630166\n",
      "- TRAIN R2 SCORE : 0.9553311026179707\n",
      "\n",
      "- TEST MAE LOSS : 9.198114395141602\n",
      "- TEST MAPE LOSS : 20864.01171875\n",
      "- TEST MSE LOSS : 510.3040466308594\n",
      "- TEST R2 SCORE : 0.9144798517227173\n",
      "성능 및 손실 개선이 없어서 296 EPOCH에 학습 중단\n",
      "pre_val : [101.9261474609375, 67.48104858398438, 237.5321807861328, 248.838623046875, 9.232355751009891e-07, 73.64958953857422, 205.06414794921875, 55.75084686279297, 227.16595458984375, 110.36505889892578]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[297 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169607656585587\n",
      "- TRAIN MAPE LOSS : 0.3139972606686862\n",
      "- TRAIN MSE LOSS : 254.38428643873522\n",
      "- TRAIN R2 SCORE : 0.9553311058691332\n",
      "\n",
      "- TEST MAE LOSS : 9.198134422302246\n",
      "- TEST MAPE LOSS : 20864.005859375\n",
      "- TEST MSE LOSS : 510.3045349121094\n",
      "- TEST R2 SCORE : 0.9144797325134277\n",
      "성능 및 손실 개선이 없어서 297 EPOCH에 학습 중단\n",
      "pre_val : [101.92669677734375, 67.48182678222656, 237.5321807861328, 248.83856201171875, 9.652034123064368e-07, 73.64981842041016, 205.0640869140625, 55.75098419189453, 227.16592407226562, 110.36510467529297]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[298 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1696229505872395\n",
      "- TRAIN MAPE LOSS : 0.3138140284994265\n",
      "- TRAIN MSE LOSS : 254.38428217854533\n",
      "- TRAIN R2 SCORE : 0.9553311067527824\n",
      "\n",
      "- TEST MAE LOSS : 9.198151588439941\n",
      "- TEST MAPE LOSS : 20864.021484375\n",
      "- TEST MSE LOSS : 510.3048400878906\n",
      "- TEST R2 SCORE : 0.914479672908783\n",
      "성능 및 손실 개선이 없어서 298 EPOCH에 학습 중단\n",
      "pre_val : [101.92691802978516, 67.48231506347656, 237.5320587158203, 248.83827209472656, 9.124638609137037e-07, 73.65010833740234, 205.06402587890625, 55.751129150390625, 227.1658935546875, 110.36516571044922]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[299 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169638958043985\n",
      "- TRAIN MAPE LOSS : 0.31397833166109934\n",
      "- TRAIN MSE LOSS : 254.38425177514137\n",
      "- TRAIN R2 SCORE : 0.955331112104696\n",
      "\n",
      "- TEST MAE LOSS : 9.198171615600586\n",
      "- TEST MAPE LOSS : 20864.01171875\n",
      "- TEST MSE LOSS : 510.30523681640625\n",
      "- TEST R2 SCORE : 0.9144796133041382\n",
      "성능 및 손실 개선이 없어서 299 EPOCH에 학습 중단\n",
      "pre_val : [101.92741394042969, 67.48316955566406, 237.53213500976562, 248.83824157714844, 9.478892479819478e-07, 73.65042114257812, 205.06398010253906, 55.75128173828125, 227.16583251953125, 110.36522674560547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[300 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16965563400642\n",
      "- TRAIN MAPE LOSS : 0.31393254384242153\n",
      "- TRAIN MSE LOSS : 254.38425076998197\n",
      "- TRAIN R2 SCORE : 0.9553311126048748\n",
      "\n",
      "- TEST MAE LOSS : 9.198190689086914\n",
      "- TEST MAPE LOSS : 20864.02734375\n",
      "- TEST MSE LOSS : 510.30560302734375\n",
      "- TEST R2 SCORE : 0.9144795536994934\n",
      "성능 및 손실 개선이 없어서 300 EPOCH에 학습 중단\n",
      "pre_val : [101.92762756347656, 67.4838638305664, 237.53196716308594, 248.8379669189453, 9.416349939783686e-07, 73.65064239501953, 205.0638885498047, 55.75142288208008, 227.16580200195312, 110.3652572631836]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[301 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169670749677644\n",
      "- TRAIN MAPE LOSS : 0.31418381815554797\n",
      "- TRAIN MSE LOSS : 254.3842258714796\n",
      "- TRAIN R2 SCORE : 0.9553311175566453\n",
      "\n",
      "- TEST MAE LOSS : 9.198209762573242\n",
      "- TEST MAPE LOSS : 20864.03125\n",
      "- TEST MSE LOSS : 510.3059997558594\n",
      "- TEST R2 SCORE : 0.9144794940948486\n",
      "성능 및 손실 개선이 없어서 301 EPOCH에 학습 중단\n",
      "pre_val : [101.92805480957031, 67.48445129394531, 237.531982421875, 248.83790588378906, 9.02476358533022e-07, 73.65093994140625, 205.0638885498047, 55.75155258178711, 227.165771484375, 110.36529541015625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[302 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169687265849614\n",
      "- TRAIN MAPE LOSS : 0.31343597954647107\n",
      "- TRAIN MSE LOSS : 254.38421348571777\n",
      "- TRAIN R2 SCORE : 0.9553311197074144\n",
      "\n",
      "- TEST MAE LOSS : 9.19822883605957\n",
      "- TEST MAPE LOSS : 20864.037109375\n",
      "- TEST MSE LOSS : 510.3063659667969\n",
      "- TEST R2 SCORE : 0.9144794344902039\n",
      "성능 및 손실 개선이 없어서 302 EPOCH에 학습 중단\n",
      "pre_val : [101.92837524414062, 67.48523712158203, 237.53175354003906, 248.837646484375, 9.36608444135345e-07, 73.65116882324219, 205.06378173828125, 55.75171661376953, 227.16571044921875, 110.36532592773438]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[303 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169702795268773\n",
      "- TRAIN MAPE LOSS : 0.3144924713916087\n",
      "- TRAIN MSE LOSS : 254.38420205389704\n",
      "- TRAIN R2 SCORE : 0.9553311214080223\n",
      "\n",
      "- TEST MAE LOSS : 9.198246002197266\n",
      "- TEST MAPE LOSS : 20864.044921875\n",
      "- TEST MSE LOSS : 510.3067932128906\n",
      "- TEST R2 SCORE : 0.9144793748855591\n",
      "성능 및 손실 개선이 없어서 303 EPOCH에 학습 중단\n",
      "pre_val : [101.92869567871094, 67.48590087890625, 237.5318145751953, 248.83746337890625, 8.84789756128157e-07, 73.65141296386719, 205.0636749267578, 55.75188064575195, 227.16561889648438, 110.3653564453125]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[304 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169718394179444\n",
      "- TRAIN MAPE LOSS : 0.3135060783699676\n",
      "- TRAIN MSE LOSS : 254.38418293719525\n",
      "- TRAIN R2 SCORE : 0.9553311250259826\n",
      "\n",
      "- TEST MAE LOSS : 9.198265075683594\n",
      "- TEST MAPE LOSS : 20864.041015625\n",
      "- TEST MSE LOSS : 510.3071594238281\n",
      "- TEST R2 SCORE : 0.9144793152809143\n",
      "성능 및 손실 개선이 없어서 304 EPOCH에 학습 중단\n",
      "pre_val : [101.92910766601562, 67.48657989501953, 237.5316925048828, 248.8373565673828, 9.830346243688837e-07, 73.65176391601562, 205.06369018554688, 55.75202560424805, 227.1656494140625, 110.36541748046875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[305 / 1000]\n",
      "- TRAIN MAE LOSS : 7.16973517064448\n",
      "- TRAIN MAPE LOSS : 0.3140327149978676\n",
      "- TRAIN MSE LOSS : 254.38417044046042\n",
      "- TRAIN R2 SCORE : 0.9553311269933528\n",
      "\n",
      "- TEST MAE LOSS : 9.198287010192871\n",
      "- TEST MAPE LOSS : 20864.05078125\n",
      "- TEST MSE LOSS : 510.3076171875\n",
      "- TEST R2 SCORE : 0.9144792556762695\n",
      "성능 및 손실 개선이 없어서 305 EPOCH에 학습 중단\n",
      "pre_val : [101.92936706542969, 67.48714447021484, 237.53167724609375, 248.83717346191406, 9.473606041865423e-07, 73.6519775390625, 205.0635986328125, 55.75218200683594, 227.16558837890625, 110.36546325683594]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[306 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169751196174355\n",
      "- TRAIN MAPE LOSS : 0.3138197695807769\n",
      "- TRAIN MSE LOSS : 254.3841662528298\n",
      "- TRAIN R2 SCORE : 0.9553311285439071\n",
      "\n",
      "- TEST MAE LOSS : 9.198304176330566\n",
      "- TEST MAPE LOSS : 20864.060546875\n",
      "- TEST MSE LOSS : 510.30792236328125\n",
      "- TEST R2 SCORE : 0.91447913646698\n",
      "성능 및 손실 개선이 없어서 306 EPOCH에 학습 중단\n",
      "pre_val : [101.9298324584961, 67.48805236816406, 237.5316619873047, 248.83714294433594, 9.606532103134668e-07, 73.65225982666016, 205.06358337402344, 55.7523078918457, 227.16555786132812, 110.36549377441406]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[307 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169766208808739\n",
      "- TRAIN MAPE LOSS : 0.3139632591323836\n",
      "- TRAIN MSE LOSS : 254.3841249463275\n",
      "- TRAIN R2 SCORE : 0.9553311358131729\n",
      "\n",
      "- TEST MAE LOSS : 9.198322296142578\n",
      "- TEST MAPE LOSS : 20864.064453125\n",
      "- TEST MSE LOSS : 510.3083190917969\n",
      "- TEST R2 SCORE : 0.91447913646698\n",
      "성능 및 손실 개선이 없어서 307 EPOCH에 학습 중단\n",
      "pre_val : [101.9300537109375, 67.48849487304688, 237.5315704345703, 248.8368682861328, 9.244281500286888e-07, 73.6525650024414, 205.0634765625, 55.75246810913086, 227.16549682617188, 110.36556243896484]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[308 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169783150266101\n",
      "- TRAIN MAPE LOSS : 0.31381356103541136\n",
      "- TRAIN MSE LOSS : 254.38413254211\n",
      "- TRAIN R2 SCORE : 0.9553311346627615\n",
      "\n",
      "- TEST MAE LOSS : 9.198342323303223\n",
      "- TEST MAPE LOSS : 20864.064453125\n",
      "- TEST MSE LOSS : 510.3087463378906\n",
      "- TEST R2 SCORE : 0.9144790172576904\n",
      "성능 및 손실 개선이 없어서 308 EPOCH에 학습 중단\n",
      "pre_val : [101.93048858642578, 67.48928833007812, 237.53155517578125, 248.83677673339844, 9.200482509186259e-07, 73.65276336669922, 205.06341552734375, 55.752601623535156, 227.1654815673828, 110.36555480957031]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[309 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169798466409003\n",
      "- TRAIN MAPE LOSS : 0.31399925713824645\n",
      "- TRAIN MSE LOSS : 254.3841114412321\n",
      "- TRAIN R2 SCORE : 0.9553311385141386\n",
      "\n",
      "- TEST MAE LOSS : 9.198358535766602\n",
      "- TEST MAPE LOSS : 20864.064453125\n",
      "- TEST MSE LOSS : 510.30908203125\n",
      "- TEST R2 SCORE : 0.9144789576530457\n",
      "성능 및 손실 개선이 없어서 309 EPOCH에 학습 중단\n",
      "pre_val : [101.9307632446289, 67.48995208740234, 237.5314483642578, 248.83653259277344, 9.439961559110088e-07, 73.65304565429688, 205.06333923339844, 55.752784729003906, 227.1654052734375, 110.3656005859375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[310 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1698137880205275\n",
      "- TRAIN MAPE LOSS : 0.3137160435610718\n",
      "- TRAIN MSE LOSS : 254.38408946324063\n",
      "- TRAIN R2 SCORE : 0.9553311425822598\n",
      "\n",
      "- TEST MAE LOSS : 9.198380470275879\n",
      "- TEST MAPE LOSS : 20864.07421875\n",
      "- TEST MSE LOSS : 510.30950927734375\n",
      "- TEST R2 SCORE : 0.9144788980484009\n",
      "성능 및 손실 개선이 없어서 310 EPOCH에 학습 중단\n",
      "pre_val : [101.93132019042969, 67.49073028564453, 237.5313720703125, 248.83645629882812, 9.647995966588496e-07, 73.65335083007812, 205.06333923339844, 55.75288772583008, 227.1654052734375, 110.36566162109375]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[311 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169830858123886\n",
      "- TRAIN MAPE LOSS : 0.31387201487132305\n",
      "- TRAIN MSE LOSS : 254.3840885839929\n",
      "- TRAIN R2 SCORE : 0.9553311429657303\n",
      "\n",
      "- TEST MAE LOSS : 9.198399543762207\n",
      "- TEST MAPE LOSS : 20864.080078125\n",
      "- TEST MSE LOSS : 510.3098449707031\n",
      "- TEST R2 SCORE : 0.9144788384437561\n",
      "성능 및 손실 개선이 없어서 311 EPOCH에 학습 중단\n",
      "pre_val : [101.93153381347656, 67.49134826660156, 237.53138732910156, 248.8363037109375, 8.696250688444707e-07, 73.65360260009766, 205.06320190429688, 55.75303268432617, 227.1653289794922, 110.36569213867188]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[312 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169846688317252\n",
      "- TRAIN MAPE LOSS : 0.3138442461812621\n",
      "- TRAIN MSE LOSS : 254.38406470878974\n",
      "- TRAIN R2 SCORE : 0.9553311471338872\n",
      "\n",
      "- TEST MAE LOSS : 9.198418617248535\n",
      "- TEST MAPE LOSS : 20864.07421875\n",
      "- TEST MSE LOSS : 510.31036376953125\n",
      "- TEST R2 SCORE : 0.9144787788391113\n",
      "성능 및 손실 개선이 없어서 312 EPOCH에 학습 중단\n",
      "pre_val : [101.93196868896484, 67.49200439453125, 237.53131103515625, 248.836181640625, 9.20695470085775e-07, 73.65390014648438, 205.0631866455078, 55.75315856933594, 227.1653289794922, 110.36573791503906]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[313 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169863594828786\n",
      "- TRAIN MAPE LOSS : 0.313696705275378\n",
      "- TRAIN MSE LOSS : 254.38407335614824\n",
      "- TRAIN R2 SCORE : 0.9553311456166781\n",
      "\n",
      "- TEST MAE LOSS : 9.198437690734863\n",
      "- TEST MAPE LOSS : 20864.078125\n",
      "- TEST MSE LOSS : 510.3106994628906\n",
      "- TEST R2 SCORE : 0.9144787192344666\n",
      "성능 및 손실 개선이 없어서 313 EPOCH에 학습 중단\n",
      "pre_val : [101.93228149414062, 67.49272155761719, 237.53121948242188, 248.83596801757812, 8.765521215536864e-07, 73.65410614013672, 205.06309509277344, 55.75332260131836, 227.165283203125, 110.36576843261719]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[314 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169878933646462\n",
      "- TRAIN MAPE LOSS : 0.31412233888894525\n",
      "- TRAIN MSE LOSS : 254.3840426278281\n",
      "- TRAIN R2 SCORE : 0.9553311509685917\n",
      "\n",
      "- TEST MAE LOSS : 9.198455810546875\n",
      "- TEST MAPE LOSS : 20864.0859375\n",
      "- TEST MSE LOSS : 510.3111267089844\n",
      "- TEST R2 SCORE : 0.9144786596298218\n",
      "성능 및 손실 개선이 없어서 314 EPOCH에 학습 중단\n",
      "pre_val : [101.93265533447266, 67.49352264404297, 237.5311279296875, 248.83575439453125, 9.286343356507132e-07, 73.65438842773438, 205.06304931640625, 55.75349044799805, 227.1652374267578, 110.36581420898438]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[315 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169894753769561\n",
      "- TRAIN MAPE LOSS : 0.31357078853499637\n",
      "- TRAIN MSE LOSS : 254.3840393786664\n",
      "- TRAIN R2 SCORE : 0.9553311518522409\n",
      "\n",
      "- TEST MAE LOSS : 9.198474884033203\n",
      "- TEST MAPE LOSS : 20864.087890625\n",
      "- TEST MSE LOSS : 510.3115234375\n",
      "- TEST R2 SCORE : 0.9144785404205322\n",
      "성능 및 손실 개선이 없어서 315 EPOCH에 학습 중단\n",
      "pre_val : [101.9329605102539, 67.49398040771484, 237.5310516357422, 248.83563232421875, 8.694262305652956e-07, 73.6546859741211, 205.06301879882812, 55.75361251831055, 227.16522216796875, 110.36585235595703]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[316 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169911381714828\n",
      "- TRAIN MAPE LOSS : 0.31407906601479\n",
      "- TRAIN MSE LOSS : 254.3840274367966\n",
      "- TRAIN R2 SCORE : 0.9553311539029742\n",
      "\n",
      "- TEST MAE LOSS : 9.198495864868164\n",
      "- TEST MAPE LOSS : 20864.0859375\n",
      "- TEST MSE LOSS : 510.3118896484375\n",
      "- TEST R2 SCORE : 0.9144785404205322\n",
      "성능 및 손실 개선이 없어서 316 EPOCH에 학습 중단\n",
      "pre_val : [101.93338012695312, 67.49472045898438, 237.53102111816406, 248.83543395996094, 9.45855049394595e-07, 73.65494537353516, 205.06292724609375, 55.75374984741211, 227.16519165039062, 110.36591339111328]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[317 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169926928073377\n",
      "- TRAIN MAPE LOSS : 0.3137023882349054\n",
      "- TRAIN MSE LOSS : 254.38400558951852\n",
      "- TRAIN R2 SCORE : 0.9553311578210417\n",
      "\n",
      "- TEST MAE LOSS : 9.19851303100586\n",
      "- TEST MAPE LOSS : 20864.087890625\n",
      "- TEST MSE LOSS : 510.3123474121094\n",
      "- TEST R2 SCORE : 0.9144784212112427\n",
      "성능 및 손실 개선이 없어서 317 EPOCH에 학습 중단\n",
      "pre_val : [101.9336929321289, 67.49553680419922, 237.531005859375, 248.83531188964844, 9.152994380201562e-07, 73.65519714355469, 205.06285095214844, 55.7539176940918, 227.16513061523438, 110.36593627929688]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[318 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169943196823547\n",
      "- TRAIN MAPE LOSS : 0.31409929246283497\n",
      "- TRAIN MSE LOSS : 254.38399245468887\n",
      "- TRAIN R2 SCORE : 0.9553311597884118\n",
      "\n",
      "- TEST MAE LOSS : 9.19853401184082\n",
      "- TEST MAPE LOSS : 20864.09375\n",
      "- TEST MSE LOSS : 510.3127746582031\n",
      "- TEST R2 SCORE : 0.9144783616065979\n",
      "성능 및 손실 개선이 없어서 318 EPOCH에 학습 중단\n",
      "pre_val : [101.93397521972656, 67.49602508544922, 237.53094482421875, 248.83517456054688, 8.54225277180376e-07, 73.65545654296875, 205.06277465820312, 55.7540283203125, 227.16505432128906, 110.36597442626953]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[319 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169959450101519\n",
      "- TRAIN MAPE LOSS : 0.3135146330187579\n",
      "- TRAIN MSE LOSS : 254.38398659766136\n",
      "- TRAIN R2 SCORE : 0.9553311616724187\n",
      "\n",
      "- TEST MAE LOSS : 9.198552131652832\n",
      "- TEST MAPE LOSS : 20864.09375\n",
      "- TEST MSE LOSS : 510.3130798339844\n",
      "- TEST R2 SCORE : 0.9144783020019531\n",
      "성능 및 손실 개선이 없어서 319 EPOCH에 학습 중단\n",
      "pre_val : [101.9344482421875, 67.49691772460938, 237.5309295654297, 248.8350372314453, 9.60510647018964e-07, 73.65575408935547, 205.062744140625, 55.75419616699219, 227.16500854492188, 110.36601257324219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[320 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169974966382647\n",
      "- TRAIN MAPE LOSS : 0.31416495893853946\n",
      "- TRAIN MSE LOSS : 254.38396879663\n",
      "- TRAIN R2 SCORE : 0.9553311645901287\n",
      "\n",
      "- TEST MAE LOSS : 9.198569297790527\n",
      "- TEST MAPE LOSS : 20864.103515625\n",
      "- TEST MSE LOSS : 510.3135070800781\n",
      "- TEST R2 SCORE : 0.9144782423973083\n",
      "성능 및 손실 개선이 없어서 320 EPOCH에 학습 중단\n",
      "pre_val : [101.93463897705078, 67.4973373413086, 237.5308380126953, 248.83485412597656, 9.279026471631369e-07, 73.65599822998047, 205.06265258789062, 55.75432586669922, 227.1649932861328, 110.36605072021484]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[321 / 1000]\n",
      "- TRAIN MAE LOSS : 7.169991132095977\n",
      "- TRAIN MAPE LOSS : 0.3135188772643988\n",
      "- TRAIN MSE LOSS : 254.38395857750953\n",
      "- TRAIN R2 SCORE : 0.9553311661573557\n",
      "\n",
      "- TEST MAE LOSS : 9.198590278625488\n",
      "- TEST MAPE LOSS : 20864.095703125\n",
      "- TEST MSE LOSS : 510.31390380859375\n",
      "- TEST R2 SCORE : 0.9144781827926636\n",
      "성능 및 손실 개선이 없어서 321 EPOCH에 학습 중단\n",
      "pre_val : [101.93516540527344, 67.49821472167969, 237.53079223632812, 248.83474731445312, 9.548635944156558e-07, 73.65628814697266, 205.06265258789062, 55.754486083984375, 227.1649627685547, 110.36609649658203]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[322 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170007474805925\n",
      "- TRAIN MAPE LOSS : 0.31423602632969827\n",
      "- TRAIN MSE LOSS : 254.3839526223136\n",
      "- TRAIN R2 SCORE : 0.9553311676578922\n",
      "\n",
      "- TEST MAE LOSS : 9.1986083984375\n",
      "- TEST MAPE LOSS : 20864.11328125\n",
      "- TEST MSE LOSS : 510.3143005371094\n",
      "- TEST R2 SCORE : 0.9144781231880188\n",
      "성능 및 손실 개선이 없어서 322 EPOCH에 학습 중단\n",
      "pre_val : [101.93537139892578, 67.49880981445312, 237.53076171875, 248.83457946777344, 9.741547728481237e-07, 73.65653991699219, 205.06253051757812, 55.75461959838867, 227.16490173339844, 110.36612701416016]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[323 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170023134871796\n",
      "- TRAIN MAPE LOSS : 0.31373279755922046\n",
      "- TRAIN MSE LOSS : 254.38392796389707\n",
      "- TRAIN R2 SCORE : 0.9553311720761386\n",
      "\n",
      "- TEST MAE LOSS : 9.198627471923828\n",
      "- TEST MAPE LOSS : 20864.103515625\n",
      "- TEST MSE LOSS : 510.314697265625\n",
      "- TEST R2 SCORE : 0.914478063583374\n",
      "성능 및 손실 개선이 없어서 323 EPOCH에 학습 중단\n",
      "pre_val : [101.93588256835938, 67.49951934814453, 237.5306854248047, 248.8344268798828, 8.923518635128858e-07, 73.65679168701172, 205.0625, 55.75476837158203, 227.16490173339844, 110.36620330810547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[324 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170040172763637\n",
      "- TRAIN MAPE LOSS : 0.3137747092800332\n",
      "- TRAIN MSE LOSS : 254.38393431710196\n",
      "- TRAIN R2 SCORE : 0.955331170442221\n",
      "\n",
      "- TEST MAE LOSS : 9.198648452758789\n",
      "- TEST MAPE LOSS : 20864.1171875\n",
      "- TEST MSE LOSS : 510.3150634765625\n",
      "- TEST R2 SCORE : 0.9144779443740845\n",
      "성능 및 손실 개선이 없어서 324 EPOCH에 학습 중단\n",
      "pre_val : [101.9361343383789, 67.50020599365234, 237.53060913085938, 248.83425903320312, 9.499462976236828e-07, 73.6571044921875, 205.06240844726562, 55.754913330078125, 227.16481018066406, 110.36620330810547]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[325 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170055736061577\n",
      "- TRAIN MAPE LOSS : 0.3139443609639481\n",
      "- TRAIN MSE LOSS : 254.38391241380384\n",
      "- TRAIN R2 SCORE : 0.9553311749938485\n",
      "\n",
      "- TEST MAE LOSS : 9.1986665725708\n",
      "- TEST MAPE LOSS : 20864.107421875\n",
      "- TEST MSE LOSS : 510.3155212402344\n",
      "- TEST R2 SCORE : 0.9144778847694397\n",
      "성능 및 손실 개선이 없어서 325 EPOCH에 학습 중단\n",
      "pre_val : [101.93657684326172, 67.50098419189453, 237.5305633544922, 248.83412170410156, 8.703221965333796e-07, 73.65726470947266, 205.0623779296875, 55.755088806152344, 227.16481018066406, 110.36622619628906]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[326 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170071072478394\n",
      "- TRAIN MAPE LOSS : 0.3138252702376226\n",
      "- TRAIN MSE LOSS : 254.3839047732053\n",
      "- TRAIN R2 SCORE : 0.9553311757274441\n",
      "\n",
      "- TEST MAE LOSS : 9.198684692382812\n",
      "- TEST MAPE LOSS : 20864.123046875\n",
      "- TEST MSE LOSS : 510.3158874511719\n",
      "- TEST R2 SCORE : 0.9144778251647949\n",
      "성능 및 손실 개선이 없어서 326 EPOCH에 학습 중단\n",
      "pre_val : [101.936767578125, 67.50148010253906, 237.53048706054688, 248.833984375, 8.614354101155186e-07, 73.65764617919922, 205.06231689453125, 55.755184173583984, 227.16476440429688, 110.3663101196289]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[327 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170087603122204\n",
      "- TRAIN MAPE LOSS : 0.313777113375026\n",
      "- TRAIN MSE LOSS : 254.38388880162805\n",
      "- TRAIN R2 SCORE : 0.9553311791620055\n",
      "\n",
      "- TEST MAE LOSS : 9.19870376586914\n",
      "- TEST MAPE LOSS : 20864.125\n",
      "- TEST MSE LOSS : 510.3162841796875\n",
      "- TEST R2 SCORE : 0.9144777655601501\n",
      "성능 및 손실 개선이 없어서 327 EPOCH에 학습 중단\n",
      "pre_val : [101.93722534179688, 67.502197265625, 237.53045654296875, 248.83375549316406, 9.963723641703837e-07, 73.65780639648438, 205.06222534179688, 55.75532913208008, 227.1647186279297, 110.36631774902344]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[328 / 1000]\n",
      "- TRAIN MAE LOSS : 7.17010285977717\n",
      "- TRAIN MAPE LOSS : 0.31386514502649127\n",
      "- TRAIN MSE LOSS : 254.38387625847662\n",
      "- TRAIN R2 SCORE : 0.9553311814461555\n",
      "\n",
      "- TEST MAE LOSS : 9.198721885681152\n",
      "- TEST MAPE LOSS : 20864.12890625\n",
      "- TEST MSE LOSS : 510.316650390625\n",
      "- TEST R2 SCORE : 0.9144777059555054\n",
      "성능 및 손실 개선이 없어서 328 EPOCH에 학습 중단\n",
      "pre_val : [101.93751525878906, 67.50285339355469, 237.53042602539062, 248.8336944580078, 8.76725039233861e-07, 73.6580581665039, 205.06214904785156, 55.7555046081543, 227.1646728515625, 110.3663558959961]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[329 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170118680700556\n",
      "- TRAIN MAPE LOSS : 0.3138137423835851\n",
      "- TRAIN MSE LOSS : 254.3838599907935\n",
      "- TRAIN R2 SCORE : 0.9553311836302697\n",
      "\n",
      "- TEST MAE LOSS : 9.19874095916748\n",
      "- TEST MAPE LOSS : 20864.134765625\n",
      "- TEST MSE LOSS : 510.31707763671875\n",
      "- TEST R2 SCORE : 0.9144776463508606\n",
      "성능 및 손실 개선이 없어서 329 EPOCH에 학습 중단\n",
      "pre_val : [101.93790435791016, 67.5035400390625, 237.5303192138672, 248.83343505859375, 9.35052526074287e-07, 73.65837097167969, 205.06210327148438, 55.755638122558594, 227.1646728515625, 110.36641693115234]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[330 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170134861886084\n",
      "- TRAIN MAPE LOSS : 0.313651145536687\n",
      "- TRAIN MSE LOSS : 254.3838492125398\n",
      "- TRAIN R2 SCORE : 0.9553311869147775\n",
      "\n",
      "- TEST MAE LOSS : 9.198760986328125\n",
      "- TEST MAPE LOSS : 20864.125\n",
      "- TEST MSE LOSS : 510.3174743652344\n",
      "- TEST R2 SCORE : 0.9144775867462158\n",
      "성능 및 손실 개선이 없어서 330 EPOCH에 학습 중단\n",
      "pre_val : [101.93819427490234, 67.50419616699219, 237.53028869628906, 248.8333740234375, 9.109716074817698e-07, 73.6585693359375, 205.06202697753906, 55.75579833984375, 227.16458129882812, 110.36641693115234]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[331 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170150769240372\n",
      "- TRAIN MAPE LOSS : 0.31414768907625773\n",
      "- TRAIN MSE LOSS : 254.38384536262993\n",
      "- TRAIN R2 SCORE : 0.9553311869481227\n",
      "\n",
      "- TEST MAE LOSS : 9.19878101348877\n",
      "- TEST MAPE LOSS : 20864.13671875\n",
      "- TEST MSE LOSS : 510.3179016113281\n",
      "- TEST R2 SCORE : 0.9144774675369263\n",
      "성능 및 손실 개선이 없어서 331 EPOCH에 학습 중단\n",
      "pre_val : [101.93867492675781, 67.50504302978516, 237.53024291992188, 248.8331756591797, 9.728586292112595e-07, 73.65894317626953, 205.06198120117188, 55.75593948364258, 227.16456604003906, 110.36650085449219]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[332 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170167717566857\n",
      "- TRAIN MAPE LOSS : 0.3133980236754759\n",
      "- TRAIN MSE LOSS : 254.38383203253045\n",
      "- TRAIN R2 SCORE : 0.9553311891989275\n",
      "\n",
      "- TEST MAE LOSS : 9.198800086975098\n",
      "- TEST MAPE LOSS : 20864.140625\n",
      "- TEST MSE LOSS : 510.3182373046875\n",
      "- TEST R2 SCORE : 0.9144774675369263\n",
      "성능 및 손실 개선이 없어서 332 EPOCH에 학습 중단\n",
      "pre_val : [101.93893432617188, 67.50558471679688, 237.5301971435547, 248.83306884765625, 9.457349960939609e-07, 73.65914916992188, 205.06192016601562, 55.75611114501953, 227.16452026367188, 110.36653137207031]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[333 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170183569834783\n",
      "- TRAIN MAPE LOSS : 0.3142413578667007\n",
      "- TRAIN MSE LOSS : 254.38382588900052\n",
      "- TRAIN R2 SCORE : 0.9553311905327376\n",
      "\n",
      "- TEST MAE LOSS : 9.19881820678711\n",
      "- TEST MAPE LOSS : 20864.140625\n",
      "- TEST MSE LOSS : 510.31866455078125\n",
      "- TEST R2 SCORE : 0.9144773483276367\n",
      "성능 및 손실 개선이 없어서 333 EPOCH에 학습 중단\n",
      "pre_val : [101.93919372558594, 67.5062255859375, 237.530029296875, 248.8328399658203, 8.675547178427223e-07, 73.65937805175781, 205.06179809570312, 55.75621032714844, 227.16445922851562, 110.36654663085938]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[334 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170198807949786\n",
      "- TRAIN MAPE LOSS : 0.31353017903603875\n",
      "- TRAIN MSE LOSS : 254.38380945699197\n",
      "- TRAIN R2 SCORE : 0.9553311941173527\n",
      "\n",
      "- TEST MAE LOSS : 9.198836326599121\n",
      "- TEST MAPE LOSS : 20864.138671875\n",
      "- TEST MSE LOSS : 510.31903076171875\n",
      "- TEST R2 SCORE : 0.9144772887229919\n",
      "성능 및 손실 개선이 없어서 334 EPOCH에 학습 중단\n",
      "pre_val : [101.93968200683594, 67.50695037841797, 237.5301055908203, 248.832763671875, 9.522691470920108e-07, 73.65969848632812, 205.0618133544922, 55.756385803222656, 227.16444396972656, 110.36660766601562]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[335 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170215586415537\n",
      "- TRAIN MAPE LOSS : 0.31387665775741314\n",
      "- TRAIN MSE LOSS : 254.38380014646305\n",
      "- TRAIN R2 SCORE : 0.9553311952010735\n",
      "\n",
      "- TEST MAE LOSS : 9.198857307434082\n",
      "- TEST MAPE LOSS : 20864.1484375\n",
      "- TEST MSE LOSS : 510.3194885253906\n",
      "- TEST R2 SCORE : 0.9144772291183472\n",
      "성능 및 손실 개선이 없어서 335 EPOCH에 학습 중단\n",
      "pre_val : [101.93998718261719, 67.50755310058594, 237.5299530029297, 248.83253479003906, 9.444651141166105e-07, 73.65991973876953, 205.0617218017578, 55.75649642944336, 227.1644287109375, 110.36662292480469]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[336 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170231653827054\n",
      "- TRAIN MAPE LOSS : 0.3138838754250453\n",
      "- TRAIN MSE LOSS : 254.38379340485258\n",
      "- TRAIN R2 SCORE : 0.9553311965849016\n",
      "\n",
      "- TEST MAE LOSS : 9.198874473571777\n",
      "- TEST MAPE LOSS : 20864.15625\n",
      "- TEST MSE LOSS : 510.3197937011719\n",
      "- TEST R2 SCORE : 0.9144771695137024\n",
      "성능 및 손실 개선이 없어서 336 EPOCH에 학습 중단\n",
      "pre_val : [101.94034576416016, 67.50822448730469, 237.52996826171875, 248.83241271972656, 9.241693987860344e-07, 73.66023254394531, 205.06163024902344, 55.756595611572266, 227.1643829345703, 110.36668395996094]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[337 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170247295619724\n",
      "- TRAIN MAPE LOSS : 0.3139362880056138\n",
      "- TRAIN MSE LOSS : 254.38377457945498\n",
      "- TRAIN R2 SCORE : 0.9553312006196776\n",
      "\n",
      "- TEST MAE LOSS : 9.198893547058105\n",
      "- TEST MAPE LOSS : 20864.1484375\n",
      "- TEST MSE LOSS : 510.3202209472656\n",
      "- TEST R2 SCORE : 0.9144771099090576\n",
      "성능 및 손실 개선이 없어서 337 EPOCH에 학습 중단\n",
      "pre_val : [101.94070434570312, 67.50880432128906, 237.52987670898438, 248.83224487304688, 9.019851177072269e-07, 73.66048431396484, 205.0615997314453, 55.75675964355469, 227.16432189941406, 110.36673736572266]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[338 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1702636526014425\n",
      "- TRAIN MAPE LOSS : 0.3136380308736246\n",
      "- TRAIN MSE LOSS : 254.38377525649705\n",
      "- TRAIN R2 SCORE : 0.9553311997193557\n",
      "\n",
      "- TEST MAE LOSS : 9.19891357421875\n",
      "- TEST MAPE LOSS : 20864.154296875\n",
      "- TEST MSE LOSS : 510.32061767578125\n",
      "- TEST R2 SCORE : 0.9144770503044128\n",
      "성능 및 손실 개선이 없어서 338 EPOCH에 학습 중단\n",
      "pre_val : [101.94110870361328, 67.50960540771484, 237.52984619140625, 248.83209228515625, 9.02758529264247e-07, 73.66069793701172, 205.0615234375, 55.75690841674805, 227.164306640625, 110.36676025390625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[339 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170279280655867\n",
      "- TRAIN MAPE LOSS : 0.31400222563399716\n",
      "- TRAIN MSE LOSS : 254.3837553411097\n",
      "- TRAIN R2 SCORE : 0.9553312033206433\n",
      "\n",
      "- TEST MAE LOSS : 9.198931694030762\n",
      "- TEST MAPE LOSS : 20864.16015625\n",
      "- TEST MSE LOSS : 510.3209533691406\n",
      "- TEST R2 SCORE : 0.9144769906997681\n",
      "성능 및 손실 개선이 없어서 339 EPOCH에 학습 중단\n",
      "pre_val : [101.94135284423828, 67.51032257080078, 237.5297393798828, 248.8319549560547, 9.356609780297731e-07, 73.66098022460938, 205.06146240234375, 55.757076263427734, 227.16427612304688, 110.36679077148438]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[340 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170295349401194\n",
      "- TRAIN MAPE LOSS : 0.31369028979091795\n",
      "- TRAIN MSE LOSS : 254.38374046165626\n",
      "- TRAIN R2 SCORE : 0.9553312059382458\n",
      "\n",
      "- TEST MAE LOSS : 9.19895076751709\n",
      "- TEST MAPE LOSS : 20864.166015625\n",
      "- TEST MSE LOSS : 510.3214111328125\n",
      "- TEST R2 SCORE : 0.9144769310951233\n",
      "성능 및 손실 개선이 없어서 340 EPOCH에 학습 중단\n",
      "pre_val : [101.94178009033203, 67.51084899902344, 237.5297088623047, 248.831787109375, 9.053761687027873e-07, 73.66120910644531, 205.06137084960938, 55.7572021484375, 227.16421508789062, 110.3668441772461]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[341 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170311516448335\n",
      "- TRAIN MAPE LOSS : 0.31376565277889057\n",
      "- TRAIN MSE LOSS : 254.38373863273569\n",
      "- TRAIN R2 SCORE : 0.9553312069052583\n",
      "\n",
      "- TEST MAE LOSS : 9.198970794677734\n",
      "- TEST MAPE LOSS : 20864.16015625\n",
      "- TEST MSE LOSS : 510.3218078613281\n",
      "- TEST R2 SCORE : 0.9144768714904785\n",
      "성능 및 손실 개선이 없어서 341 EPOCH에 학습 중단\n",
      "pre_val : [101.94205474853516, 67.5116195678711, 237.5296173095703, 248.8316650390625, 9.548612069920637e-07, 73.66151428222656, 205.06130981445312, 55.757320404052734, 227.1641845703125, 110.36685943603516]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[342 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170327347508677\n",
      "- TRAIN MAPE LOSS : 0.3139047554755336\n",
      "- TRAIN MSE LOSS : 254.38372603356422\n",
      "- TRAIN R2 SCORE : 0.9553312088392831\n",
      "\n",
      "- TEST MAE LOSS : 9.198988914489746\n",
      "- TEST MAPE LOSS : 20864.1640625\n",
      "- TEST MSE LOSS : 510.3222351074219\n",
      "- TEST R2 SCORE : 0.914476752281189\n",
      "성능 및 손실 개선이 없어서 342 EPOCH에 학습 중단\n",
      "pre_val : [101.94248962402344, 67.51237487792969, 237.52964782714844, 248.83152770996094, 1.0143468216483598e-06, 73.66173553466797, 205.061279296875, 55.757484436035156, 227.16415405273438, 110.3669204711914]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[343 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170343085535756\n",
      "- TRAIN MAPE LOSS : 0.3136646237891246\n",
      "- TRAIN MSE LOSS : 254.38371527718496\n",
      "- TRAIN R2 SCORE : 0.9553312111901237\n",
      "\n",
      "- TEST MAE LOSS : 9.199007034301758\n",
      "- TEST MAPE LOSS : 20864.173828125\n",
      "- TEST MSE LOSS : 510.322509765625\n",
      "- TEST R2 SCORE : 0.914476752281189\n",
      "성능 및 손실 개선이 없어서 343 EPOCH에 학습 중단\n",
      "pre_val : [101.94270324707031, 67.51294708251953, 237.5294952392578, 248.8313446044922, 8.69800942382426e-07, 73.6619644165039, 205.06121826171875, 55.757633209228516, 227.16412353515625, 110.36693572998047]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[344 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170358664305894\n",
      "- TRAIN MAPE LOSS : 0.3139885975363163\n",
      "- TRAIN MSE LOSS : 254.38370046922378\n",
      "- TRAIN R2 SCORE : 0.9553312133408927\n",
      "\n",
      "- TEST MAE LOSS : 9.19902515411377\n",
      "- TEST MAPE LOSS : 20864.181640625\n",
      "- TEST MSE LOSS : 510.32293701171875\n",
      "- TEST R2 SCORE : 0.9144766330718994\n",
      "성능 및 손실 개선이 없어서 344 EPOCH에 학습 중단\n",
      "pre_val : [101.9431381225586, 67.51366424560547, 237.5294952392578, 248.8311767578125, 9.251454002878745e-07, 73.66228485107422, 205.06114196777344, 55.75775146484375, 227.1640625, 110.36699676513672]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[345 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170374742521273\n",
      "- TRAIN MAPE LOSS : 0.31360313774405657\n",
      "- TRAIN MSE LOSS : 254.3836875904857\n",
      "- TRAIN R2 SCORE : 0.9553312156250426\n",
      "\n",
      "- TEST MAE LOSS : 9.199047088623047\n",
      "- TEST MAPE LOSS : 20864.173828125\n",
      "- TEST MSE LOSS : 510.32342529296875\n",
      "- TEST R2 SCORE : 0.9144765734672546\n",
      "성능 및 손실 개선이 없어서 345 EPOCH에 학습 중단\n",
      "pre_val : [101.94345092773438, 67.51422882080078, 237.5294189453125, 248.83108520507812, 9.371520945933298e-07, 73.66255187988281, 205.0610809326172, 55.757896423339844, 227.16403198242188, 110.36702728271484]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[346 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170392011695808\n",
      "- TRAIN MAPE LOSS : 0.31394573202760484\n",
      "- TRAIN MSE LOSS : 254.38368511493388\n",
      "- TRAIN R2 SCORE : 0.9553312157917689\n",
      "\n",
      "- TEST MAE LOSS : 9.199064254760742\n",
      "- TEST MAPE LOSS : 20864.173828125\n",
      "- TEST MSE LOSS : 510.3237609863281\n",
      "- TEST R2 SCORE : 0.9144765138626099\n",
      "성능 및 손실 개선이 없어서 346 EPOCH에 학습 중단\n",
      "pre_val : [101.9439468383789, 67.51498413085938, 237.5293731689453, 248.8309326171875, 9.041750672622584e-07, 73.66283416748047, 205.06106567382812, 55.75803756713867, 227.16400146484375, 110.36707305908203]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[347 / 1000]\n",
      "- TRAIN MAE LOSS : 7.1704078653642345\n",
      "- TRAIN MAPE LOSS : 0.31371167250707016\n",
      "- TRAIN MSE LOSS : 254.3836799621582\n",
      "- TRAIN R2 SCORE : 0.9553312174590317\n",
      "\n",
      "- TEST MAE LOSS : 9.199084281921387\n",
      "- TEST MAPE LOSS : 20864.1875\n",
      "- TEST MSE LOSS : 510.3241882324219\n",
      "- TEST R2 SCORE : 0.9144764542579651\n",
      "성능 및 손실 개선이 없어서 347 EPOCH에 학습 중단\n",
      "pre_val : [101.94414520263672, 67.51551818847656, 237.529296875, 248.83070373535156, 9.499309499005903e-07, 73.66300964355469, 205.06094360351562, 55.758182525634766, 227.1639404296875, 110.3670883178711]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[348 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170422330336137\n",
      "- TRAIN MAPE LOSS : 0.3140697650090381\n",
      "- TRAIN MSE LOSS : 254.3836478130634\n",
      "- TRAIN R2 SCORE : 0.9553312229276537\n",
      "\n",
      "- TEST MAE LOSS : 9.199101448059082\n",
      "- TEST MAPE LOSS : 20864.181640625\n",
      "- TEST MSE LOSS : 510.3245544433594\n",
      "- TEST R2 SCORE : 0.9144763946533203\n",
      "성능 및 손실 개선이 없어서 348 EPOCH에 학습 중단\n",
      "pre_val : [101.94453430175781, 67.5162124633789, 237.5292205810547, 248.8306121826172, 8.71201677909994e-07, 73.66329956054688, 205.0609130859375, 55.758338928222656, 227.16392517089844, 110.36714172363281]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[349 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170439389168799\n",
      "- TRAIN MAPE LOSS : 0.3133684109146153\n",
      "- TRAIN MSE LOSS : 254.3836579927031\n",
      "- TRAIN R2 SCORE : 0.9553312210936646\n",
      "\n",
      "- TEST MAE LOSS : 9.199121475219727\n",
      "- TEST MAPE LOSS : 20864.19921875\n",
      "- TEST MSE LOSS : 510.32489013671875\n",
      "- TEST R2 SCORE : 0.9144763350486755\n",
      "성능 및 손실 개선이 없어서 349 EPOCH에 학습 중단\n",
      "pre_val : [101.94486236572266, 67.51688385009766, 237.5292205810547, 248.83050537109375, 9.524338793198694e-07, 73.6635971069336, 205.06082153320312, 55.75845718383789, 227.16387939453125, 110.3671875]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[350 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170454429946579\n",
      "- TRAIN MAPE LOSS : 0.31420440003275873\n",
      "- TRAIN MSE LOSS : 254.38363423594228\n",
      "- TRAIN R2 SCORE : 0.9553312254452205\n",
      "\n",
      "- TEST MAE LOSS : 9.199138641357422\n",
      "- TEST MAPE LOSS : 20864.1875\n",
      "- TEST MSE LOSS : 510.32525634765625\n",
      "- TEST R2 SCORE : 0.9144762754440308\n",
      "성능 및 손실 개선이 없어서 350 EPOCH에 학습 중단\n",
      "pre_val : [101.94515228271484, 67.51759338378906, 237.52911376953125, 248.8302764892578, 9.15913346943853e-07, 73.66378021240234, 205.06076049804688, 55.75864791870117, 227.16383361816406, 110.36719512939453]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[351 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170470249802916\n",
      "- TRAIN MAPE LOSS : 0.3134222745759921\n",
      "- TRAIN MSE LOSS : 254.38362206732475\n",
      "- TRAIN R2 SCORE : 0.9553312275793169\n",
      "\n",
      "- TEST MAE LOSS : 9.199158668518066\n",
      "- TEST MAPE LOSS : 20864.1875\n",
      "- TEST MSE LOSS : 510.32574462890625\n",
      "- TEST R2 SCORE : 0.9144761562347412\n",
      "성능 및 손실 개선이 없어서 351 EPOCH에 학습 중단\n",
      "pre_val : [101.94557189941406, 67.5181884765625, 237.52908325195312, 248.8301544189453, 9.8869872999785e-07, 73.66410064697266, 205.0607147216797, 55.758731842041016, 227.163818359375, 110.36724853515625]\n",
      "y_val : [ 89  48 247 247   0  78 230  47 230 110]\n",
      "\n",
      "[352 / 1000]\n",
      "- TRAIN MAE LOSS : 7.170487075218787\n",
      "- TRAIN MAPE LOSS : 0.31391111528175275\n",
      "- TRAIN MSE LOSS : 254.38362753487968\n",
      "- TRAIN R2 SCORE : 0.9553312266123045\n",
      "\n",
      "- TEST MAE LOSS : 9.199175834655762\n",
      "- TEST MAPE LOSS : 20864.189453125\n",
      "- TEST MSE LOSS : 510.3260803222656\n",
      "- TEST R2 SCORE : 0.9144761562347412\n",
      "성능 및 손실 개선이 없어서 352 EPOCH에 학습 중단\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mae_loss, mape_loss, mse_loss, r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwater_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_y_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_trainDL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_y_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[19], line 22\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(testDF, testtargetDF, model, trainDL, test_value)\u001b[0m\n\u001b[0;32m     20\u001b[0m mae_loss \u001b[38;5;241m=\u001b[39m MAEloss(pre_y, targetTS)\n\u001b[0;32m     21\u001b[0m mape_loss \u001b[38;5;241m=\u001b[39m MAPEloss(pre_y, targetTS)\n\u001b[1;32m---> 22\u001b[0m mse_loss \u001b[38;5;241m=\u001b[39m \u001b[43mMSEloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpre_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargetTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m mae_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mae_loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     25\u001b[0m mape_loss_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m mape_loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torchmetrics\\metric.py:312\u001b[0m, in \u001b[0;36mMetric.forward\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_full_state_update(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    311\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 312\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_reduce_state_update\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_cache\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torchmetrics\\metric.py:381\u001b[0m, in \u001b[0;36mMetric._forward_reduce_state_update\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# allow grads for batch computation\u001b[39;00m\n\u001b[0;32m    380\u001b[0m \u001b[38;5;66;03m# calculate batch state and compute batch value\u001b[39;00m\n\u001b[1;32m--> 381\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m batch_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute()\n\u001b[0;32m    384\u001b[0m \u001b[38;5;66;03m# reduce batch and global state\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torchmetrics\\metric.py:483\u001b[0m, in \u001b[0;36mMetric._wrap_update.<locals>.wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_grad):\n\u001b[0;32m    482\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 483\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    485\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all tensors to be on\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(err):\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torchmetrics\\regression\\mse.py:102\u001b[0m, in \u001b[0;36mMeanSquaredError.update\u001b[1;34m(self, preds, target)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate\u001b[39m(\u001b[38;5;28mself\u001b[39m, preds: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    101\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Update state with predictions and targets.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m     sum_squared_error, num_obs \u001b[38;5;241m=\u001b[39m \u001b[43m_mean_squared_error_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msum_squared_error \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sum_squared_error\n\u001b[0;32m    105\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_obs\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torchmetrics\\functional\\regression\\mse.py:37\u001b[0m, in \u001b[0;36m_mean_squared_error_update\u001b[1;34m(preds, target, num_outputs)\u001b[0m\n\u001b[0;32m     35\u001b[0m     preds \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     36\u001b[0m     target \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m diff \u001b[38;5;241m=\u001b[39m \u001b[43mpreds\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\n\u001b[0;32m     38\u001b[0m sum_squared_error \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msum(diff \u001b[38;5;241m*\u001b[39m diff, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sum_squared_error, target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mae_loss, mape_loss, mse_loss, r2 = training(water_X_test, water_y_test, lstm_model, water_trainDL, water_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-2\\AppData\\Local\\Temp\\ipykernel_22920\\1109599893.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('./saved_models/model_weights_30.pth', map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3237, grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# mae loss = 8.3237\n",
    "state_dict = torch.load('./saved_models/model_weights_30.pth', map_location=torch.device('cpu'))\n",
    "lstm_model.load_state_dict(state_dict)\n",
    "lstm_model.eval()\n",
    "\n",
    "featureDF = water_X_test\n",
    "targetDF = water_y_test\n",
    "\n",
    "featureTS = torch.FloatTensor(featureDF.values).to(DEVICE)\n",
    "targetTS = torch.FloatTensor(targetDF.values).to(DEVICE)\n",
    "\n",
    "pre_y = lstm_model(featureTS)\n",
    "mae_loss = MAEloss(pre_y, targetTS)\n",
    "print(mae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
