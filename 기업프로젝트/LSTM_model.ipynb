{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torchmetrics.regression import R2Score, MeanAbsoluteError, MeanAbsolutePercentageError, MeanSquaredError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/'\n",
    "\n",
    "# electric_df = pd.read_=8csv(DATA_PATH + 'electric_df.csv', index_col = 0)\n",
    "water_df = pd.read_csv(DATA_PATH + 'water_df.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>...</td>\n",
       "      <td>95</td>\n",
       "      <td>46</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120</td>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>46</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>210</td>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>...</td>\n",
       "      <td>139</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>410</td>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>43</td>\n",
       "      <td>...</td>\n",
       "      <td>204</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>184</td>\n",
       "      <td>180</td>\n",
       "      <td>260</td>\n",
       "      <td>35</td>\n",
       "      <td>145</td>\n",
       "      <td>203</td>\n",
       "      <td>216</td>\n",
       "      <td>43</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>53</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>150</td>\n",
       "      <td>51</td>\n",
       "      <td>169</td>\n",
       "      <td>204</td>\n",
       "      <td>169</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339995</th>\n",
       "      <td>157</td>\n",
       "      <td>230</td>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>...</td>\n",
       "      <td>58</td>\n",
       "      <td>218</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339996</th>\n",
       "      <td>230</td>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>...</td>\n",
       "      <td>218</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339997</th>\n",
       "      <td>169</td>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>...</td>\n",
       "      <td>290</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339998</th>\n",
       "      <td>47</td>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>143</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339999</th>\n",
       "      <td>122</td>\n",
       "      <td>218</td>\n",
       "      <td>350</td>\n",
       "      <td>110</td>\n",
       "      <td>183</td>\n",
       "      <td>190</td>\n",
       "      <td>230</td>\n",
       "      <td>98</td>\n",
       "      <td>143</td>\n",
       "      <td>253</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>68</td>\n",
       "      <td>38</td>\n",
       "      <td>263</td>\n",
       "      <td>78</td>\n",
       "      <td>158</td>\n",
       "      <td>290</td>\n",
       "      <td>300</td>\n",
       "      <td>280</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>340000 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1    2    3    4    5    6    7    8    9  ...   19   20   21  \\\n",
       "0        30  120  210  410   32  184  180  260   35  145  ...   95   46  139   \n",
       "1       120  210  410   32  184  180  260   35  145  203  ...   46  139  204   \n",
       "2       210  410   32  184  180  260   35  145  203  216  ...  139  204  198   \n",
       "3       410   32  184  180  260   35  145  203  216   43  ...  204  198   53   \n",
       "4        32  184  180  260   35  145  203  216   43  136  ...  198   53  162   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "339995  157  230  169   47  122  218  350  110  183  190  ...   58  218  290   \n",
       "339996  230  169   47  122  218  350  110  183  190  230  ...  218  290  105   \n",
       "339997  169   47  122  218  350  110  183  190  230   98  ...  290  105   10   \n",
       "339998   47  122  218  350  110  183  190  230   98  143  ...  105   10   68   \n",
       "339999  122  218  350  110  183  190  230   98  143  253  ...   10   68   38   \n",
       "\n",
       "         22   23   24   25   26   27   28  \n",
       "0       204  198   53  162  210  150   51  \n",
       "1       198   53  162  210  150   51  169  \n",
       "2        53  162  210  150   51  169  204  \n",
       "3       162  210  150   51  169  204  169  \n",
       "4       210  150   51  169  204  169   38  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "339995  105   10   68   38  263   78  158  \n",
       "339996   10   68   38  263   78  158  290  \n",
       "339997   68   38  263   78  158  290  300  \n",
       "339998   38  263   78  158  290  300  280  \n",
       "339999  263   78  158  290  300  280  160  \n",
       "\n",
       "[340000 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_features = electric_df[electric_df.columns[:-1]]\n",
    "# electric_target = electric_df[electric_df.columns[-1:]]\n",
    "\n",
    "# electric_X_train, electric_X_test, electric_y_train, electric_y_test = train_test_split(electric_features,\n",
    "#                                                     electric_target,\n",
    "#                                                     random_state = 42,\n",
    "                                                    # test_size = 0.2)\n",
    "\n",
    "water_features = water_df[water_df.columns[:-1]]\n",
    "water_target = water_df[water_df.columns[-1:]]\n",
    "\n",
    "water_X_train, water_X_test, water_y_train, water_y_test = train_test_split(water_features,\n",
    "                                                                            water_target,\n",
    "                                                                            random_state = 42,\n",
    "                                                                            test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, featureDF, targetDF):\n",
    "        self.featureDF = featureDF\n",
    "        self.targetDF = targetDF\n",
    "        self.n_rows = self.featureDF.shape[0]\n",
    "        self.n_cols = self.featureDF.shape[1]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_rows\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        featureTS = torch.FloatTensor(self.featureDF.iloc[index].values)\n",
    "        targetTS = torch.FloatTensor(self.targetDF.iloc[index].values)\n",
    "\n",
    "        return featureTS, targetTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, hidden_dim, input_size, n_layers, dropout,\n",
    "                 bidirectional):\n",
    "        super().__init__()\n",
    "\n",
    "        self.model = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = n_layers,\n",
    "            dropout = dropout,\n",
    "            bidirectional = bidirectional,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "        if bidirectional:\n",
    "            self.linear = nn.Linear(hidden_dim * 2, 1)\n",
    "        \n",
    "        else:\n",
    "            self.linear = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "        # 성능에 따라 추가\n",
    "        # self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        output, _ = self.model(inputs)\n",
    "        logits = self.linear(output)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_mmscaler = MinMaxScaler().fit(electric_X_train)\n",
    "water_rbscaler = RobustScaler().fit(water_X_train)\n",
    "\n",
    "# with open('electric_min_max_scaler.pkl', 'wb') as f:\n",
    "#     pickle.dump(electric_mmscaler, f)\n",
    "\n",
    "with open('water_robust_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(water_rbscaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_X_train_scaled = electric_mmscaler.transform(electric_X_train)\n",
    "# electric_X_test_scaled = electric_mmscaler.transform(electric_X_test)\n",
    "\n",
    "water_X_train_scaled = water_rbscaler.transform(water_X_train)\n",
    "water_X_test_scaled = water_rbscaler.transform(water_X_test)\n",
    "\n",
    "# electric_X_train = pd.DataFrame(electric_X_train_scaled, columns = electric_X_train.columns)\n",
    "# electric_X_test = pd.DataFrame(electric_X_test_scaled, columns = electric_X_test.columns)\n",
    "\n",
    "water_X_train = pd.DataFrame(water_X_train_scaled, columns = water_X_train.columns)\n",
    "water_X_test = pd.DataFrame(water_X_test_scaled, columns = water_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# electric_trainDS = CustomDataset(electric_X_train, electric_y_train)\n",
    "water_trainDS = CustomDataset(water_X_train, water_y_train)\n",
    "\n",
    "# electric_trainDL = DataLoader(electric_trainDS, batch_size = BATCH_SIZE)\n",
    "water_trainDL = DataLoader(water_trainDS, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 28\n",
    "hidden_dim = 128\n",
    "n_layers = 2\n",
    "dropout = 0.5\n",
    "\n",
    "lstm_model = LSTMModel(input_size = input_size, hidden_dim = hidden_dim,\n",
    "                       n_layers = n_layers, dropout = 0.9, bidirectional = True).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MAEloss = MeanAbsoluteError()\n",
    "MAPEloss = MeanAbsolutePercentageError()\n",
    "MSEloss = MeanSquaredError()\n",
    "R2score = R2Score()\n",
    "\n",
    "optimizer = optim.Adam(lstm_model.parameters(), lr = LR)\n",
    "\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience = 100, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(featureDF, targetDF, model):\n",
    "    featureTS = torch.FloatTensor(featureDF.values).to(DEVICE)\n",
    "    targetTS = torch.FloatTensor(targetDF.values).to(DEVICE)\n",
    "\n",
    "    model.dropout = nn.Dropout(0)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pre_val = model(featureTS)\n",
    "        mae_loss_val = MAEloss(pre_val, targetTS)\n",
    "        mape_loss_val = MAPEloss(pre_val, targetTS)\n",
    "        mse_loss_val = MSEloss(pre_val, targetTS)\n",
    "        score_val = R2score(pre_val, targetTS)\n",
    "    \n",
    "    return mae_loss_val, mape_loss_val, mse_loss_val, score_val, pre_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = './saved_models/'\n",
    "os.makedirs(SAVE_PATH, exist_ok = True)\n",
    "\n",
    "def training(testDF, testtargetDF, model, trainDL, test_value):\n",
    "    BREAK_CNT_LOSS = 0\n",
    "    BREAK_CNT_SCORE = 0\n",
    "    LIMIT_VALUE = 10\n",
    "\n",
    "    MAE_LOSS_HISTORY, MAPE_LOSS_HISTORY, MSE_LOSS_HISTORY, SCORE_HISTORY = [[], []], [[], []], [[], []], [[], []]\n",
    "\n",
    "    for epoch in range(1, EPOCH + 1):\n",
    "        SAVE_MODEL = os.path.join(SAVE_PATH, f'model_{epoch}.pth')\n",
    "        SAVE_WEIGHT = os.path.join(SAVE_PATH, f'model_weights_{epoch}.pth')\n",
    "\n",
    "        mae_loss_total, mape_loss_total, mse_loss_total, score_total = 0, 0, 0, 0\n",
    "\n",
    "        for featureTS, targetTS in trainDL:\n",
    "            pre_y = model(featureTS)\n",
    "\n",
    "            mae_loss = MAEloss(pre_y, targetTS)\n",
    "            mape_loss = MAPEloss(pre_y, targetTS)\n",
    "            mse_loss = MSEloss(pre_y, targetTS)\n",
    "\n",
    "            mae_loss_total += mae_loss.item()\n",
    "            mape_loss_total += mape_loss.item()\n",
    "            mse_loss_total += mse_loss.item()\n",
    "\n",
    "            score = R2score(pre_y, targetTS)\n",
    "            score_total += score.item()\n",
    "\n",
    "            total_loss = mae_loss + mape_loss + mse_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            total_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        test_mae_loss, test_mape_loss, test_mse_loss, test_score, pre_val = testing(testDF, testtargetDF, model)\n",
    "\n",
    "        MAE_LOSS_HISTORY[1].append(test_mae_loss)\n",
    "        MAPE_LOSS_HISTORY[1].append(test_mape_loss)\n",
    "        MSE_LOSS_HISTORY[1].append(test_mse_loss)\n",
    "        SCORE_HISTORY[1].append(test_score)\n",
    "\n",
    "        MAE_LOSS_HISTORY[0].append(mae_loss_total / len(trainDL))\n",
    "        MAPE_LOSS_HISTORY[0].append(mape_loss_total / len(trainDL))\n",
    "        MSE_LOSS_HISTORY[0].append(mse_loss_total / len(trainDL))\n",
    "        SCORE_HISTORY[0].append(score_total / len(trainDL))\n",
    "\n",
    "        print(f'pre_val : {pre_val.squeeze().tolist()[:10]}\\ny_val : {test_value.values.squeeze()[:10]}\\n')\n",
    "        print(f'[{epoch} / {EPOCH}]\\n- TRAIN MAE LOSS : {MAE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN MAPE LOSS : {MAPE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN MSE LOSS : {MSE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN R2 SCORE : {SCORE_HISTORY[0][-1]}')\n",
    "\n",
    "        print(f'\\n- TEST MAE LOSS : {MAE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST MAPE LOSS : {MAPE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST MSE LOSS : {MSE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST R2 SCORE : {SCORE_HISTORY[1][-1]}')\n",
    "\n",
    "        scheduler.step(test_mae_loss)\n",
    "\n",
    "        if len(MAE_LOSS_HISTORY[1]) >= 2:\n",
    "            if MAE_LOSS_HISTORY[1][-1] >= MAE_LOSS_HISTORY[1][-2]: BREAK_CNT_LOSS += 1\n",
    "        \n",
    "        if len(MAE_LOSS_HISTORY[1]) == 1:\n",
    "            torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "            torch.save(model, SAVE_MODEL)\n",
    "\n",
    "        else:\n",
    "            if MAE_LOSS_HISTORY[1][-1] < min(MAE_LOSS_HISTORY[1][:-1]):\n",
    "                torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "                torch.save(model, SAVE_MODEL)\n",
    "\n",
    "        if BREAK_CNT_LOSS > LIMIT_VALUE:\n",
    "            print(f\"성능 및 손실 개선이 없어서 {epoch} EPOCH에 학습 중단\")\n",
    "            # break\n",
    "\n",
    "    return MAE_LOSS_HISTORY, MAPE_LOSS_HISTORY, MSE_LOSS_HISTORY, SCORE_HISTORY\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>289500</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26491</th>\n",
       "      <td>218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134099</th>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87950</th>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165405</th>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211567</th>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36707</th>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226226</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338315</th>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339626</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         28\n",
       "289500   58\n",
       "26491   218\n",
       "134099   84\n",
       "87950   210\n",
       "165405  169\n",
       "...     ...\n",
       "211567   68\n",
       "36707   350\n",
       "226226   55\n",
       "338315  143\n",
       "339626   47\n",
       "\n",
       "[68000 rows x 1 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "water_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_val : [-8.991474169306457e-05, 0.0017274414421990514, 0.033869680017232895, 0.004415200091898441, 0.0014199650613591075, 0.024644186720252037, 0.007711134385317564, 0.00305841863155365, 0.013776338659226894, 0.007394302636384964]\n",
      "y_val : [ 58 218  84 210 169 138 150 183 147 260]\n",
      "\n",
      "[1 / 100]\n",
      "- TRAIN MAE LOSS : 148.34912220135857\n",
      "- TRAIN MAPE LOSS : 192.16441621757255\n",
      "- TRAIN MSE LOSS : 27962.96738683364\n",
      "- TRAIN R2 SCORE : -4.112658343230977\n",
      "\n",
      "- TEST MAE LOSS : 148.71746826171875\n",
      "- TEST MAPE LOSS : 2.5231847763061523\n",
      "- TEST MSE LOSS : 28082.29296875\n",
      "- TEST R2 SCORE : -3.707451343536377\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mae_loss, mape_loss, mse_loss, r2 \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwater_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_y_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlstm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_trainDL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_y_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(testDF, testtargetDF, model, trainDL, test_value)\u001b[0m\n\u001b[0;32m     13\u001b[0m SAVE_WEIGHT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(SAVE_PATH, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m mae_loss_total, mape_loss_total, mse_loss_total, score_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m featureTS, targetTS \u001b[38;5;129;01min\u001b[39;00m trainDL:\n\u001b[0;32m     18\u001b[0m     pre_y \u001b[38;5;241m=\u001b[39m model(featureTS)\n\u001b[0;32m     20\u001b[0m     mae_loss \u001b[38;5;241m=\u001b[39m MAEloss(pre_y, targetTS)\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[12], line 12\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m---> 12\u001b[0m     featureTS \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatureDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     targetTS \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargetDF\u001b[38;5;241m.\u001b[39miloc[index]\u001b[38;5;241m.\u001b[39mvalues)\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m featureTS, targetTS\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mae_loss, mape_loss, mse_loss, r2 = training(water_X_test, water_y_test, lstm_model, water_trainDL, water_y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KDP-2\\AppData\\Local\\Temp\\ipykernel_22920\\1109599893.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load('./saved_models/model_weights_30.pth', map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(8.3237, grad_fn=<CloneBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# mae loss = 8.3237\n",
    "state_dict = torch.load('./saved_models/model_weights_30.pth', map_location=torch.device('cpu'))\n",
    "lstm_model.load_state_dict(state_dict)\n",
    "lstm_model.eval()\n",
    "\n",
    "featureDF = water_X_test\n",
    "targetDF = water_y_test\n",
    "\n",
    "featureTS = torch.FloatTensor(featureDF.values).to(DEVICE)\n",
    "targetTS = torch.FloatTensor(targetDF.values).to(DEVICE)\n",
    "\n",
    "pre_y = lstm_model(featureTS)\n",
    "mae_loss = MAEloss(pre_y, targetTS)\n",
    "print(mae_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
