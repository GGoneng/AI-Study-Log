{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "from AutoEncoderModule import AutoEncoderDataset\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torchmetrics.regression import R2Score, MeanAbsoluteError, MeanAbsolutePercentageError, MeanSquaredError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../Data/'\n",
    "\n",
    "electric_df = pd.read_csv(DATA_PATH + 'electric_df_clear.csv')\n",
    "water_df = pd.read_csv(DATA_PATH + 'water_df_clear.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0     1     2     3     4     5     6     7     8     9  ...    19  \\\n",
      "0  1.23  1.45  1.73  1.62  1.31  1.48  1.74  1.71  1.30  1.49  ...  1.68   \n",
      "1  1.45  1.73  1.62  1.31  1.48  1.74  1.71  1.30  1.49  1.94  ...  1.20   \n",
      "2  1.73  1.62  1.31  1.48  1.74  1.71  1.30  1.49  1.94  1.68  ...  1.42   \n",
      "3  1.62  1.31  1.48  1.74  1.71  1.30  1.49  1.94  1.68  1.26  ...  1.88   \n",
      "4  1.31  1.48  1.74  1.71  1.30  1.49  1.94  1.68  1.26  1.39  ...  1.67   \n",
      "\n",
      "     20    21    22    23    24    25    26    27    28  \n",
      "0  1.20  1.42  1.88  1.67  1.24  1.39  1.67  1.60  1.26  \n",
      "1  1.42  1.88  1.67  1.24  1.39  1.67  1.60  1.26  1.41  \n",
      "2  1.88  1.67  1.24  1.39  1.67  1.60  1.26  1.41  1.68  \n",
      "3  1.67  1.24  1.39  1.67  1.60  1.26  1.41  1.68  1.59  \n",
      "4  1.24  1.39  1.67  1.60  1.26  1.41  1.68  1.59  1.24  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "\n",
      "     0    1    2    3    4    5    6    7    8    9  ...   19   20   21   22  \\\n",
      "0   30  120  210  410   32  184  180  260   35  145  ...   95   46  139  204   \n",
      "1  120  210  410   32  184  180  260   35  145  203  ...   46  139  204  198   \n",
      "2  210  410   32  184  180  260   35  145  203  216  ...  139  204  198   53   \n",
      "3  410   32  184  180  260   35  145  203  216   43  ...  204  198   53  162   \n",
      "4   32  184  180  260   35  145  203  216   43  136  ...  198   53  162  210   \n",
      "\n",
      "    23   24   25   26   27   28  \n",
      "0  198   53  162  210  150   51  \n",
      "1   53  162  210  150   51  169  \n",
      "2  162  210  150   51  169  204  \n",
      "3  210  150   51  169  204  169  \n",
      "4  150   51  169  204  169   38  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "print(electric_df.head())\n",
    "print()\n",
    "print(water_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "electric_features = electric_df[electric_df.columns[:-1]]\n",
    "electric_target = electric_df[electric_df.columns[-1:]]\n",
    "\n",
    "electric_X_train, electric_X_test, electric_y_train, electric_y_test = train_test_split(electric_features,\n",
    "                                                    electric_target,\n",
    "                                                    random_state = 42,\n",
    "                                                    test_size = 0.2)\n",
    "\n",
    "water_features = water_df[water_df.columns[:-1]]\n",
    "water_target = water_df[water_df.columns[-1:]]\n",
    "\n",
    "water_X_train, water_X_test, water_y_train, water_y_test = train_test_split(water_features,\n",
    "                                                                            water_target,\n",
    "                                                                            random_state = 42,\n",
    "                                                                            test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "electric_rbscaler = RobustScaler().fit(electric_X_train)\n",
    "water_rbscaler = RobustScaler().fit(water_X_train)\n",
    "\n",
    "with open('electric_min_max_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(electric_rbscaler, f)\n",
    "\n",
    "with open('water_robust_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(water_rbscaler, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "electric_X_train_scaled = electric_rbscaler.transform(electric_X_train)\n",
    "electric_X_test_scaled = electric_rbscaler.transform(electric_X_test)\n",
    "\n",
    "water_X_train_scaled = water_rbscaler.transform(water_X_train)\n",
    "water_X_test_scaled = water_rbscaler.transform(water_X_test)\n",
    "\n",
    "electric_X_train = pd.DataFrame(electric_X_train_scaled, columns = electric_X_train.columns)\n",
    "electric_X_test = pd.DataFrame(electric_X_test_scaled, columns = electric_X_test.columns)\n",
    "\n",
    "water_X_train = pd.DataFrame(water_X_train_scaled, columns = water_X_train.columns)\n",
    "water_X_test = pd.DataFrame(water_X_test_scaled, columns = water_X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100000\n",
    "BATCH_SIZE = 32\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "electric_trainDS = AutoEncoderDataset(electric_X_train)\n",
    "water_trainDS = AutoEncoderDataset(water_X_train)\n",
    "\n",
    "electric_trainDL = DataLoader(electric_trainDS, batch_size = BATCH_SIZE)\n",
    "water_trainDL = DataLoader(water_trainDS, batch_size = BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_dim, latent_dim, n_layers, dropout,\n",
    "                 bidirectional):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size = input_size,\n",
    "            hidden_size = hidden_dim,\n",
    "            num_layers = n_layers,\n",
    "            dropout = dropout,\n",
    "            bidirectional = bidirectional,\n",
    "            batch_first = True\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, latent_dim)\n",
    "\n",
    "        self.reverse_fc = nn.Linear(latent_dim, hidden_dim * 2 if bidirectional else hidden_dim)\n",
    "        \n",
    "        self.decoder = nn.LSTM(\n",
    "            input_size = hidden_dim * 2 if bidirectional else hidden_dim,\n",
    "            hidden_size = input_size,\n",
    "            num_layers = n_layers,\n",
    "            dropout = dropout,\n",
    "            bidirectional = False,\n",
    "            batch_first = True\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        _, (hidden, _) = self.encoder(inputs)\n",
    "\n",
    "        if self.encoder.bidirectional:\n",
    "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=-1)\n",
    "        else:\n",
    "            hidden = hidden[-1]\n",
    "\n",
    "        fc = self.fc(hidden)\n",
    "\n",
    "        reverse_fc = self.reverse_fc(fc).unsqueeze(1).repeat(1, inputs.size(1), 1)\n",
    "        reconstructed, _ = self.decoder(reverse_fc)\n",
    "\n",
    "        return reconstructed, fc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing(featureDF, targetDF, model, DEVICE):\n",
    "    featureTS = torch.FloatTensor(featureDF.values).unsqueeze(1).to(DEVICE)\n",
    "    targetTS = torch.FloatTensor(targetDF.values).unsqueeze(1).to(DEVICE)\n",
    "    \n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        reconstructed, fc = model(featureTS)\n",
    "        reconstructed = reconstructed.contiguous()\n",
    "        targetTS = targetTS.contiguous()\n",
    "\n",
    "        mae_loss_val = MeanAbsoluteError()(reconstructed, targetTS)\n",
    "        mape_loss_val = MeanAbsolutePercentageError()(reconstructed, targetTS)\n",
    "        mse_loss_val = MeanSquaredError()(reconstructed, targetTS)\n",
    "\n",
    "        mae_loss_val = MeanAbsoluteError()(reconstructed, targetTS)\n",
    "        mape_loss_val = MeanAbsolutePercentageError()(reconstructed, targetTS)\n",
    "        mse_loss_val = MeanSquaredError()(reconstructed, targetTS)\n",
    "    \n",
    "    return mae_loss_val, mape_loss_val, mse_loss_val, reconstructed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def training(testDF, testtargetDF, model, trainDL,\n",
    "              optimizer, EPOCH, scheduler, DEVICE):\n",
    "    SAVE_PATH = './saved_models/'\n",
    "    os.makedirs(SAVE_PATH, exist_ok = True)\n",
    "\n",
    "    BREAK_CNT_LOSS = 0\n",
    "    BREAK_CNT_SCORE = 0\n",
    "    LIMIT_VALUE = 10\n",
    "\n",
    "    MAE_LOSS_HISTORY, MAPE_LOSS_HISTORY, MSE_LOSS_HISTORY = [[], []], [[], []], [[], []]\n",
    "\n",
    "    for epoch in range(1, EPOCH + 1):\n",
    "        model.train()\n",
    "\n",
    "        SAVE_MODEL = os.path.join(SAVE_PATH, f'model_{epoch}.pth')\n",
    "        SAVE_WEIGHT = os.path.join(SAVE_PATH, f'model_weights_{epoch}.pth')\n",
    "\n",
    "        mae_loss_total, mape_loss_total, mse_loss_total, score_total = 0, 0, 0, 0\n",
    "\n",
    "        for featureTS, targetTS in trainDL:\n",
    "            featureTS, targetTS = featureTS.unsqueeze(1).to(DEVICE), targetTS.unsqueeze(1).to(DEVICE)\n",
    "            \n",
    "\n",
    "            reconstructed, fc = model(featureTS)\n",
    "\n",
    "\n",
    "            mae_loss = MeanAbsoluteError()(reconstructed, targetTS)\n",
    "            mape_loss = MeanAbsolutePercentageError()(reconstructed, targetTS)\n",
    "            mse_loss = MeanSquaredError()(reconstructed, targetTS)\n",
    "\n",
    "            mae_loss_total += mae_loss.item()\n",
    "            mape_loss_total += mape_loss.item()\n",
    "            mse_loss_total += mse_loss.item()\n",
    "\n",
    "\n",
    "            total_loss = mae_loss + mape_loss + mse_loss\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            total_loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        test_mae_loss, test_mape_loss, test_mse_loss, test_reconstructed = testing(testDF, testtargetDF, model, DEVICE)\n",
    "        \n",
    "        MAE_LOSS_HISTORY[1].append(test_mae_loss)\n",
    "        MAPE_LOSS_HISTORY[1].append(test_mape_loss)\n",
    "        MSE_LOSS_HISTORY[1].append(test_mse_loss)\n",
    "\n",
    "        MAE_LOSS_HISTORY[0].append(mae_loss_total / len(trainDL))\n",
    "        MAPE_LOSS_HISTORY[0].append(mape_loss_total / len(trainDL))\n",
    "        MSE_LOSS_HISTORY[0].append(mse_loss_total / len(trainDL))\n",
    "   \n",
    "        print(f'[{epoch} / {EPOCH}]\\n- TRAIN MAE LOSS : {MAE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN MAPE LOSS : {MAPE_LOSS_HISTORY[0][-1]}')\n",
    "        print(f'- TRAIN MSE LOSS : {MSE_LOSS_HISTORY[0][-1]}')\n",
    "\n",
    "        print(f'\\n- TEST MAE LOSS : {MAE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST MAPE LOSS : {MAPE_LOSS_HISTORY[1][-1]}')\n",
    "        print(f'- TEST MSE LOSS : {MSE_LOSS_HISTORY[1][-1]}')\n",
    "\n",
    "        scheduler.step(test_mae_loss)\n",
    "\n",
    "        if len(MAE_LOSS_HISTORY[1]) >= 2:\n",
    "            if MAE_LOSS_HISTORY[1][-1] >= MAE_LOSS_HISTORY[1][-2]: BREAK_CNT_LOSS += 1\n",
    "        \n",
    "        if len(MAE_LOSS_HISTORY[1]) == 1:\n",
    "            torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "            torch.save(model, SAVE_MODEL)\n",
    "\n",
    "        else:\n",
    "            if MAE_LOSS_HISTORY[1][-1] < min(MAE_LOSS_HISTORY[1][:-1]):\n",
    "                torch.save(model.state_dict(), SAVE_WEIGHT)\n",
    "                torch.save(model, SAVE_MODEL)\n",
    "\n",
    "        if BREAK_CNT_LOSS > LIMIT_VALUE:\n",
    "            print(f\"성능 및 손실 개선이 없어서 {epoch} EPOCH에 학습 중단\")\n",
    "            # break\n",
    "\n",
    "    return MAE_LOSS_HISTORY, MAPE_LOSS_HISTORY, MSE_LOSS_HISTORY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "input_size = 28\n",
    "hidden_dim = 16\n",
    "latent_dim = 8\n",
    "n_layers = 2\n",
    "dropout = 0.1\n",
    "bidirectional = False\n",
    "\n",
    "LR = 0.001\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "recurrent_autoencoder = RecurrentAutoencoder(input_size = input_size,\n",
    "                                             hidden_dim = hidden_dim,\n",
    "                                             latent_dim = latent_dim,\n",
    "                                             n_layers = n_layers,\n",
    "                                             dropout = dropout,\n",
    "                                             bidirectional = bidirectional\n",
    "                                             )\n",
    "optimizer = optim.Adam(recurrent_autoencoder.parameters(), lr = LR)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', patience = 100, verbose = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 / 100000]\n",
      "- TRAIN MAE LOSS : 0.5417304342651701\n",
      "- TRAIN MAPE LOSS : 8.526283950372175\n",
      "- TRAIN MSE LOSS : 0.48373930311286367\n",
      "\n",
      "- TEST MAE LOSS : 0.5422823429107666\n",
      "- TEST MAPE LOSS : 1.4446171522140503\n",
      "- TEST MSE LOSS : 0.4848843216896057\n",
      "[2 / 100000]\n",
      "- TRAIN MAE LOSS : 0.5417200657704493\n",
      "- TRAIN MAPE LOSS : 1.076484737521285\n",
      "- TRAIN MSE LOSS : 0.48373673799154643\n",
      "\n",
      "- TEST MAE LOSS : 0.5422818064689636\n",
      "- TEST MAPE LOSS : 0.9858613014221191\n",
      "- TEST MSE LOSS : 0.4848841428756714\n",
      "[3 / 100000]\n",
      "- TRAIN MAE LOSS : 0.541719948691088\n",
      "- TRAIN MAPE LOSS : 0.9789327878301793\n",
      "- TRAIN MSE LOSS : 0.4837367375497218\n",
      "\n",
      "- TEST MAE LOSS : 0.5422818064689636\n",
      "- TEST MAPE LOSS : 0.9764484763145447\n",
      "- TEST MSE LOSS : 0.4848841428756714\n",
      "[4 / 100000]\n",
      "- TRAIN MAE LOSS : 0.5417199521840036\n",
      "- TRAIN MAPE LOSS : 0.9760711270112258\n",
      "- TRAIN MSE LOSS : 0.483736741113496\n",
      "\n",
      "- TEST MAE LOSS : 0.5422818064689636\n",
      "- TEST MAPE LOSS : 0.9760800004005432\n",
      "- TEST MSE LOSS : 0.4848841428756714\n",
      "[5 / 100000]\n",
      "- TRAIN MAE LOSS : 0.54171995278005\n",
      "- TRAIN MAPE LOSS : 0.9759784001570482\n",
      "- TRAIN MSE LOSS : 0.4837367413052312\n",
      "\n",
      "- TEST MAE LOSS : 0.5422818064689636\n",
      "- TEST MAPE LOSS : 0.9760692715644836\n",
      "- TEST MSE LOSS : 0.4848841428756714\n",
      "[6 / 100000]\n",
      "- TRAIN MAE LOSS : 0.54171995278005\n",
      "- TRAIN MAPE LOSS : 0.9759751905594672\n",
      "- TRAIN MSE LOSS : 0.4837367413052312\n",
      "\n",
      "- TEST MAE LOSS : 0.5422818064689636\n",
      "- TEST MAPE LOSS : 0.976068913936615\n",
      "- TEST MSE LOSS : 0.4848841428756714\n",
      "[7 / 100000]\n",
      "- TRAIN MAE LOSS : 0.54171995278005\n",
      "- TRAIN MAPE LOSS : 0.9759750876226625\n",
      "- TRAIN MSE LOSS : 0.4837367413052312\n",
      "\n",
      "- TEST MAE LOSS : 0.5422818064689636\n",
      "- TEST MAPE LOSS : 0.976068913936615\n",
      "- TEST MSE LOSS : 0.4848841428756714\n",
      "[8 / 100000]\n",
      "- TRAIN MAE LOSS : 0.54171995278005\n",
      "- TRAIN MAPE LOSS : 0.9759750874976179\n",
      "- TRAIN MSE LOSS : 0.4837367413052312\n",
      "\n",
      "- TEST MAE LOSS : 0.5422818064689636\n",
      "- TEST MAPE LOSS : 0.976068913936615\n",
      "- TEST MSE LOSS : 0.4848841428756714\n",
      "[9 / 100000]\n",
      "- TRAIN MAE LOSS : 0.54171995278005\n",
      "- TRAIN MAPE LOSS : 0.9759750874976179\n",
      "- TRAIN MSE LOSS : 0.4837367413052312\n",
      "\n",
      "- TEST MAE LOSS : 0.5422818064689636\n",
      "- TEST MAPE LOSS : 0.976068913936615\n",
      "- TEST MSE LOSS : 0.4848841428756714\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[174], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m mae_loss, mape_loss, mse_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwater_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_X_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecurrent_autoencoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwater_trainDL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                             \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[164], line 20\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(testDF, testtargetDF, model, trainDL, optimizer, EPOCH, scheduler, DEVICE)\u001b[0m\n\u001b[0;32m     16\u001b[0m SAVE_WEIGHT \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(SAVE_PATH, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_weights_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     18\u001b[0m mae_loss_total, mape_loss_total, mse_loss_total, score_total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m featureTS, targetTS \u001b[38;5;129;01min\u001b[39;00m trainDL:\n\u001b[0;32m     21\u001b[0m     featureTS, targetTS \u001b[38;5;241m=\u001b[39m featureTS\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE), targetTS\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m     24\u001b[0m     reconstructed, fc \u001b[38;5;241m=\u001b[39m model(featureTS)\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\anaconda3\\envs\\Project_38\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:52\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\KDP-2\\OneDrive\\바탕 화면\\Python\\기업 프로젝트\\third_model\\AutoEncoderModule.py:24\u001b[0m, in \u001b[0;36mAutoEncoderDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[1;32m---> 24\u001b[0m     featureTS \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFloatTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatureDF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m featureTS, featureTS\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mae_loss, mape_loss, mse_loss = training(water_X_test, water_X_test, recurrent_autoencoder, water_trainDL,\n",
    "                                             optimizer, EPOCH, scheduler, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
