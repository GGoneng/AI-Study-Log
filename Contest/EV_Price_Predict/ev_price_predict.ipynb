{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import koreanize_matplotlib\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = './Data/'\n",
    "\n",
    "TRAIN_DATA_PATH = DATA_PATH + 'train.csv'\n",
    "TEST_DATA_PATH = DATA_PATH + 'test.csv'\n",
    "SUBMISSION_DATA_PATH = DATA_PATH + 'sample_submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>제조사</th>\n",
       "      <th>모델</th>\n",
       "      <th>차량상태</th>\n",
       "      <th>배터리용량</th>\n",
       "      <th>구동방식</th>\n",
       "      <th>주행거리(km)</th>\n",
       "      <th>보증기간(년)</th>\n",
       "      <th>사고이력</th>\n",
       "      <th>연식(년)</th>\n",
       "      <th>가격(백만원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>P사</td>\n",
       "      <td>TayGTS</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>86.077</td>\n",
       "      <td>AWD</td>\n",
       "      <td>13642</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>159.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>K사</td>\n",
       "      <td>Niro</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>56.000</td>\n",
       "      <td>FWD</td>\n",
       "      <td>10199</td>\n",
       "      <td>6</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>28.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>A사</td>\n",
       "      <td>eT</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>91.200</td>\n",
       "      <td>AWD</td>\n",
       "      <td>2361</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>66.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>A사</td>\n",
       "      <td>RSeTGT</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>21683</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>99.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>B사</td>\n",
       "      <td>i5</td>\n",
       "      <td>Pre-Owned</td>\n",
       "      <td>61.018</td>\n",
       "      <td>AWD</td>\n",
       "      <td>178205</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>62.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID 제조사      모델        차량상태   배터리용량 구동방식  주행거리(km)  보증기간(년) 사고이력  \\\n",
       "0  TRAIN_0000  P사  TayGTS  Nearly New  86.077  AWD     13642        0   No   \n",
       "1  TRAIN_0001  K사    Niro  Nearly New  56.000  FWD     10199        6   No   \n",
       "2  TRAIN_0002  A사      eT   Brand New  91.200  AWD      2361        7   No   \n",
       "3  TRAIN_0003  A사  RSeTGT  Nearly New     NaN  AWD     21683        3   No   \n",
       "4  TRAIN_0004  B사      i5   Pre-Owned  61.018  AWD    178205        1   No   \n",
       "\n",
       "   연식(년)  가격(백만원)  \n",
       "0      2   159.66  \n",
       "1      0    28.01  \n",
       "2      0    66.27  \n",
       "3      0    99.16  \n",
       "4      0    62.02  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_DATA_PATH)\n",
    "test_df = pd.read_csv(TEST_DATA_PATH)\n",
    "submission_df = pd.read_csv(SUBMISSION_DATA_PATH)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7497 entries, 0 to 7496\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        7497 non-null   object \n",
      " 1   제조사       7497 non-null   object \n",
      " 2   모델        7497 non-null   object \n",
      " 3   차량상태      7497 non-null   object \n",
      " 4   배터리용량     4786 non-null   float64\n",
      " 5   구동방식      7497 non-null   object \n",
      " 6   주행거리(km)  7497 non-null   int64  \n",
      " 7   보증기간(년)   7497 non-null   int64  \n",
      " 8   사고이력      7497 non-null   object \n",
      " 9   연식(년)     7497 non-null   int64  \n",
      " 10  가격(백만원)   7497 non-null   float64\n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 644.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_graph(col):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    sns.barplot(x=train_df[f'{col}'].value_counts().index, \n",
    "                y=train_df[f'{col}'].value_counts().values, \n",
    "                palette='Set3', \n",
    "                ax=ax)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\4183445985.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=train_df[f'{col}'].value_counts().index,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph('제조사')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\4183445985.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=train_df[f'{col}'].value_counts().index,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph('모델')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\4183445985.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=train_df[f'{col}'].value_counts().index,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph('차량상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\4183445985.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=train_df[f'{col}'].value_counts().index,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph('구동방식')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\4183445985.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x=train_df[f'{col}'].value_counts().index,\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_graph('연식(년)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_battery(col):\n",
    "    for i in train_df[col].unique():\n",
    "        print(f\"{col} - {i} : {train_df[train_df[col] == i]['배터리용량'].mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연식(년) - 2 : 69.538296\n",
      "연식(년) - 0 : 69.68484126984127\n",
      "연식(년) - 1 : 66.74253498871332\n"
     ]
    }
   ],
   "source": [
    "print_mean_battery('연식(년)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 - TayGTS : 80.45416988416989\n",
      "모델 - Niro : 54.578933333333325\n",
      "모델 - eT : 83.77656402439024\n",
      "모델 - RSeTGT : 84.39925242718446\n",
      "모델 - i5 : 65.49336119402984\n",
      "모델 - ION6 : 65.87692340425532\n",
      "모델 - MS : 89.67221266968326\n",
      "모델 - MY : 63.91637988826815\n",
      "모델 - Q4eT : 69.0407149122807\n",
      "모델 - ID4 : 65.42444\n",
      "모델 - TayCT : 77.5639326923077\n",
      "모델 - Soul : 53.71446036585366\n",
      "모델 - iX : 90.0\n",
      "모델 - MX : 90.03115121951218\n",
      "모델 - IONIQ : 62.04435185185184\n",
      "모델 - EV6 : 90.0\n",
      "모델 - KNE : 72.11759670781893\n",
      "모델 - M3 : 64.48288165680474\n",
      "모델 - i3 : 52.691131498470945\n",
      "모델 - ION5 : 66.43954545454545\n",
      "모델 - Tay : 67.16731555555556\n"
     ]
    }
   ],
   "source": [
    "print_mean_battery('모델')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "보증기간(년) - 0 : 59.936046931407944\n",
      "보증기간(년) - 6 : 68.75179527559055\n",
      "보증기간(년) - 7 : 83.86369625246549\n",
      "보증기간(년) - 3 : 61.30074884792627\n",
      "보증기간(년) - 1 : 59.83024901185771\n",
      "보증기간(년) - 5 : 64.60444846796658\n",
      "보증기간(년) - 8 : 84.68549800796812\n",
      "보증기간(년) - 10 : 90.0\n",
      "보증기간(년) - 2 : 68.24809410548086\n",
      "보증기간(년) - 4 : 61.65939722222222\n",
      "보증기간(년) - 9 : 90.0\n"
     ]
    }
   ],
   "source": [
    "print_mean_battery('보증기간(년)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "차량상태 - Nearly New : 66.67888807649044\n",
      "차량상태 - Brand New : 92.5865671641791\n",
      "차량상태 - Pre-Owned : 59.053240185950415\n"
     ]
    }
   ],
   "source": [
    "print_mean_battery('차량상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "제조사 - P사 : 75.26528034682082\n",
      "제조사 - K사 : 57.49066711590296\n",
      "제조사 - A사 : 78.77559787556905\n",
      "제조사 - B사 : 62.34454742547425\n",
      "제조사 - H사 : 67.39844044665013\n",
      "제조사 - T사 : 78.31083204134367\n",
      "제조사 - V사 : 65.42444\n"
     ]
    }
   ],
   "source": [
    "print_mean_battery('제조사')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "연식(년)\n",
       "0    69.684841\n",
       "1    66.742535\n",
       "2    69.538296\n",
       "Name: 배터리용량, dtype: float64"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.groupby('연식(년)')['배터리용량'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_mean_battery(col):\n",
    "    fig, ax = plt.subplots(figsize = (12, 8))\n",
    "    sns.barplot(x = sorted(train_df[col].unique()),\n",
    "                y = train_df.groupby(col)['배터리용량'].mean(),\n",
    "                palette = 'tab20c',\n",
    "                ax = ax)\n",
    "    plt.xticks(rotation = 45, size = 20)\n",
    "    plt.yticks(size = 15)\n",
    "    plt.title(f'{col} - 평균 배터리', size = 20)\n",
    "    ax.set_ylabel('배터리 용량 (평균)', fontsize = 20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\834823150.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x = sorted(train_df[col].unique()),\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_mean_battery('제조사')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\834823150.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x = sorted(train_df[col].unique()),\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_mean_battery('모델')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\834823150.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x = sorted(train_df[col].unique()),\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_mean_battery('차량상태')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이민하\\AppData\\Local\\Temp\\ipykernel_19464\\834823150.py:3: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(x = sorted(train_df[col].unique()),\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "draw_mean_battery('보증기간(년)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>배터리용량</th>\n",
       "      <th>주행거리(km)</th>\n",
       "      <th>보증기간(년)</th>\n",
       "      <th>연식(년)</th>\n",
       "      <th>가격(백만원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>배터리용량</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.576538</td>\n",
       "      <td>0.558242</td>\n",
       "      <td>-0.021845</td>\n",
       "      <td>0.431668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>주행거리(km)</th>\n",
       "      <td>-0.576538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.664071</td>\n",
       "      <td>-0.089586</td>\n",
       "      <td>-0.035488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>보증기간(년)</th>\n",
       "      <td>0.558242</td>\n",
       "      <td>-0.664071</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>-0.349962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>연식(년)</th>\n",
       "      <td>-0.021845</td>\n",
       "      <td>-0.089586</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.058455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>가격(백만원)</th>\n",
       "      <td>0.431668</td>\n",
       "      <td>-0.035488</td>\n",
       "      <td>-0.349962</td>\n",
       "      <td>-0.058455</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             배터리용량  주행거리(km)   보증기간(년)     연식(년)   가격(백만원)\n",
       "배터리용량     1.000000 -0.576538  0.558242 -0.021845  0.431668\n",
       "주행거리(km) -0.576538  1.000000 -0.664071 -0.089586 -0.035488\n",
       "보증기간(년)   0.558242 -0.664071  1.000000  0.035294 -0.349962\n",
       "연식(년)    -0.021845 -0.089586  0.035294  1.000000 -0.058455\n",
       "가격(백만원)   0.431668 -0.035488 -0.349962 -0.058455  1.000000"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.corr(numeric_only = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델, 보증기간 7년 이상, 차량 상태가 배터리 용량을 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>제조사</th>\n",
       "      <th>모델</th>\n",
       "      <th>차량상태</th>\n",
       "      <th>배터리용량</th>\n",
       "      <th>구동방식</th>\n",
       "      <th>주행거리(km)</th>\n",
       "      <th>보증기간(년)</th>\n",
       "      <th>사고이력</th>\n",
       "      <th>연식(년)</th>\n",
       "      <th>가격(백만원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>A사</td>\n",
       "      <td>RSeTGT</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>21683</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>99.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TRAIN_0006</td>\n",
       "      <td>T사</td>\n",
       "      <td>MS</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>19395</td>\n",
       "      <td>3</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>83.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TRAIN_0008</td>\n",
       "      <td>T사</td>\n",
       "      <td>MY</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>2226</td>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>74.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>TRAIN_0009</td>\n",
       "      <td>A사</td>\n",
       "      <td>Q4eT</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>3683</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>59.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>TRAIN_0011</td>\n",
       "      <td>V사</td>\n",
       "      <td>ID4</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>1131</td>\n",
       "      <td>8</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>40.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7489</th>\n",
       "      <td>TRAIN_7489</td>\n",
       "      <td>H사</td>\n",
       "      <td>ION5</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>8871</td>\n",
       "      <td>9</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>35.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7490</th>\n",
       "      <td>TRAIN_7490</td>\n",
       "      <td>A사</td>\n",
       "      <td>Q4eT</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>5794</td>\n",
       "      <td>7</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>59.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7491</th>\n",
       "      <td>TRAIN_7491</td>\n",
       "      <td>K사</td>\n",
       "      <td>Soul</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FWD</td>\n",
       "      <td>5966</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>16.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>TRAIN_7492</td>\n",
       "      <td>H사</td>\n",
       "      <td>ION5</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>3773</td>\n",
       "      <td>10</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>35.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>TRAIN_7494</td>\n",
       "      <td>P사</td>\n",
       "      <td>TayCT</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWD</td>\n",
       "      <td>1363</td>\n",
       "      <td>2</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2711 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID 제조사      모델        차량상태  배터리용량 구동방식  주행거리(km)  보증기간(년) 사고이력  \\\n",
       "3     TRAIN_0003  A사  RSeTGT  Nearly New    NaN  AWD     21683        3   No   \n",
       "6     TRAIN_0006  T사      MS  Nearly New    NaN  AWD     19395        3   No   \n",
       "8     TRAIN_0008  T사      MY   Brand New    NaN  AWD      2226        8   No   \n",
       "9     TRAIN_0009  A사    Q4eT   Brand New    NaN  AWD      3683        7   No   \n",
       "11    TRAIN_0011  V사     ID4   Brand New    NaN  AWD      1131        8   No   \n",
       "...          ...  ..     ...         ...    ...  ...       ...      ...  ...   \n",
       "7489  TRAIN_7489  H사    ION5   Brand New    NaN  AWD      8871        9   No   \n",
       "7490  TRAIN_7490  A사    Q4eT   Brand New    NaN  AWD      5794        7   No   \n",
       "7491  TRAIN_7491  K사    Soul   Brand New    NaN  FWD      5966       10   No   \n",
       "7492  TRAIN_7492  H사    ION5   Brand New    NaN  AWD      3773       10   No   \n",
       "7494  TRAIN_7494  P사   TayCT   Brand New    NaN  AWD      1363        2   No   \n",
       "\n",
       "      연식(년)  가격(백만원)  \n",
       "3         0    99.16  \n",
       "6         0    83.42  \n",
       "8         0    74.06  \n",
       "9         0    59.66  \n",
       "11        0    40.50  \n",
       "...     ...      ...  \n",
       "7489      0    35.83  \n",
       "7490      0    59.95  \n",
       "7491      0    16.75  \n",
       "7492      0    35.95  \n",
       "7494      0   120.00  \n",
       "\n",
       "[2711 rows x 11 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[train_df['배터리용량'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['보증기간(년)'] = train_df['보증기간(년)'].apply(lambda x: 'high' if x >= 7 else 'low')\n",
    "test_df['보증기간(년)'] = test_df['보증기간(년)'].apply(lambda x: 'high' if x >= 7 else 'low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_battery(cond_df, df):\n",
    "    for i in range(len(cond_df)):\n",
    "        model = cond_df.iloc[i]['모델']\n",
    "        status = cond_df.iloc[i]['차량상태']\n",
    "        warranty = cond_df.iloc[i]['보증기간(년)']\n",
    "        \n",
    "        cond = (train_df['모델'] == model) & (train_df['차량상태'] == status) & (train_df['보증기간(년)'] == warranty)       \n",
    "        df.loc[cond_df.iloc[i].name, '배터리용량'] = train_df[cond]['배터리용량'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_battery(train_df[train_df['배터리용량'].isna()], train_df)\n",
    "fill_battery(test_df[test_df['배터리용량'].isna()], test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>제조사</th>\n",
       "      <th>모델</th>\n",
       "      <th>차량상태</th>\n",
       "      <th>배터리용량</th>\n",
       "      <th>구동방식</th>\n",
       "      <th>주행거리(km)</th>\n",
       "      <th>보증기간(년)</th>\n",
       "      <th>사고이력</th>\n",
       "      <th>연식(년)</th>\n",
       "      <th>가격(백만원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>P사</td>\n",
       "      <td>TayGTS</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>86.077</td>\n",
       "      <td>AWD</td>\n",
       "      <td>13642</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>159.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>K사</td>\n",
       "      <td>Niro</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>56.000</td>\n",
       "      <td>FWD</td>\n",
       "      <td>10199</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>28.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>A사</td>\n",
       "      <td>eT</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>91.200</td>\n",
       "      <td>AWD</td>\n",
       "      <td>2361</td>\n",
       "      <td>high</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>66.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>A사</td>\n",
       "      <td>RSeTGT</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>78.227</td>\n",
       "      <td>AWD</td>\n",
       "      <td>21683</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>99.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>B사</td>\n",
       "      <td>i5</td>\n",
       "      <td>Pre-Owned</td>\n",
       "      <td>61.018</td>\n",
       "      <td>AWD</td>\n",
       "      <td>178205</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>62.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7492</th>\n",
       "      <td>TRAIN_7492</td>\n",
       "      <td>H사</td>\n",
       "      <td>ION5</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>90.000</td>\n",
       "      <td>AWD</td>\n",
       "      <td>3773</td>\n",
       "      <td>high</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>35.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7493</th>\n",
       "      <td>TRAIN_7493</td>\n",
       "      <td>B사</td>\n",
       "      <td>i3</td>\n",
       "      <td>Pre-Owned</td>\n",
       "      <td>46.000</td>\n",
       "      <td>RWD</td>\n",
       "      <td>135411</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>23.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7494</th>\n",
       "      <td>TRAIN_7494</td>\n",
       "      <td>P사</td>\n",
       "      <td>TayCT</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>90.000</td>\n",
       "      <td>AWD</td>\n",
       "      <td>1363</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>120.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>TRAIN_7495</td>\n",
       "      <td>B사</td>\n",
       "      <td>i3</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>56.000</td>\n",
       "      <td>RWD</td>\n",
       "      <td>39445</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>2</td>\n",
       "      <td>24.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>TRAIN_7496</td>\n",
       "      <td>T사</td>\n",
       "      <td>MY</td>\n",
       "      <td>Pre-Owned</td>\n",
       "      <td>51.940</td>\n",
       "      <td>AWD</td>\n",
       "      <td>80215</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>74.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7497 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID 제조사      모델        차량상태   배터리용량 구동방식  주행거리(km) 보증기간(년) 사고이력  \\\n",
       "0     TRAIN_0000  P사  TayGTS  Nearly New  86.077  AWD     13642     low   No   \n",
       "1     TRAIN_0001  K사    Niro  Nearly New  56.000  FWD     10199     low   No   \n",
       "2     TRAIN_0002  A사      eT   Brand New  91.200  AWD      2361    high   No   \n",
       "3     TRAIN_0003  A사  RSeTGT  Nearly New  78.227  AWD     21683     low   No   \n",
       "4     TRAIN_0004  B사      i5   Pre-Owned  61.018  AWD    178205     low   No   \n",
       "...          ...  ..     ...         ...     ...  ...       ...     ...  ...   \n",
       "7492  TRAIN_7492  H사    ION5   Brand New  90.000  AWD      3773    high   No   \n",
       "7493  TRAIN_7493  B사      i3   Pre-Owned  46.000  RWD    135411     low   No   \n",
       "7494  TRAIN_7494  P사   TayCT   Brand New  90.000  AWD      1363     low   No   \n",
       "7495  TRAIN_7495  B사      i3  Nearly New  56.000  RWD     39445     low   No   \n",
       "7496  TRAIN_7496  T사      MY   Pre-Owned  51.940  AWD     80215     low   No   \n",
       "\n",
       "      연식(년)  가격(백만원)  \n",
       "0         2   159.66  \n",
       "1         0    28.01  \n",
       "2         0    66.27  \n",
       "3         0    99.16  \n",
       "4         0    62.02  \n",
       "...     ...      ...  \n",
       "7492      0    35.95  \n",
       "7493      0    23.40  \n",
       "7494      0   120.00  \n",
       "7495      2    24.00  \n",
       "7496      0    74.06  \n",
       "\n",
       "[7497 rows x 11 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7497 entries, 0 to 7496\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   ID        7497 non-null   object \n",
      " 1   제조사       7497 non-null   object \n",
      " 2   모델        7497 non-null   object \n",
      " 3   차량상태      7497 non-null   object \n",
      " 4   배터리용량     7497 non-null   float64\n",
      " 5   구동방식      7497 non-null   object \n",
      " 6   주행거리(km)  7497 non-null   int64  \n",
      " 7   보증기간(년)   7497 non-null   object \n",
      " 8   사고이력      7497 non-null   object \n",
      " 9   연식(년)     7497 non-null   int64  \n",
      " 10  가격(백만원)   7497 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(7)\n",
      "memory usage: 644.4+ KB\n"
     ]
    }
   ],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>제조사</th>\n",
       "      <th>모델</th>\n",
       "      <th>차량상태</th>\n",
       "      <th>배터리용량</th>\n",
       "      <th>구동방식</th>\n",
       "      <th>주행거리(km)</th>\n",
       "      <th>보증기간(년)</th>\n",
       "      <th>사고이력</th>\n",
       "      <th>연식(년)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>P사</td>\n",
       "      <td>TayCT</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>76.093</td>\n",
       "      <td>AWD</td>\n",
       "      <td>14057</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>B사</td>\n",
       "      <td>iX</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>90.000</td>\n",
       "      <td>AWD</td>\n",
       "      <td>7547</td>\n",
       "      <td>high</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>B사</td>\n",
       "      <td>i5</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>90.000</td>\n",
       "      <td>RWD</td>\n",
       "      <td>7197</td>\n",
       "      <td>high</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>H사</td>\n",
       "      <td>ION5</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>68.479</td>\n",
       "      <td>AWD</td>\n",
       "      <td>10357</td>\n",
       "      <td>high</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>K사</td>\n",
       "      <td>EV6</td>\n",
       "      <td>Brand New</td>\n",
       "      <td>90.000</td>\n",
       "      <td>FWD</td>\n",
       "      <td>7597</td>\n",
       "      <td>high</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>TEST_841</td>\n",
       "      <td>P사</td>\n",
       "      <td>TayGTS</td>\n",
       "      <td>Pre-Owned</td>\n",
       "      <td>64.683</td>\n",
       "      <td>AWD</td>\n",
       "      <td>117298</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>TEST_842</td>\n",
       "      <td>V사</td>\n",
       "      <td>ID4</td>\n",
       "      <td>Pre-Owned</td>\n",
       "      <td>55.547</td>\n",
       "      <td>AWD</td>\n",
       "      <td>72308</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>TEST_843</td>\n",
       "      <td>V사</td>\n",
       "      <td>ID4</td>\n",
       "      <td>Pre-Owned</td>\n",
       "      <td>55.547</td>\n",
       "      <td>AWD</td>\n",
       "      <td>124537</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>TEST_844</td>\n",
       "      <td>A사</td>\n",
       "      <td>Q4eT</td>\n",
       "      <td>Nearly New</td>\n",
       "      <td>69.646</td>\n",
       "      <td>AWD</td>\n",
       "      <td>15629</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>TEST_845</td>\n",
       "      <td>B사</td>\n",
       "      <td>i3</td>\n",
       "      <td>Pre-Owned</td>\n",
       "      <td>46.000</td>\n",
       "      <td>AWD</td>\n",
       "      <td>53945</td>\n",
       "      <td>low</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>846 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID 제조사      모델        차량상태   배터리용량 구동방식  주행거리(km) 보증기간(년) 사고이력  \\\n",
       "0    TEST_000  P사   TayCT  Nearly New  76.093  AWD     14057     low   No   \n",
       "1    TEST_001  B사      iX   Brand New  90.000  AWD      7547    high   No   \n",
       "2    TEST_002  B사      i5   Brand New  90.000  RWD      7197    high  Yes   \n",
       "3    TEST_003  H사    ION5  Nearly New  68.479  AWD     10357    high   No   \n",
       "4    TEST_004  K사     EV6   Brand New  90.000  FWD      7597    high   No   \n",
       "..        ...  ..     ...         ...     ...  ...       ...     ...  ...   \n",
       "841  TEST_841  P사  TayGTS   Pre-Owned  64.683  AWD    117298     low   No   \n",
       "842  TEST_842  V사     ID4   Pre-Owned  55.547  AWD     72308     low   No   \n",
       "843  TEST_843  V사     ID4   Pre-Owned  55.547  AWD    124537     low   No   \n",
       "844  TEST_844  A사    Q4eT  Nearly New  69.646  AWD     15629     low   No   \n",
       "845  TEST_845  B사      i3   Pre-Owned  46.000  AWD     53945     low   No   \n",
       "\n",
       "     연식(년)  \n",
       "0        0  \n",
       "1        0  \n",
       "2        0  \n",
       "3        1  \n",
       "4        0  \n",
       "..     ...  \n",
       "841      0  \n",
       "842      0  \n",
       "843      0  \n",
       "844      0  \n",
       "845      0  \n",
       "\n",
       "[846 rows x 10 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "\n",
    "object_list = ['제조사', '모델', '차량상태', '구동방식', '보증기간(년)', '사고이력']\n",
    "\n",
    "for col in object_list:\n",
    "    train_df[col] = encoder.fit_transform(train_df[col])\n",
    "    test_df[col] = encoder.fit_transform(test_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>제조사</th>\n",
       "      <th>모델</th>\n",
       "      <th>차량상태</th>\n",
       "      <th>배터리용량</th>\n",
       "      <th>구동방식</th>\n",
       "      <th>주행거리(km)</th>\n",
       "      <th>보증기간(년)</th>\n",
       "      <th>사고이력</th>\n",
       "      <th>연식(년)</th>\n",
       "      <th>가격(백만원)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_0000</td>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>86.077</td>\n",
       "      <td>0</td>\n",
       "      <td>13642</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>159.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_0001</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>56.000</td>\n",
       "      <td>1</td>\n",
       "      <td>10199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_0002</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>91.200</td>\n",
       "      <td>0</td>\n",
       "      <td>2361</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_0003</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>78.227</td>\n",
       "      <td>0</td>\n",
       "      <td>21683</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_0004</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>61.018</td>\n",
       "      <td>0</td>\n",
       "      <td>178205</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  제조사  모델  차량상태   배터리용량  구동방식  주행거리(km)  보증기간(년)  사고이력  연식(년)  \\\n",
       "0  TRAIN_0000    4  16     1  86.077     0     13642        1     0      2   \n",
       "1  TRAIN_0001    3  10     1  56.000     1     10199        1     0      0   \n",
       "2  TRAIN_0002    0  17     0  91.200     0      2361        0     0      0   \n",
       "3  TRAIN_0003    0  12     1  78.227     0     21683        1     0      0   \n",
       "4  TRAIN_0004    1  19     2  61.018     0    178205        1     0      0   \n",
       "\n",
       "   가격(백만원)  \n",
       "0   159.66  \n",
       "1    28.01  \n",
       "2    66.27  \n",
       "3    99.16  \n",
       "4    62.02  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>제조사</th>\n",
       "      <th>모델</th>\n",
       "      <th>차량상태</th>\n",
       "      <th>배터리용량</th>\n",
       "      <th>구동방식</th>\n",
       "      <th>주행거리(km)</th>\n",
       "      <th>보증기간(년)</th>\n",
       "      <th>사고이력</th>\n",
       "      <th>연식(년)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TEST_000</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>76.093</td>\n",
       "      <td>0</td>\n",
       "      <td>14057</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TEST_001</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>0</td>\n",
       "      <td>7547</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TEST_002</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>2</td>\n",
       "      <td>7197</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TEST_003</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68.479</td>\n",
       "      <td>0</td>\n",
       "      <td>10357</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TEST_004</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>90.000</td>\n",
       "      <td>1</td>\n",
       "      <td>7597</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  제조사  모델  차량상태   배터리용량  구동방식  주행거리(km)  보증기간(년)  사고이력  연식(년)\n",
       "0  TEST_000    4  15     1  76.093     0     14057        1     0      0\n",
       "1  TEST_001    1  20     0  90.000     0      7547        0     0      0\n",
       "2  TEST_002    1  19     0  90.000     2      7197        0     1      0\n",
       "3  TEST_003    2   2     1  68.479     0     10357        0     0      1\n",
       "4  TEST_004    3   0     0  90.000     1      7597        0     0      0"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('ID', axis = 1, inplace = True)\n",
    "test_df.drop('ID', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['가격(백만원)']\n",
    "feature = train_df.drop('가격(백만원)', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(feature, target, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = xgb.XGBRegressor(random_state = 42)\n",
    "\n",
    "params = {\n",
    "    'n_estimators' : [50, 100, 200, 300, 500, 1000, 2000],\n",
    "    'learning_rate' : [0.001, 0.005, 0.01, 0.05, 0.1],\n",
    "    'max_depth' : [3, 5, 7, 9, 12, 15],\n",
    "    'subsample' : [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree' : [0.8, 0.9, 1.0],\n",
    "    'gamma' : [0, 0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1000 candidates, totalling 5000 fits\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-10.117 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.735 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.636 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.634 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.856 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.226 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.283 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.247 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.244 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.299 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.182 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.200 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.175 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.151 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.233 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-22.418 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-22.083 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-21.988 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-21.565 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-21.314 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-11.277 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-11.115 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-11.115 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-10.878 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-10.684 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.488 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.154 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.046 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-22.562 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-22.379 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.800 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.779 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.807 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.716 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.743 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.337 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.285 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.312 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.173 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.333 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.226 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.288 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.243 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.224 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.309 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.218 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.243 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.216 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.158 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.290 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.636 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.490 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.464 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.242 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.139 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.9;, score=-18.561 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.9;, score=-18.295 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.9;, score=-18.226 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.9;, score=-17.900 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.9;, score=-17.702 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.185 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.243 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.183 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.162 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.256 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.212 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.282 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.244 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.207 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.290 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-18.205 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-17.960 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-17.927 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-17.537 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-17.326 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-11.239 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-11.080 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-11.094 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-10.813 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-10.670 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.224 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.278 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.242 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.235 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.296 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-11.140 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-10.998 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-11.035 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-10.781 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-10.577 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.645 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.492 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.469 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.274 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.136 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.203 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.276 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.227 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.226 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.281 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-18.403 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-18.127 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-18.085 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-17.697 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-17.503 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-11.139 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-10.986 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-11.034 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-10.750 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-10.594 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=1.0;, score=-24.498 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=1.0;, score=-24.172 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=1.0;, score=-24.069 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=1.0;, score=-23.591 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=1.0;, score=-23.339 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.227 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.294 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.257 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.243 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.312 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.903 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.888 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.875 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.787 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.865 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-22.443 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-22.127 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-22.023 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-21.631 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-21.388 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.8;, score=-23.313 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.8;, score=-23.013 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.8;, score=-22.907 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.8;, score=-22.489 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.8;, score=-22.198 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.386 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.375 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.310 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.261 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.437 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.278 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.329 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.251 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.217 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.349 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.9;, score=-18.297 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.9;, score=-18.023 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.9;, score=-17.984 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.9;, score=-17.595 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.9;, score=-17.410 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-11.484 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-11.304 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-11.299 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-11.017 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-10.891 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-22.272 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.958 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.871 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.430 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.204 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.176 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.248 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.209 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.192 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.258 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.476 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.496 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.465 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.364 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.558 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.478 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.280 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.288 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.005 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-10.869 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.203 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.254 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.230 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.199 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.269 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-2.751 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-2.758 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-2.804 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-2.729 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-2.713 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.983 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.601 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.657 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.502 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-4.107 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=-2.059 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=-2.065 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=-2.101 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=-2.039 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=1.0;, score=-2.047 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=1.0;, score=-6.041 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=1.0;, score=-6.148 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=1.0;, score=-6.039 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=1.0;, score=-5.928 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=1.0;, score=-5.758 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-22.384 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-22.054 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.965 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.522 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.298 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.176 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.217 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.185 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.143 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.269 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.187 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.228 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.190 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.168 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.254 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.230 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.297 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.262 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.238 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.304 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.976 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.973 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.989 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.909 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.921 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.221 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.300 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.245 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.246 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.322 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.454 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.225 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.139 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-17.821 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-17.618 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.265 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.300 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.244 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.201 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.349 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.242 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.280 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.232 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.206 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.310 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-27.143 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-26.766 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-26.636 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-26.114 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-25.856 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8;, score=-20.213 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8;, score=-19.856 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8;, score=-19.813 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8;, score=-19.394 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.8;, score=-19.277 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.962 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.564 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.671 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.269 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.896 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.9;, score=-2.056 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.9;, score=-1.982 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.9;, score=-1.946 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.9;, score=-1.886 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.9;, score=-2.035 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.981 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.974 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.991 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.916 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.938 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-14.064 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-13.596 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-13.636 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-13.303 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-13.429 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.968 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.948 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.959 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.884 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.908 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.340 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.283 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.387 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.262 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.179 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.223 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.262 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.223 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.165 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.329 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.186 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.224 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.170 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.153 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.284 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.773 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.755 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.784 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.717 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.727 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=-4.903 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=-4.826 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=-4.872 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=-4.671 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=1.0;, score=-4.790 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.583 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.464 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.277 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.247 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.792 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.202 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.273 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.220 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.214 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.288 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-28.437 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-28.055 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-27.916 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-27.371 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-27.103 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.208 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.273 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.217 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.208 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.283 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.9;, score=-1.221 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.9;, score=-1.309 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.9;, score=-1.266 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.9;, score=-1.256 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.9;, score=-1.324 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.235 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.270 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.180 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.169 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.315 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=1.0;, score=-10.038 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=1.0;, score=-9.903 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=1.0;, score=-9.839 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=1.0;, score=-9.749 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=1.0;, score=-9.245 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.600 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.237 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.147 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-22.702 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-22.474 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.485 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.492 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.500 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.283 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.545 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.195 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.213 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.195 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.159 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.243 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-18.187 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-17.939 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-17.915 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-17.517 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-17.314 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.262 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.196 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.214 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.037 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.010 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-25.504 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-25.134 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-25.025 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-24.564 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-24.297 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.219 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.243 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.216 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.156 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.291 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-6.137 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-5.619 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-5.760 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-5.504 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-6.263 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.189 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.235 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.172 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.165 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.254 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.8;, score=-27.530 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.8;, score=-27.161 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.8;, score=-27.014 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.8;, score=-26.477 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.8;, score=-26.243 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-3.013 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-3.001 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-2.989 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-2.922 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-2.973 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-11.239 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-11.079 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-11.093 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-10.813 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.9;, score=-10.670 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.471 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.412 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.462 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.343 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.311 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.8;, score=-23.388 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.8;, score=-23.058 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.8;, score=-22.960 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.8;, score=-22.502 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.8;, score=-22.269 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-5.427 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-5.094 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-4.975 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-5.055 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-5.486 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.177 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.197 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.180 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.146 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.231 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.477 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.268 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.285 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.003 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-10.862 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.289 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.316 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.278 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.228 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.334 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-24.566 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-24.225 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-24.117 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-23.640 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-23.396 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.223 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.309 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.264 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.255 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.329 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-11.421 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-11.242 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-11.246 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-10.967 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-10.833 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.216 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.234 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.173 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.150 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.281 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.822 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.662 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.522 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.252 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.760 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-28.476 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-28.088 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-27.946 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-27.407 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-27.136 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.214 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.240 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.192 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.144 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.299 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-6.116 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.904 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.833 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.910 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-6.200 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-11.439 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-11.257 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-11.259 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-10.978 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-10.837 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.252 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.326 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.280 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.249 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.340 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.278 total time=122.8min\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.370 total time=   9.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.312 total time=   5.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.322 total time=   4.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.385 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.196 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.299 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.242 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.229 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.299 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.576 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.579 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.621 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.392 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.270 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.9;, score=-22.269 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.9;, score=-21.960 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.9;, score=-21.865 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.9;, score=-21.443 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.9;, score=-21.190 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.182 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.230 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.173 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.151 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.283 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.186 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.271 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.228 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.215 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.279 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.750 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.708 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.762 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.631 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.655 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.214 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.228 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.166 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.148 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.281 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.229 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.273 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.227 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.182 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.336 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=1.0;, score=-11.235 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=1.0;, score=-11.079 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=1.0;, score=-11.089 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=1.0;, score=-10.808 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=1.0;, score=-10.664 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.183 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.225 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.187 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.154 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.256 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.177 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.231 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.173 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.143 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.276 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.268 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.306 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.247 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.196 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.353 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.177 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.199 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.177 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.146 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.224 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.191 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.252 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.214 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.193 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.270 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.679 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.587 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.617 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.503 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.474 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.589 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.269 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.225 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.194 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.582 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.644 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.564 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.527 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.430 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.675 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.317 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.319 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.277 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.198 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.317 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.545 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.488 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.461 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.392 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.613 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.190 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.234 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.174 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.168 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.247 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.177 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.236 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.180 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.163 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.264 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=1.0;, score=-28.470 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=1.0;, score=-28.083 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=1.0;, score=-27.941 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=1.0;, score=-27.398 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=1.0;, score=-27.131 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-18.312 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-18.040 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.998 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.606 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.415 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.273 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.298 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.223 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.200 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.338 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.212 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.253 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.216 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.182 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.292 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.238 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.304 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.293 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.231 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.323 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.201 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.250 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.231 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.216 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.278 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=-1.192 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=-1.253 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=-1.209 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=-1.197 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.8;, score=-1.274 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.196 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.242 total time=   2.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.232 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.214 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.264 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.294 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.332 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.249 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.206 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.380 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.623 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.559 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.529 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.418 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.628 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.177 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.229 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.215 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.188 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.258 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.645 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.492 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.469 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.274 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.136 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.207 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.254 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.231 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.201 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.302 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.507 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.652 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.491 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.347 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-6.965 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.224 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.263 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.228 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.210 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.291 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.199 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.230 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.209 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.174 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.275 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.8;, score=-2.885 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.8;, score=-2.867 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.8;, score=-2.901 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.8;, score=-2.833 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.8;, score=-2.823 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.199 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.231 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.211 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.172 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.269 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.183 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.225 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.187 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.154 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.256 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.224 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.265 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.226 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.164 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.317 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.502 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.172 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.072 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-23.592 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-23.342 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.775 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.746 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.717 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.620 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.896 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.195 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.216 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.187 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.155 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.251 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.195 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.244 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.220 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.179 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.280 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.201 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.248 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.212 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.175 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.264 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.718 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.326 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.183 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-27.651 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-27.373 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=1.0;, score=-2.982 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=1.0;, score=-2.986 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=1.0;, score=-3.002 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=1.0;, score=-2.932 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=1.0;, score=-2.940 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-7.003 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.894 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.958 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.759 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.662 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.179 total time=   3.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.251 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.209 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.191 total time=   3.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.256 total time=   3.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.221 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.295 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.256 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.254 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.302 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=-2.489 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=-2.345 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=-2.314 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=-2.283 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.9;, score=-2.642 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-7.610 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-7.063 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-7.110 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-6.893 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-7.382 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.341 total time=11.2min\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.279 total time=   3.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.381 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.254 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.172 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.169 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.186 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.154 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.092 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.184 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-2.175 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-2.155 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-1.989 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-2.005 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-2.192 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.421 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.078 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.963 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.604 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.269 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-18.302 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-18.033 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-17.983 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-17.601 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-17.403 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.186 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.275 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.224 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.196 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.267 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.177 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.197 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.180 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.146 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.231 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-20.109 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-19.868 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-19.716 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-19.070 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-19.222 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.272 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.286 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.246 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.230 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.322 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-18.187 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.938 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.913 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.514 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.310 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.086 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-10.933 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-10.975 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-10.692 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-10.541 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.787 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.477 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.567 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-12.857 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.307 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.158 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.197 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.175 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.122 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.192 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.9;, score=-3.806 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.9;, score=-3.757 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.9;, score=-3.573 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.9;, score=-3.587 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.9;, score=-3.757 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-11.530 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-11.321 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-11.317 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-11.059 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-10.883 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.224 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.306 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.243 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.255 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.335 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.801 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.788 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.803 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.765 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.754 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.200 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.272 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.231 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.220 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.289 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.209 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.254 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.231 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.223 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.283 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-18.424 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-18.148 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-18.094 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-17.708 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.8;, score=-17.515 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.312 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.317 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.276 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.193 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.309 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-11.117 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-10.976 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-11.013 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-10.757 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-10.557 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.387 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.361 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.304 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.256 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.425 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-27.058 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-26.699 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-26.570 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-26.058 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-25.783 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-7.610 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-7.063 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-7.110 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-6.893 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.8;, score=-7.382 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.244 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.289 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.234 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.176 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.323 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.063 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.077 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.074 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.024 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.076 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.441 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.444 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.439 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.243 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.486 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.772 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.756 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.782 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.718 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.728 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.221 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.256 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.184 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.172 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.304 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=0.9;, score=-7.784 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=0.9;, score=-7.619 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=0.9;, score=-7.630 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=0.9;, score=-7.514 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=0.9;, score=-7.421 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-18.291 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-18.025 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.979 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.593 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.404 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.8;, score=-28.518 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.8;, score=-28.128 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.8;, score=-27.985 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.8;, score=-27.452 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.8;, score=-27.179 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.203 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.228 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.222 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.188 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.253 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-2.019 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.908 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.929 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.829 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-2.038 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.183 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.215 total time=   3.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.207 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.162 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.241 total time=   3.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.8;, score=-22.197 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.8;, score=-21.898 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.8;, score=-21.819 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.8;, score=-21.378 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.8;, score=-21.137 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.489 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.194 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.139 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.765 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.545 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-11.078 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.924 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.976 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.686 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.533 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.235 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.277 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.250 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.222 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.297 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-11.484 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-11.304 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-11.299 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-11.017 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.8;, score=-10.890 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.185 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.203 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.182 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.152 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.232 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.187 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.232 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.167 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.163 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.245 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.454 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.225 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.139 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-17.821 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-17.618 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.278 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.329 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.251 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.217 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.349 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.243 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.078 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.087 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-10.804 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-10.670 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.237 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.267 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.216 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.164 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.315 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.213 total time=   3.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.293 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.234 total time=   3.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.230 total time=   3.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.308 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.227 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.324 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.253 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.243 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.315 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-3.003 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.965 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.959 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.892 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.932 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.766 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.719 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.760 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.601 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.667 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=-11.244 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=-11.082 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=-11.086 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=-10.840 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.9;, score=-10.658 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.180 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.216 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.199 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.162 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.233 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.795 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.780 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.800 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.744 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.749 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.421 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.078 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.963 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.604 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.269 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.221 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.316 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.247 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.254 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.303 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.8;, score=-4.693 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.8;, score=-4.607 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.8;, score=-4.636 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.8;, score=-4.521 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.8;, score=-4.499 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-28.517 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-28.127 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.984 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.449 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.179 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.303 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.369 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.313 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.286 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.402 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.189 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.238 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.208 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.180 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.265 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=1.0;, score=-11.464 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=1.0;, score=-11.278 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=1.0;, score=-11.280 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=1.0;, score=-10.997 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=1.0;, score=-10.868 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-18.177 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.928 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.898 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.512 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.300 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-23.595 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-23.238 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-23.143 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-22.805 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-22.473 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=1.0;, score=-27.110 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=1.0;, score=-26.746 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=1.0;, score=-26.608 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=1.0;, score=-26.115 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=1.0;, score=-25.844 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.9;, score=-1.203 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.9;, score=-1.279 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.9;, score=-1.248 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.9;, score=-1.222 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.9;, score=-1.284 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.198 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.281 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.235 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.218 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.283 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.199 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.232 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.212 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.176 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.269 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-4.320 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.796 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.709 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.841 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-4.309 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.277 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.334 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.273 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.251 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.366 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.221 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.259 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.236 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.218 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.296 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=1.0;, score=-18.454 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=1.0;, score=-18.173 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=1.0;, score=-18.118 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=1.0;, score=-17.734 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=1.0;, score=-17.546 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-28.437 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-28.055 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-27.916 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-27.372 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-27.103 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.214 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.309 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.253 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.248 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.317 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-6.868 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-6.759 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-6.865 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-6.702 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-6.506 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.882 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.863 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.901 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.828 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-2.817 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.225 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.312 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.246 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.234 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.313 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.238 total time=   6.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.332 total time=   6.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.264 total time=   6.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.275 total time=   6.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.340 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.175 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.211 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.175 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.137 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.259 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.537 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.178 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.069 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.707 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.378 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.280 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.345 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.278 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.260 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.359 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-28.436 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-28.054 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.915 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.370 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.103 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-20.254 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.924 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.848 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.449 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.259 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.230 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.274 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.268 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.232 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.312 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.281 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.308 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.229 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.196 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.366 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.180 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.229 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.168 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.141 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.270 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.760 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.678 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.659 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.530 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.796 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.287 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.302 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.241 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.207 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.360 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.218 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.310 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.249 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.252 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.304 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-23.385 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-23.059 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-22.957 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-22.520 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-22.260 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.254 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.304 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.255 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.252 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.337 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-11.477 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-11.277 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-11.286 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-11.004 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-10.864 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.237 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.306 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.268 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.257 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.333 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-22.192 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.891 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.816 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.371 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.135 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.686 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.299 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.154 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-27.630 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-27.344 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-18.476 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-18.190 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-18.137 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-17.748 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-17.563 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.220 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.237 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.171 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.155 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.277 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.196 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.221 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.186 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.162 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.249 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.238 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.284 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.230 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.207 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.319 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.9;, score=-2.300 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.9;, score=-2.313 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.9;, score=-2.279 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.9;, score=-2.224 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.9;, score=-2.319 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.614 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.521 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.483 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.290 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.599 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.252 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.289 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.245 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.187 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.337 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.614 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.577 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.519 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.421 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.631 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-18.217 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-17.968 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-17.938 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-17.552 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-17.339 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.187 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.229 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.220 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.189 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.255 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.986 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.971 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.969 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.881 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.932 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.193 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.249 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.231 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.211 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.273 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.179 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.201 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.167 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.125 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.247 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.209 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.282 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.235 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.220 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.313 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.204 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.255 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.219 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.208 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.271 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.219 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.263 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.222 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.218 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.295 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.421 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-24.078 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.963 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.604 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=1.0;, score=-23.269 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-18.194 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-17.967 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-17.917 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-17.563 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-17.306 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.258 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.250 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.267 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.059 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.8;, score=-3.265 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.454 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.113 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.016 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-22.556 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-22.322 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=-1.794 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=-1.704 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=-1.684 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=-1.572 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=1.0;, score=-1.743 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.219 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.308 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.251 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.245 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.300 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.169 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.207 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.166 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.119 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.257 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.906 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.891 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.881 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.817 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.9;, score=-2.870 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.879 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.869 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.916 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.845 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=0.8;, score=-2.825 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-18.822 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-18.535 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-18.463 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-18.121 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-17.911 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.598 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.454 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.488 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.389 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.579 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.508 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.304 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.306 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.033 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-10.871 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.176 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.230 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.181 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.142 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.265 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.300 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.047 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.988 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.615 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.392 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.190 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.200 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.170 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.123 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.243 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-18.219 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.994 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.940 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.605 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.330 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.233 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.305 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.258 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.237 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.318 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.182 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.242 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.177 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.168 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.262 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-6.287 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-6.027 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-5.923 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-6.002 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-6.345 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.191 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.235 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.174 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.165 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.256 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.182 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.251 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.224 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.195 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.268 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.255 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.339 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.274 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.274 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.327 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.235 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.244 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.184 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.149 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.296 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.219 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.278 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.240 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.217 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.308 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.238 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.288 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.239 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.234 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.300 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.508 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.304 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.306 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.033 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-10.871 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.236 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.266 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.177 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.156 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.315 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-18.205 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-17.956 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-17.931 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-17.531 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-17.328 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-23.653 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-23.308 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-23.204 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-22.757 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-22.527 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.288 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.350 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.281 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.265 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.369 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.255 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.102 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.107 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-10.868 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-10.670 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-27.540 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-27.166 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-27.029 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-26.548 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-26.250 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.191 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.247 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.230 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.198 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.260 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.205 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.248 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.237 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.198 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.288 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.218 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.262 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.205 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.153 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.311 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.187 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.192 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.181 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.141 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.233 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.212 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.277 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.228 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.226 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.293 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.170 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.205 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.194 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.151 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.233 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.255 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.269 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.209 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.170 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.326 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=1.0;, score=-18.289 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=1.0;, score=-18.027 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=1.0;, score=-17.974 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=1.0;, score=-17.585 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=1.0;, score=-17.388 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=1.0;, score=-2.756 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=1.0;, score=-2.746 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=1.0;, score=-2.805 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=1.0;, score=-2.723 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=1.0;, score=-2.696 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.217 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.247 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.218 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.161 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.304 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.188 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.225 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.174 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.163 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.282 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.716 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.588 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.484 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-12.725 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.339 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.642 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.291 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.181 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-23.704 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-23.462 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.8;, score=-2.684 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.8;, score=-2.479 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.8;, score=-2.466 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.8;, score=-2.383 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.8;, score=-2.663 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-11.251 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-11.082 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-11.094 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-10.813 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-10.679 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.230 total time=   4.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.315 total time=   3.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.252 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.247 total time=   4.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.314 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-23.475 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-23.138 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-23.035 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-22.592 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-22.340 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-20.227 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.898 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.820 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.437 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.248 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.226 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.318 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.257 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.251 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.318 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=1.0;, score=-24.605 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=1.0;, score=-24.276 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=1.0;, score=-24.147 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=1.0;, score=-23.714 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=1.0;, score=-23.458 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-18.165 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.917 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.893 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.496 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.292 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.190 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.234 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.174 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.168 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.247 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-22.626 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-22.285 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-22.185 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-21.775 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.9;, score=-21.538 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.263 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.302 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.256 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.196 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.342 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-27.139 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-26.763 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-26.633 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-26.112 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-25.855 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-3.014 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-3.001 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-2.989 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-2.924 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=0.8;, score=-2.975 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8;, score=-1.515 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8;, score=-1.513 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8;, score=-1.460 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8;, score=-1.413 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.8;, score=-1.614 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.200 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.269 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.226 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.216 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.281 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.191 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.258 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.204 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.181 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.260 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.8;, score=-4.669 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.8;, score=-4.570 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.8;, score=-4.602 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.8;, score=-4.489 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=0.8;, score=-4.455 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.879 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.862 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.905 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.827 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.814 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-28.455 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-28.069 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-27.929 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-27.385 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=50, subsample=0.8;, score=-27.118 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.169 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.223 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.216 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.192 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.260 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.656 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.668 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.638 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.388 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.773 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.9;, score=-11.258 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.9;, score=-11.094 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.9;, score=-11.104 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.9;, score=-10.820 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.9;, score=-10.684 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-6.110 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-5.931 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-5.876 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-5.753 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-6.175 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.176 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.228 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.174 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.130 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.271 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.335 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.347 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.308 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.260 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.351 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.180 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.226 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.219 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.191 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.259 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.973 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.971 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.987 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.906 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=500, subsample=1.0;, score=-2.919 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.214 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.233 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.206 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.164 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.250 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.175 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.218 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.168 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.136 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.264 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.191 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.255 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.205 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.182 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.264 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.196 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.244 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.217 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.185 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.276 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.281 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.257 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.214 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.175 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.313 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.9;, score=-20.099 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.9;, score=-19.795 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.9;, score=-19.709 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.9;, score=-19.109 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.9;, score=-19.139 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.234 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.248 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.193 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.162 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.308 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-11.509 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-11.310 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-11.305 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-11.040 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-10.875 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.216 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.279 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.235 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.217 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.328 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.679 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.295 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.142 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-27.621 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-27.336 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-11.077 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.923 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.975 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.686 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.533 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=0.9;, score=-18.191 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=0.9;, score=-17.944 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=0.9;, score=-17.916 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=0.9;, score=-17.527 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=0.9;, score=-17.317 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.310 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.250 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.347 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.228 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.8;, score=-4.149 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.8;, score=-18.567 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.8;, score=-18.308 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.8;, score=-18.233 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.8;, score=-17.926 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=100, subsample=0.8;, score=-17.704 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-23.382 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-23.053 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-22.955 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-22.496 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-22.265 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-27.056 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-26.698 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-26.569 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-26.054 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-25.781 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.9;, score=-18.305 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.9;, score=-18.051 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.9;, score=-17.992 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.9;, score=-17.634 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.9;, score=-17.399 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-18.312 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-18.050 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-17.982 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-17.661 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-17.397 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.286 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.310 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.234 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.226 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.334 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-10.037 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.883 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.839 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.534 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.473 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-28.436 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-28.056 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-27.915 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-27.377 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=0.9;, score=-27.101 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-7.228 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-7.092 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-7.129 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-6.936 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-6.847 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.219 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.299 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.242 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.244 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.311 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.221 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.256 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.210 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.181 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.9;, score=-1.295 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-6.025 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.798 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.814 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.794 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-6.149 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-11.117 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-10.965 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-11.014 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-10.730 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-10.576 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.212 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.300 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.252 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.245 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.297 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=0.9;, score=-18.482 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=0.9;, score=-18.193 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=0.9;, score=-18.143 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=0.9;, score=-17.755 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=0.9;, score=-17.567 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-18.296 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-18.039 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-17.988 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-17.601 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=1.0;, score=-17.398 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.196 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.214 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.195 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.161 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=1.0;, score=-1.246 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-5.125 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-5.016 total time=   3.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-5.051 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-5.032 total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.967 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.478 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.280 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.287 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-11.004 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.9;, score=-10.869 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.233 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.287 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.252 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.239 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.325 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-24.563 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-24.221 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-24.113 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-23.636 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-23.394 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-11.083 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-10.931 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-10.981 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-10.695 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-10.544 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.696 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.542 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.525 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.328 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.185 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.307 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.325 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.262 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.218 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.368 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.182 total time=   5.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.227 total time=   5.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.206 total time=   5.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.160 total time=   5.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.262 total time=   5.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.9;, score=-3.912 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.9;, score=-3.458 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.9;, score=-3.789 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.9;, score=-3.338 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.9;, score=-4.088 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.176 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.242 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.162 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.153 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.268 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.193 total time=   3.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.241 total time=   3.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.178 total time=   3.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.162 total time=   3.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.257 total time=   3.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.362 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.289 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.384 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.244 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.177 total time=   5.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-6.137 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-5.619 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-5.760 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-5.504 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.8;, score=-6.263 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-18.464 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-18.237 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-18.145 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-17.891 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.8;, score=-17.624 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.235 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.285 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.254 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.244 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.318 total time=   2.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.240 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.277 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.207 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.194 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.298 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-22.276 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-21.968 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-21.870 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-21.455 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=0.8;, score=-21.194 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.9;, score=-18.418 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.9;, score=-18.141 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.9;, score=-18.090 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.9;, score=-17.706 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=50, subsample=0.9;, score=-17.507 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-18.460 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-18.172 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-18.114 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-17.742 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=0.8;, score=-17.524 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.204 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.223 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.178 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.150 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.282 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.985 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.783 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.760 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.541 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.8;, score=-11.396 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.8;, score=-22.447 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.8;, score=-22.139 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.8;, score=-22.027 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.8;, score=-21.653 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=300, subsample=0.8;, score=-21.390 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.9;, score=-6.243 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.9;, score=-5.834 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.9;, score=-5.862 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.9;, score=-5.599 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.9;, score=-6.176 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.177 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.231 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.169 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.135 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.266 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.187 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.271 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.218 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.197 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.268 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0;, score=-18.534 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0;, score=-18.268 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0;, score=-18.201 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0;, score=-17.834 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=1.0;, score=-17.674 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-22.188 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.903 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.814 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.384 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.123 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.228 total time=   4.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.316 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.264 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.226 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.316 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.192 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.227 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.205 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.170 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.264 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.686 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.299 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-28.154 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-27.630 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=1.0;, score=-27.344 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.189 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.242 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.219 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.188 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.277 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.205 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.300 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.245 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.208 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.286 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.178 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.248 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.193 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.177 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.267 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.188 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.249 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.214 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.175 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.271 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.198 total time=   9.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.283 total time=   9.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.220 total time=   9.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.203 total time=  10.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.281 total time=   9.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-25.422 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-25.068 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-24.949 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-24.463 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.9;, score=-24.226 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-10.136 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.692 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.636 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.584 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.829 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.174 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.209 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.168 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.121 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.254 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.283 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.298 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.246 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.218 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.338 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.166 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.218 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.192 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.161 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.247 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.198 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.273 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.216 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.214 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.290 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-27.533 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-27.165 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-27.014 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-26.505 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-26.243 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-4.320 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.796 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.709 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.841 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-4.309 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-11.492 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-11.294 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-11.293 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-11.008 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=0.8;, score=-10.879 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.222 total time=   5.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.313 total time=   5.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.262 total time=   5.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.269 total time=   5.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.315 total time=   5.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.189 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.199 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.175 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.126 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.251 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.989 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.873 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.934 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.732 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.626 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-18.311 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-18.040 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.998 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.606 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.415 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.208 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.237 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.202 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.146 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.9;, score=-1.288 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.193 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.254 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.203 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.177 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.259 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.147 total time=   2.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.008 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.042 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-10.813 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-10.584 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.236 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.266 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.177 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.156 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.315 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.221 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.260 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.191 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.176 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.302 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-18.175 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-17.928 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-17.898 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-17.513 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-17.301 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-20.109 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-19.868 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-19.716 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-19.070 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.8;, score=-19.222 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.210 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.274 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.225 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.195 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.283 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-11.426 total time=   3.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-11.249 total time=   3.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-11.252 total time=   3.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-10.971 total time=   3.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-10.841 total time=   3.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.226 total time=   6.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.299 total time=   6.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.260 total time=   6.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.245 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.322 total time=   6.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-7.484 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-7.042 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-7.242 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-6.891 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-7.446 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=0.9;, score=-2.915 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=0.9;, score=-2.891 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=0.9;, score=-2.921 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=0.9;, score=-2.842 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=0.9;, score=-2.852 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.264 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.297 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.247 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.196 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.350 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-27.095 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-26.725 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-26.595 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-26.075 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.8;, score=-25.816 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.216 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.295 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.252 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.244 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.318 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=1.0;, score=-4.624 total time=   7.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=1.0;, score=-4.547 total time=   8.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=1.0;, score=-4.586 total time=   7.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=1.0;, score=-4.470 total time=   8.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=1.0;, score=-4.426 total time=   8.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.295 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.333 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.254 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.216 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.369 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.8;, score=-11.120 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.8;, score=-10.967 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.8;, score=-11.011 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.8;, score=-10.728 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=0.8;, score=-10.573 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.246 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.257 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.213 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.172 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.343 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.8;, score=-25.501 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.8;, score=-25.130 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.8;, score=-25.020 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.8;, score=-24.542 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=0.8;, score=-24.300 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.204 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.276 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.230 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.204 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.285 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.208 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.265 total time=   4.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.238 total time=   4.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.207 total time=   5.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.291 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.239 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.303 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.263 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.248 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.314 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.636 total time=   4.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.543 total time=   4.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.584 total time=   4.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.460 total time=   4.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.424 total time=   4.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.203 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.257 total time=   2.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.228 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.225 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.283 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.221 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.254 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.216 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.179 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.274 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.990 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.874 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.934 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.732 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.627 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-11.140 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-10.998 total time=   2.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-11.035 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-10.781 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.9;, score=-10.577 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=-1.708 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=-1.652 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=-1.633 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=-1.553 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.9;, score=-1.743 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.382 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.377 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.311 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.272 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.447 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=1.0;, score=-1.313 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=1.0;, score=-1.376 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=1.0;, score=-1.313 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=1.0;, score=-1.295 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=1.0;, score=-1.393 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-24.647 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-24.297 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-24.188 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-23.710 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-23.463 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-18.321 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-18.056 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-17.998 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-17.642 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=0.9;, score=-17.409 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.159 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.214 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.197 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.178 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.240 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.175 total time=   3.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.201 total time=   2.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.180 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.144 total time=   2.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.228 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.228 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.322 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.256 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.269 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.323 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.9;, score=-4.335 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.9;, score=-3.592 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.9;, score=-3.598 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.9;, score=-3.679 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.9;, score=-4.189 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-18.403 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-18.127 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-18.084 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-17.696 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.9;, score=-17.503 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.282 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.350 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.283 total time=   2.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.262 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.367 total time=   2.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.651 total time=   5.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.570 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.607 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.496 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.8;, score=-4.459 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8;, score=-11.483 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8;, score=-11.295 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8;, score=-11.293 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8;, score=-11.009 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=100, subsample=0.8;, score=-10.887 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-23.487 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-23.173 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-23.026 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-22.712 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=1.0;, score=-22.380 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-18.312 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-18.040 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.997 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.606 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=12, n_estimators=100, subsample=1.0;, score=-17.415 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.054 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.084 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.096 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.048 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.8;, score=-2.074 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.678 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.580 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.616 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.491 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.461 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.880 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.871 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.870 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.790 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=1.0;, score=-2.838 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.274 total time=   4.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.334 total time=   4.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.307 total time=   4.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.305 total time=   4.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.367 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-28.685 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-28.295 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-28.154 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-27.597 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-27.344 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.180 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.231 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.176 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.144 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.267 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.180 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.195 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.170 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.119 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.249 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=0.9;, score=-27.111 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=0.9;, score=-26.747 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=0.9;, score=-26.609 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=0.9;, score=-26.127 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=5, n_estimators=100, subsample=0.9;, score=-25.846 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.186 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.216 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.170 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.132 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.261 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.211 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.263 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.243 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.247 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.292 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.646 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.296 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.184 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-23.707 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-23.465 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-11.250 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-11.086 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-11.109 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-10.826 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-10.688 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.247 total time=   8.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.309 total time=   8.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.273 total time=   7.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.282 total time=   8.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.318 total time=   8.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.227 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.257 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.192 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.167 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.307 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-5.369 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-5.078 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-4.991 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-4.983 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-5.431 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.061 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.075 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.074 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.019 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.066 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8;, score=-2.580 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8;, score=-2.343 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8;, score=-2.450 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8;, score=-2.303 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.8;, score=-2.547 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=1.0;, score=-27.137 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=1.0;, score=-26.762 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=1.0;, score=-26.631 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=1.0;, score=-26.110 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=1.0;, score=-25.852 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.185 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.220 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.177 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.151 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.237 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.477 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.268 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.285 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.003 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-10.862 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=1.0;, score=-3.260 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=1.0;, score=-3.265 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=1.0;, score=-3.288 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=1.0;, score=-3.195 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=1.0;, score=-3.278 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.194 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.254 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.212 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.195 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.9;, score=-1.268 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.243 total time=   7.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.325 total time=   7.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.269 total time=   7.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.269 total time=   7.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.331 total time=   7.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.224 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.296 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.259 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.239 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.318 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8;, score=-18.549 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8;, score=-18.284 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8;, score=-18.209 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8;, score=-17.908 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=50, subsample=0.8;, score=-17.682 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=-2.324 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=-2.323 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=-2.284 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=-2.205 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.8;, score=-2.326 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-23.486 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-23.164 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-23.017 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-22.464 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-22.383 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.175 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.223 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.178 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.140 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.269 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-18.476 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-18.191 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-18.137 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-17.748 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=100, subsample=1.0;, score=-17.564 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.9;, score=-23.306 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.9;, score=-22.992 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.9;, score=-22.904 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.9;, score=-22.442 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=0.9;, score=-22.199 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=-4.740 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=-4.698 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=-4.729 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=-4.577 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=200, subsample=0.8;, score=-4.639 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0;, score=-3.867 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0;, score=-3.805 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0;, score=-3.682 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0;, score=-3.388 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=1.0;, score=-4.099 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.491 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.506 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.459 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.372 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.566 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.194 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.262 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.221 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.206 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.295 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.225 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.258 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.183 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.172 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.296 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.509 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.394 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.361 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.191 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.036 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=1.0;, score=-7.002 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=1.0;, score=-6.898 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=1.0;, score=-6.953 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=1.0;, score=-6.764 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=1.0;, score=-6.652 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-27.060 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-26.697 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-26.572 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-26.050 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-25.787 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.230 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.274 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.211 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.174 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=0.8;, score=-1.308 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-14.034 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.699 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.613 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.379 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.9;, score=-13.471 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.877 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.611 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.583 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.331 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.960 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.222 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.290 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.255 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.226 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.296 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-4.320 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.796 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.709 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-3.841 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=1.0;, score=-4.309 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.383 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.404 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.305 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.262 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=1000, subsample=1.0;, score=-1.445 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.221 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.250 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.221 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.163 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.305 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.211 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.269 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.250 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.234 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.268 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-22.266 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.955 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.866 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.424 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.194 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.454 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.113 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.016 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-22.556 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-22.322 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.8;, score=-1.167 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.8;, score=-1.231 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.8;, score=-1.214 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.8;, score=-1.196 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.8;, score=-1.257 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.284 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.291 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.243 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.211 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.346 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.971 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.881 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.822 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.804 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-2.008 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.238 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.270 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.191 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.171 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.309 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.137 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.986 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.035 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.751 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.596 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.224 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.254 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.197 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.178 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.296 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.164 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.217 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.205 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.180 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.242 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.233 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.299 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.246 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.243 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.298 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-24.606 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-24.278 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-24.149 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-23.736 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-23.459 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.240 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.297 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.255 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.258 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.308 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.176 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.228 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.174 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.130 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=1.0;, score=-1.271 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.136 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.985 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.034 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.751 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.595 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-24.639 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-24.289 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-24.178 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-23.700 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-23.460 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.932 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.841 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.873 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.752 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.788 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.175 total time=   2.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.246 total time=   3.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.206 total time=   3.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.187 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.253 total time=   2.9s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=1.0;, score=-22.187 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=1.0;, score=-21.891 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=1.0;, score=-21.813 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=1.0;, score=-21.368 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=1.0;, score=-21.130 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.239 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.304 total time=   2.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.261 total time=   2.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.254 total time=   2.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.319 total time=   2.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.8;, score=-24.568 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.8;, score=-24.231 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.8;, score=-24.116 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.8;, score=-23.658 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.8;, score=-23.391 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.200 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.233 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.209 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.176 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.277 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.204 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.224 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.206 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.145 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.277 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.172 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.246 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.208 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.184 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.252 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.9;, score=-2.633 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.9;, score=-2.497 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.9;, score=-2.442 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.9;, score=-2.428 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=0.9;, score=-2.660 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.499 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.170 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.069 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-23.587 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-23.339 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.890 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.664 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.622 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.032 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.345 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.986 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.971 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.969 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.881 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=500, subsample=1.0;, score=-2.932 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.244 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.323 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.269 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.255 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.338 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.186 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.275 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.224 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.196 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.267 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.286 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.297 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.253 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.227 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.347 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.218 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.278 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.242 total time=   1.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.229 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.295 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.9;, score=-20.130 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.9;, score=-19.830 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.9;, score=-19.746 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.9;, score=-19.189 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=0.9;, score=-19.177 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-27.542 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-27.167 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-27.030 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-26.516 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=0.9;, score=-26.251 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.918 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.900 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.883 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.872 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.882 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.965 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.761 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.735 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.539 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.382 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.220 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.265 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.203 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.181 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.294 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-11.242 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-11.080 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-11.101 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-10.820 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-10.681 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.210 total time=   7.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.289 total time=   6.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.239 total time=   6.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.235 total time=   6.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.296 total time=   6.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-18.523 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-18.223 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-18.173 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-17.794 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-17.575 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.234 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.325 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.261 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.253 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=1.0;, score=-1.322 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-11.245 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-11.079 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-11.094 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-10.811 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=0.9;, score=-10.683 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.223 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.240 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.191 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.179 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=1.0;, score=-1.273 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.669 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.565 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.514 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.652 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.602 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.196 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.282 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.221 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.202 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.272 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.8;, score=-3.034 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.8;, score=-3.024 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.8;, score=-3.005 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.8;, score=-2.945 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.8;, score=-3.002 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.170 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.192 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.192 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.150 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.230 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.236 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.270 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.222 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.172 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.325 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.162 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.184 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.151 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.075 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.176 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.809 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.759 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.735 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.633 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.856 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.180 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.258 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.207 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.185 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.267 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.202 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.272 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.239 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.211 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.284 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.172 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.209 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.168 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.122 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.257 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.177 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.211 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.175 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.137 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.258 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-13.891 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-13.623 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-13.573 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-12.887 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-13.337 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.9;, score=-11.534 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.9;, score=-11.420 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.9;, score=-11.388 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.9;, score=-11.210 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=0.9;, score=-11.061 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-24.506 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-24.178 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-24.076 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-23.599 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-23.345 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.178 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.247 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.224 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.183 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.253 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.214 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.260 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.191 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.175 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.293 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-18.219 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.994 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.940 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.605 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.330 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.822 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.662 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.522 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.252 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.760 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=0.8;, score=-18.217 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=0.8;, score=-17.968 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=0.8;, score=-17.938 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=0.8;, score=-17.551 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=0.8;, score=-17.337 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.179 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.219 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.175 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.127 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.271 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.259 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.318 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.265 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.256 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.334 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.189 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.247 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.192 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.174 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.253 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-20.104 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.813 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.717 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.411 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.138 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.970 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.858 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.822 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-1.805 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=0.8;, score=-2.008 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-22.271 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-21.958 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-21.871 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-21.429 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-21.201 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.182 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.256 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.195 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.174 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.256 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.191 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.229 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.209 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.175 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.285 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.506 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.176 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.076 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-23.597 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-23.346 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.271 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.308 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.251 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.202 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.360 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.578 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.323 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.251 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-17.886 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-17.723 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-28.463 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-28.080 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.936 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.414 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.134 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.201 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.285 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.239 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.229 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.288 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-22.271 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-21.958 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-21.871 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-21.429 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.8;, score=-21.201 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.180 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.225 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.219 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.195 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=500, subsample=0.9;, score=-1.253 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.190 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.200 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.170 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.123 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.243 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.879 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.862 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.904 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.827 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=1.0;, score=-2.814 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.260 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.359 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.288 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.286 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.354 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.210 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.254 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.250 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.207 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.295 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.812 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.524 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.456 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-18.083 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=1.0;, score=-17.902 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-22.192 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.893 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.815 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.371 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.132 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=1.0;, score=-24.660 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=1.0;, score=-24.302 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=1.0;, score=-24.194 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=1.0;, score=-23.721 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=1.0;, score=-23.467 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.644 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.417 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.407 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.201 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.590 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.226 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.269 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.224 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.218 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.311 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.261 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.275 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.213 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.194 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.345 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-22.192 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.891 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.816 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.371 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.134 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.209 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.234 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.209 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.150 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.284 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.219 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.258 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.220 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.184 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.8;, score=-1.316 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.183 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.231 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.169 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.143 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.266 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.8;, score=-7.247 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.8;, score=-7.114 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.8;, score=-7.146 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.8;, score=-6.956 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.8;, score=-6.869 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.220 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.244 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.217 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.157 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.292 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-22.384 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-22.049 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-21.959 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-21.519 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-21.292 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.218 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.249 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.203 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.187 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.278 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.085 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-10.947 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-10.983 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-10.699 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-10.524 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-22.192 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.891 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.816 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.370 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.133 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-3.036 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-3.013 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-3.009 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.920 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=0.8;, score=-2.998 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-18.205 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-17.956 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-17.931 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-17.531 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=500, subsample=1.0;, score=-17.328 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-3.869 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-3.704 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-3.649 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-3.231 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-4.019 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-6.849 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-6.745 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-6.853 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-6.645 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.9;, score=-6.514 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.8;, score=-28.472 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.8;, score=-28.085 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.8;, score=-27.944 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.8;, score=-27.400 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.8;, score=-27.133 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-10.118 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.467 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.631 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-8.999 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.565 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.218 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.247 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.218 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.161 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=500, subsample=0.9;, score=-1.304 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.252 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.266 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.213 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.181 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.320 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.232 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.316 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.254 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.243 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.318 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=-1.493 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=-1.471 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=-1.408 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=-1.345 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=3, n_estimators=300, subsample=0.9;, score=-1.527 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.186 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.263 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.229 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.205 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.8;, score=-1.284 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-11.132 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-10.978 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-11.027 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-10.741 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.9;, score=-10.588 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.191 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.237 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.175 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.164 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=1.0;, score=-1.248 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.222 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.313 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.254 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.261 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.335 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.255 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.302 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.238 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.208 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.330 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.259 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.353 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.308 total time=   2.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.268 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.335 total time=   1.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-11.248 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-11.085 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-11.102 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-10.820 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=9, n_estimators=1000, subsample=0.8;, score=-10.677 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-20.112 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.913 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.767 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.471 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.225 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.170 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.225 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.183 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.158 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.247 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-22.382 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-22.055 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.964 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.521 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.300 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.894 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.906 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.900 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.824 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.861 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.644 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.549 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.525 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.429 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.669 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.233 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.273 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.181 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.165 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.313 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.244 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.323 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.271 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.251 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=1.0;, score=-1.342 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.200 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.290 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.221 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.204 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.275 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-24.563 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-24.226 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-24.112 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-23.649 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-23.388 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.228 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.285 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.254 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.240 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.322 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.679 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.667 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.576 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.544 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.724 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.178 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.230 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.176 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.147 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.268 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.225 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.279 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.236 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.225 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=50, subsample=0.9;, score=-1.325 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.426 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.367 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.378 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.384 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.349 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-28.471 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-28.084 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.943 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.400 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.133 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.506 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.394 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.361 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.143 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=1.0;, score=-11.034 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.999 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.988 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.985 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.913 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.945 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.291 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.292 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.233 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.206 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.313 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-27.093 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-26.724 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-26.593 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-26.081 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=0.9;, score=-25.812 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.208 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.294 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.241 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.239 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.317 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.8;, score=-2.309 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.8;, score=-2.317 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.8;, score=-2.276 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.8;, score=-2.226 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=300, subsample=0.8;, score=-2.318 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.749 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.708 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.762 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.631 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.655 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.211 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.263 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.221 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.215 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.281 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-18.458 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-18.229 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-18.140 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-17.856 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-17.621 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.895 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.868 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.875 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.801 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=50, subsample=0.8;, score=-2.862 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.229 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.260 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.210 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.204 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.286 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-10.037 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.883 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.839 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.534 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.9;, score=-9.473 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.185 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.230 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.223 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.200 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.255 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.226 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.273 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.228 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.221 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.297 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.257 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.349 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.308 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.258 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=1.0;, score=-1.345 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.346 total time=   2.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.283 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.385 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.261 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.178 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.199 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.265 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.217 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.220 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=500, subsample=0.8;, score=-1.282 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.948 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.757 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.735 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.541 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.394 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.228 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.242 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.188 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.155 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.8;, score=-1.304 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=-4.300 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=-4.246 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=-4.355 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=-4.221 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=1.0;, score=-4.132 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-22.267 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.953 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.867 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.424 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.9;, score=-21.200 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.217 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.272 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.234 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.212 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.295 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=0.8;, score=-23.457 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=0.8;, score=-23.124 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=0.8;, score=-23.024 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=0.8;, score=-22.565 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=0.8;, score=-22.330 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.235 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.082 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-11.078 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-10.803 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=1.0;, score=-10.650 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.214 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.261 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.228 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.201 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.9;, score=-1.287 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.224 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.274 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.210 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.200 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.300 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.452 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.385 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.453 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.326 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.275 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-23.653 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-23.308 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-23.204 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-22.757 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=1.0;, score=-22.527 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.164 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.211 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.199 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.173 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.236 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.562 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.221 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.113 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-23.636 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-23.392 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.181 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.227 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.176 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.139 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.260 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.679 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.295 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.142 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-27.602 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-27.337 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-18.582 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-18.326 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-18.254 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-17.929 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=500, subsample=0.9;, score=-17.728 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.217 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.282 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.252 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.245 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.305 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.215 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.257 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.211 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.204 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=500, subsample=0.9;, score=-1.298 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.841 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.768 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.702 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.583 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.908 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=1.0;, score=-3.739 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=1.0;, score=-3.744 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=1.0;, score=-3.697 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=1.0;, score=-3.697 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=1.0;, score=-3.698 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.335 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.346 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.305 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.254 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=300, subsample=0.9;, score=-2.356 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.226 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.314 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.262 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.246 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.314 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.233 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.279 total time=   1.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.247 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.224 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.303 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.225 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.312 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.246 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.234 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.313 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.191 total time=   3.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.243 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.221 total time=   3.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.205 total time=   3.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.260 total time=   3.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.223 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.302 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.267 total time=   2.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.248 total time=   2.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.332 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.154 total time=   2.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.206 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.198 total time=   2.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.170 total time=   3.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.229 total time=   3.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.188 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.214 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.189 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.154 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.226 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-27.092 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-26.722 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-26.593 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-26.074 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-25.814 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.224 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.267 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.203 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.194 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.278 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.210 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.238 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.168 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.142 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.280 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-3.145 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-3.111 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-3.101 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-3.027 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=500, subsample=0.9;, score=-3.074 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.215 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.252 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.217 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.185 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.298 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.750 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.708 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.762 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.631 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.655 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=1.0;, score=-25.421 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=1.0;, score=-25.067 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=1.0;, score=-24.947 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=1.0;, score=-24.550 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=200, subsample=1.0;, score=-24.226 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.507 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.652 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.491 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.347 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-6.965 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.189 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.249 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.187 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.153 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.260 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.304 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.248 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.350 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.224 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=15, n_estimators=200, subsample=0.9;, score=-4.144 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-27.090 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.722 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.592 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.072 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-25.811 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-22.188 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.903 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.814 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.384 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.123 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.171 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.242 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.206 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.185 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=1000, subsample=0.8;, score=-1.257 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.179 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.218 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.179 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.137 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.258 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-7.003 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.894 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.957 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.758 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.661 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.261 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.331 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.288 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.290 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.353 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.265 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.300 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.246 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.201 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.349 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.207 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.256 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.216 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.210 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.274 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-18.466 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-18.183 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-18.128 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-17.746 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=500, subsample=0.8;, score=-17.556 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-28.716 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-28.322 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-28.183 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-27.640 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.8;, score=-27.374 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.308 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.326 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.268 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.225 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=1000, subsample=0.8;, score=-1.376 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-23.486 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-23.140 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-23.033 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-22.527 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.8;, score=-22.378 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-18.302 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-18.032 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.985 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.600 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.410 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.182 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.199 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.173 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.116 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.248 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-27.140 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-26.763 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-26.634 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-26.113 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=100, subsample=0.9;, score=-25.855 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-27.060 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-26.697 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-26.572 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-26.050 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=0.8;, score=-25.787 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-3.031 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-3.007 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.996 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.912 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=7, n_estimators=50, subsample=1.0;, score=-2.976 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-11.522 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-11.321 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-11.316 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-11.059 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.8;, score=-10.882 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=0.9;, score=-23.657 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=0.9;, score=-23.311 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=0.9;, score=-23.203 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=0.9;, score=-22.779 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=50, subsample=0.9;, score=-22.529 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.173 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.221 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.174 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.138 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=0.9;, score=-1.270 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.559 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.219 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.110 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-23.632 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-23.389 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.220 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.305 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.252 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.241 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.311 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.975 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.765 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.752 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.558 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=5, n_estimators=100, subsample=0.9;, score=-11.385 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.062 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.075 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.074 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.020 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.9;, score=-2.066 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9;, score=-20.227 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9;, score=-19.891 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9;, score=-19.829 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9;, score=-19.431 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=0.9;, score=-19.274 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-14.113 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.715 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.775 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.366 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=1.0;, score=-13.545 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-5.206 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-5.107 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-5.020 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-4.544 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.8;, score=-5.134 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.225 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.257 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.209 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.175 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.329 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=-1.190 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=-1.249 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=-1.233 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=-1.185 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=300, subsample=0.9;, score=-1.267 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-24.502 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-24.172 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-24.073 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-23.593 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.9;, score=-23.342 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.242 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.259 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.180 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.160 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.306 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.426 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.367 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.378 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.384 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=5, n_estimators=50, subsample=0.8;, score=-3.349 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.214 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.299 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.257 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.260 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.306 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.200 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.255 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.229 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.220 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.277 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.583 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.464 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.277 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.247 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=50, subsample=0.8;, score=-3.792 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.171 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.198 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.199 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.160 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=1.0;, score=-1.226 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-11.484 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-11.296 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-11.294 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-11.008 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=12, n_estimators=200, subsample=0.8;, score=-10.879 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.253 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.090 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.113 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.832 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.696 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.182 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.255 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.186 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.177 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.254 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-13.788 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-13.408 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-13.542 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-12.956 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=100, subsample=0.8;, score=-13.282 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.8;, score=-11.709 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.8;, score=-11.565 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.8;, score=-11.543 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.8;, score=-11.360 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.8;, score=-11.205 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-11.238 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-11.083 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-11.102 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-10.826 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-10.681 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-18.291 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-18.025 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.979 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.593 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=1.0;, score=-17.404 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-6.140 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-6.012 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-5.980 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-5.388 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=500, subsample=0.8;, score=-5.992 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.201 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.246 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.219 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.203 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.276 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.216 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.311 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.250 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.231 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.292 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.576 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.579 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.621 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.392 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.270 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.264 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.296 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.246 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.194 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.350 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=-4.686 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=-4.583 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=-4.619 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=-4.499 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.9;, score=-4.465 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.287 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.318 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.241 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.228 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.337 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-7.240 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-7.111 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-7.136 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.947 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.868 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.488 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.175 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.028 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-22.561 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-22.382 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.219 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.244 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.217 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.157 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.292 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-10.057 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.374 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.582 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.093 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.564 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.294 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.331 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.249 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.206 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.380 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.484 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.501 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.455 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.372 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.9;, score=-1.574 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-18.407 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-18.119 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-18.075 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-17.685 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-17.490 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.932 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.841 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.873 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.752 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.788 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-18.475 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-18.190 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-18.133 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-17.750 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-17.549 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.293 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.300 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.245 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.211 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.344 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.968 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.980 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.999 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.928 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.680 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.9;, score=-1.489 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.9;, score=-1.471 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.9;, score=-1.447 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.9;, score=-1.389 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=50, subsample=0.9;, score=-1.592 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.205 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.285 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.242 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.225 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.302 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.847 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.740 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.843 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.635 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.505 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.348 total time=   2.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.284 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.386 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.262 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.8;, score=-4.180 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.822 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.662 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.522 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.252 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.760 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.191 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.235 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.174 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.165 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=1.0;, score=-1.256 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.191 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.258 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.220 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.207 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.277 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-22.272 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.958 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.871 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.430 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.204 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-22.191 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.893 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.815 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.371 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.132 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.397 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.393 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.294 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.276 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.424 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-5.158 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-5.039 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-5.041 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-5.001 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=0.8;, score=-4.977 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.156 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.211 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.198 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.176 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=0.8;, score=-1.235 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-22.411 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-22.072 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.984 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.548 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=7, n_estimators=300, subsample=1.0;, score=-21.306 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.968 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.980 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.999 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.928 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.680 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.170 total time=   1.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.224 total time=   1.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.209 total time=   1.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.188 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.8;, score=-1.247 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.182 total time=   1.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.226 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.221 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.194 total time=   1.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.254 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.167 total time=   2.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.216 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.205 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.184 total time=   2.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.240 total time=   3.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-10.016 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.859 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.821 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-8.867 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=300, subsample=0.8;, score=-9.462 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.231 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.293 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.246 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.230 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.314 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.467 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.277 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.273 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.016 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-10.839 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.255 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.319 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.264 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.265 total time=   1.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.335 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.491 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.506 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.460 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.372 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=0.8;, score=-1.566 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0;, score=-20.075 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0;, score=-19.880 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0;, score=-19.734 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0;, score=-19.433 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=50, subsample=1.0;, score=-19.192 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.231 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.304 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.242 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.235 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=500, subsample=0.8;, score=-1.306 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-22.266 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.955 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.866 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.424 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=9, n_estimators=300, subsample=0.9;, score=-21.194 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.554 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.441 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.408 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.189 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.080 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.209 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.264 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.198 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.173 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.294 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-20.254 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.924 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.848 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.449 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=1.0;, score=-19.259 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-11.117 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-10.976 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-11.013 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-10.757 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=200, subsample=0.9;, score=-10.557 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-11.259 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-11.096 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-11.094 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-10.872 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=100, subsample=0.8;, score=-10.665 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.214 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.242 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.210 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.156 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=0.9;, score=-1.301 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.213 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.273 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.227 total time=   1.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.224 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.290 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.452 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.381 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.434 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.305 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=2000, subsample=1.0;, score=-4.262 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-27.540 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-27.166 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-27.029 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-26.548 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=100, subsample=1.0;, score=-26.250 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.576 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.579 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.621 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.392 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=2000, subsample=0.9;, score=-7.270 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.226 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.299 total time=   1.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.258 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.256 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.8;, score=-1.319 total time=   1.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.213 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.246 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.212 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.157 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=0.8;, score=-1.296 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.207 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.258 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.226 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.227 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.284 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.207 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.276 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.234 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.211 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.8;, score=-1.289 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.188 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.204 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.183 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.148 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.227 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=0.8;, score=-4.453 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=0.8;, score=-4.374 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=0.8;, score=-4.440 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=0.8;, score=-4.316 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=0.8;, score=-4.262 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.218 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.297 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.244 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.239 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.301 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.306 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.318 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.256 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.210 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.399 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-28.436 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-28.054 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-27.915 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-27.370 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-27.103 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.179 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.227 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.171 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.143 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=7, n_estimators=200, subsample=1.0;, score=-1.276 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.182 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.216 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.178 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.151 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.250 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.192 total time=   2.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.238 total time=   2.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.178 total time=   2.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.162 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.255 total time=   2.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.900 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.846 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.900 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.740 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=2000, subsample=1.0;, score=-4.796 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-24.563 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-24.226 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-24.112 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-23.649 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=7, n_estimators=200, subsample=0.9;, score=-23.388 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.170 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.222 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.188 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.161 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.245 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.254 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.261 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.280 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.059 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.271 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.203 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.262 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.240 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.205 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.1, max_depth=9, n_estimators=300, subsample=0.9;, score=-1.275 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.771 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.681 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.657 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.512 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.766 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.8;, score=-7.239 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.8;, score=-7.099 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.8;, score=-7.134 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.8;, score=-6.940 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=12, n_estimators=300, subsample=0.8;, score=-6.849 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.231 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.271 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.240 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.239 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.305 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.279 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.309 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.227 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.197 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.354 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.182 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.199 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.173 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.116 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=7, n_estimators=1000, subsample=1.0;, score=-1.248 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-18.523 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-18.223 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-18.173 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-17.794 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=100, subsample=1.0;, score=-17.575 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.517 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.225 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.663 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-6.939 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=1.0;, score=-7.492 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-23.475 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-23.138 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-23.035 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-22.592 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=50, subsample=0.9;, score=-22.340 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.222 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.225 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.183 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.143 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.280 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=100, subsample=0.8;, score=-18.201 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=100, subsample=0.8;, score=-17.955 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=100, subsample=0.8;, score=-17.918 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=100, subsample=0.8;, score=-17.534 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=100, subsample=0.8;, score=-17.320 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.793 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.702 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.670 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.559 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.802 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-22.388 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-22.060 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.968 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.527 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=300, subsample=0.8;, score=-21.303 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.9;, score=-6.859 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.9;, score=-6.753 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.9;, score=-6.857 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.9;, score=-6.670 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.9;, score=-6.499 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=-5.413 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=-5.195 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=-4.997 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=-5.191 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=0.9;, score=-5.448 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.201 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.287 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.219 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.200 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=200, subsample=1.0;, score=-1.276 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.598 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.454 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.488 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.389 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.578 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.237 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.270 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.222 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.172 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.325 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=0.8;, score=-14.059 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=0.8;, score=-13.664 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=0.8;, score=-13.601 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=0.8;, score=-13.354 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=0.8;, score=-13.444 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-11.425 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-11.256 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-11.253 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-10.978 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=1.0;, score=-10.846 total time=   1.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-3.022 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-3.009 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-3.013 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-2.926 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=50, subsample=0.9;, score=-2.993 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.255 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.272 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.205 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.175 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=0.9;, score=-1.321 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.780 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.619 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.634 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.515 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=300, subsample=1.0;, score=-7.416 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.279 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.319 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.249 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.216 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.339 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.250 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.317 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.253 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.252 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.329 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.8;, score=-20.074 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.8;, score=-19.842 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.8;, score=-19.703 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.8;, score=-19.037 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.005, max_depth=3, n_estimators=100, subsample=0.8;, score=-19.212 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.220 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.241 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.169 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.166 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.289 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.418 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.384 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.313 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.266 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.459 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-24.647 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-24.296 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-24.185 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-23.707 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.8;, score=-23.464 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.209 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.282 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.238 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.212 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=1000, subsample=0.9;, score=-1.283 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-20.112 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.913 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.767 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.471 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.225 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.212 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.293 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.241 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.228 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=1.0;, score=-1.303 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.213 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.312 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.255 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.234 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=300, subsample=1.0;, score=-1.301 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-13.891 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-13.623 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-13.573 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-12.887 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=3, n_estimators=200, subsample=0.9;, score=-13.337 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.225 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.254 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.218 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.170 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=1000, subsample=0.8;, score=-1.310 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.155 total time=   2.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.211 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.197 total time=   3.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.172 total time=   4.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.232 total time=   3.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.488 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.154 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-23.046 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-22.562 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=3, n_estimators=300, subsample=0.9;, score=-22.379 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.248 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.264 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.206 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.164 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.327 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-28.437 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-28.055 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-27.916 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-27.371 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.8;, score=-27.103 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.390 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.385 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.296 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.282 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.425 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.198 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.281 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.223 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.203 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=1.0;, score=-1.272 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.244 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.319 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.303 total time=   1.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.284 total time=   2.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.9;, score=-1.324 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.292 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.293 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.250 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.194 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=0.8;, score=-2.297 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.9;, score=-4.645 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.9;, score=-4.568 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.9;, score=-4.602 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.9;, score=-4.487 total time=   2.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=2000, subsample=0.9;, score=-4.457 total time=   2.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.231 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.268 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.224 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.220 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.289 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.564 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.356 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.422 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.255 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=200, subsample=0.9;, score=-2.658 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.172 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.204 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.169 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.122 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=1.0;, score=-1.251 total time=   1.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-28.482 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-28.095 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.952 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.424 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=5, n_estimators=50, subsample=0.9;, score=-27.150 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.273 total time=   5.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.353 total time=   4.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.288 total time=   4.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.294 total time=   6.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.1, max_depth=12, n_estimators=2000, subsample=0.8;, score=-1.360 total time=   4.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-28.436 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-28.054 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-27.915 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-27.370 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=15, n_estimators=50, subsample=0.9;, score=-27.103 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-18.415 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-18.140 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-18.086 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-17.702 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=15, n_estimators=50, subsample=0.8;, score=-17.509 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.186 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.242 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.181 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.169 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=500, subsample=1.0;, score=-1.272 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.234 total time=   2.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.319 total time=   2.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.252 total time=   2.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.245 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.316 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.229 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.287 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.249 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.230 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.9;, score=-1.322 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.267 total time=   3.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.336 total time=   3.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.305 total time=   2.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.280 total time=   2.6s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=0.9;, score=-1.360 total time=   2.6s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-18.308 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-18.048 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-17.996 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-17.614 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=500, subsample=0.8;, score=-17.410 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-27.151 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-26.772 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-26.643 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-26.125 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=7, n_estimators=100, subsample=1.0;, score=-25.859 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-11.078 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-10.927 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-10.970 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-10.685 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=100, subsample=1.0;, score=-10.536 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.238 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.284 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.229 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.209 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=50, subsample=0.8;, score=-1.320 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-7.522 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-7.514 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-7.519 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-6.628 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.8;, score=-7.136 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.548 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.494 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.481 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.509 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=500, subsample=0.9;, score=-3.521 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.757 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.676 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.659 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.534 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.8;, score=-1.797 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.9;, score=-1.222 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.9;, score=-1.258 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.9;, score=-1.218 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.9;, score=-1.186 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=9, n_estimators=100, subsample=0.9;, score=-1.299 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.227 total time=   3.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.311 total time=   2.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.248 total time=   2.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.240 total time=   2.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.8;, score=-1.313 total time=   2.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.559 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.560 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.509 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.417 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.640 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.196 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.258 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.211 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.190 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.267 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-18.407 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-18.119 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-18.075 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-17.685 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=1.0;, score=-17.490 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-24.647 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-24.297 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-24.188 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-23.710 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.9;, score=-23.463 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.824 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.784 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.690 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.582 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=1.0;, score=-1.897 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.251 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.273 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.205 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.165 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.333 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.227 total time=   1.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.277 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.256 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.241 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.329 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-5.929 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-5.620 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-6.171 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-5.500 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=0.9;, score=-6.134 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.163 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.184 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.151 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.076 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.176 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.636 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.417 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.407 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.201 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.592 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=1.0;, score=-4.343 total time=   1.6s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=1.0;, score=-4.275 total time=   1.6s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=1.0;, score=-4.368 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=1.0;, score=-4.243 total time=   2.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=9, n_estimators=2000, subsample=1.0;, score=-4.167 total time=   2.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.396 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.375 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.311 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.271 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=500, subsample=0.9;, score=-1.447 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.193 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.228 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.171 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.164 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=100, subsample=0.8;, score=-1.275 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.173 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.226 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.217 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.195 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.266 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.9;, score=-11.475 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.9;, score=-11.297 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.9;, score=-11.289 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.9;, score=-11.006 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=0.9;, score=-10.889 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.8;, score=-27.141 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.8;, score=-26.766 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.8;, score=-26.636 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.8;, score=-26.114 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.8;, score=-25.856 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.218 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.273 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.233 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.219 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=1000, subsample=0.9;, score=-1.298 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-24.506 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-24.178 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-24.076 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-23.599 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=200, subsample=0.8;, score=-23.345 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-23.382 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-23.053 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-22.955 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-22.495 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=15, n_estimators=50, subsample=1.0;, score=-22.265 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.215 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.260 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.221 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.157 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.308 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.454 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.113 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-23.016 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-22.556 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.005, max_depth=12, n_estimators=50, subsample=1.0;, score=-22.322 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.502 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.172 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-24.072 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-23.592 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=0.9;, score=-23.341 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.216 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.262 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.219 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.189 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=5, n_estimators=1000, subsample=0.8;, score=-1.282 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.176 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.203 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.204 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.158 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=1.0;, score=-1.225 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-5.189 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-5.215 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-5.067 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-5.088 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=300, subsample=1.0;, score=-4.947 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.189 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.253 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.206 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.182 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.276 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.212 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.300 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.252 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.245 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=1.0;, score=-1.297 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=1.0;, score=-11.468 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=1.0;, score=-11.292 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=1.0;, score=-11.287 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=1.0;, score=-11.008 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=15, n_estimators=200, subsample=1.0;, score=-10.881 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.288 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.351 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.281 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.264 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.368 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.990 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.874 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.934 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.733 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=0.9;, score=-6.627 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.630 total time=   2.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.546 total time=   2.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.588 total time=   2.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.472 total time=   2.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=12, n_estimators=2000, subsample=0.9;, score=-4.436 total time=   2.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.822 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.662 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.522 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.252 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=1000, subsample=0.8;, score=-3.760 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-28.454 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-28.068 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.928 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.384 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=12, n_estimators=50, subsample=0.9;, score=-27.118 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.687 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.300 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-28.154 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-27.610 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=50, subsample=0.9;, score=-27.344 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-27.055 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.694 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.568 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.048 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-25.783 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.987 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.878 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.931 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.727 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.624 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-11.254 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-11.095 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-11.099 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-10.817 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=9, n_estimators=200, subsample=1.0;, score=-10.678 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.203 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.262 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.224 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.212 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.274 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.456 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.384 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.425 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.300 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=1.0;, score=-4.268 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.843 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.744 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.854 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.648 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.005, max_depth=15, n_estimators=300, subsample=0.9;, score=-6.515 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-11.127 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-10.972 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-11.023 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-10.733 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=1.0;, score=-10.580 total time=   0.9s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.227 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.286 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.246 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.227 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=0.8;, score=-1.330 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-2.000 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-1.966 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-1.945 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-1.918 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=300, subsample=1.0;, score=-2.176 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.218 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.296 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.252 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.246 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.05, max_depth=15, n_estimators=200, subsample=0.8;, score=-1.311 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-27.092 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-26.722 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-26.593 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-26.074 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.001, max_depth=15, n_estimators=100, subsample=0.9;, score=-25.815 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.797 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.704 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.670 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.559 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=3, n_estimators=2000, subsample=0.9;, score=-1.801 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.270 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.350 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.282 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.256 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=12, n_estimators=100, subsample=1.0;, score=-1.351 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.172 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.213 total time=   2.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.169 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.134 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.262 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-11.251 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-11.086 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-11.109 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-10.827 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=1000, subsample=0.8;, score=-10.688 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.228 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.262 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.193 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.173 total time=   1.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.308 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.270 total time=   1.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.302 total time=   1.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.233 total time=   1.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.196 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.352 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=300, subsample=0.9;, score=-1.222 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=300, subsample=0.9;, score=-1.304 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=300, subsample=0.9;, score=-1.253 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=300, subsample=0.9;, score=-1.237 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.05, max_depth=15, n_estimators=300, subsample=0.9;, score=-1.313 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.191 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.245 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.218 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.165 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=200, subsample=0.8;, score=-1.259 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.305 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.244 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.345 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.219 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.139 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.191 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.218 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.189 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.154 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=1.0;, score=-1.247 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.183 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.230 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.216 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.171 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=0.9;, score=-1.256 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.9;, score=-1.247 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.9;, score=-1.307 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.9;, score=-1.275 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.9;, score=-1.261 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.1, max_depth=15, n_estimators=50, subsample=0.9;, score=-1.349 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.215 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.238 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.168 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.143 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.279 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.214 total time=   6.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.293 total time=   7.9s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.242 total time=   6.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.237 total time=   6.7s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.005, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.298 total time=   7.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-24.639 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-24.289 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-24.178 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-23.700 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=1.0;, score=-23.460 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.194 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.212 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.184 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.153 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.05, max_depth=9, n_estimators=500, subsample=1.0;, score=-1.225 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.544 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.498 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.461 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.392 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=0.8;, score=-1.612 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.183 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.242 total time=   1.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.178 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.168 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.8;, score=-1.261 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.160 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.212 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.209 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.170 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.242 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.248 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.264 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.206 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.165 total time=   1.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.327 total time=   1.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=1.0;, score=-28.476 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=1.0;, score=-28.087 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=1.0;, score=-27.946 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=1.0;, score=-27.404 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=50, subsample=1.0;, score=-27.134 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.194 total time=   1.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.230 total time=   3.5s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.237 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.202 total time=   1.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=2000, subsample=0.9;, score=-1.273 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.209 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.235 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.210 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.151 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0, learning_rate=0.05, max_depth=7, n_estimators=100, subsample=1.0;, score=-1.283 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.190 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.249 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.218 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.195 total time=   1.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.05, max_depth=7, n_estimators=2000, subsample=0.9;, score=-1.284 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-20.227 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.898 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.820 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.437 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.001, max_depth=3, n_estimators=500, subsample=1.0;, score=-19.248 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.166 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.210 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.194 total time=   0.9s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.154 total time=   0.9s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=9, n_estimators=1000, subsample=0.9;, score=-1.236 total time=   1.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=1.0;, score=-4.309 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=1.0;, score=-4.242 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=1.0;, score=-4.334 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=1.0;, score=-4.210 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.01, max_depth=9, n_estimators=200, subsample=1.0;, score=-4.135 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=1.0;, score=-7.252 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=1.0;, score=-7.097 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=1.0;, score=-7.137 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=1.0;, score=-6.955 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=1.0;, score=-6.836 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=-4.699 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=-4.592 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=-4.623 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=-4.508 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=200, subsample=0.8;, score=-4.472 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0;, score=-3.972 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0;, score=-3.798 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0;, score=-3.729 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0;, score=-3.782 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=1.0;, score=-4.087 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.316 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.372 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.321 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.293 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.05, max_depth=15, n_estimators=100, subsample=0.9;, score=-1.412 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.177 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.197 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.180 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.146 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.231 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.214 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.240 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.192 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.144 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.299 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.220 total time=   0.8s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.238 total time=   0.9s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.176 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.151 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=5, n_estimators=2000, subsample=1.0;, score=-1.287 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.224 total time=   0.9s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.268 total time=   0.8s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.223 total time=   0.8s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.217 total time=   0.8s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=2000, subsample=0.9;, score=-1.288 total time=   0.8s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-27.144 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.764 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.637 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-26.116 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=9, n_estimators=100, subsample=1.0;, score=-25.853 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.999 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.989 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.984 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.913 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=50, subsample=1.0;, score=-2.945 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.220 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.245 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.178 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.162 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.304 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=0.9;, score=-2.986 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=0.9;, score=-2.988 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=0.9;, score=-3.005 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=0.9;, score=-2.927 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.005, max_depth=15, n_estimators=500, subsample=0.9;, score=-2.952 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.783 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.609 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.608 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.374 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.005, max_depth=3, n_estimators=2000, subsample=1.0;, score=-2.791 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.193 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.237 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.231 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.189 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=12, n_estimators=500, subsample=0.9;, score=-1.253 total time=   0.4s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.489 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.194 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.139 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.765 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.545 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.567 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.226 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.117 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-23.641 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-23.398 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=-1.295 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=-1.343 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=-1.271 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=-1.212 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.1, max_depth=5, n_estimators=100, subsample=1.0;, score=-1.386 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.281 total time=   1.7s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.360 total time=   1.7s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.298 total time=   1.6s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.299 total time=   1.8s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.369 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-24.677 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-24.334 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-24.213 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-23.776 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.1, learning_rate=0.001, max_depth=5, n_estimators=200, subsample=0.9;, score=-23.521 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.489 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.449 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.464 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.299 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.8;, score=-2.533 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.899 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.631 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.631 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.302 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.8;, score=-3.986 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.254 total time=   0.6s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.102 total time=   0.6s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-11.107 total time=   0.6s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-10.868 total time=   0.6s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=7, n_estimators=1000, subsample=0.8;, score=-10.670 total time=   0.6s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-18.177 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.928 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.898 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.512 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.01, max_depth=12, n_estimators=50, subsample=0.8;, score=-17.300 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.588 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.505 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.410 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.223 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.8;, score=-2.584 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0;, score=-18.446 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0;, score=-18.156 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0;, score=-18.108 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0;, score=-17.726 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.01, max_depth=7, n_estimators=50, subsample=1.0;, score=-17.508 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-4.020 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-3.637 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-3.693 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-3.537 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=500, subsample=0.9;, score=-4.132 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.152 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.202 total time=   1.4s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.193 total time=   1.5s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.166 total time=   1.5s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.01, max_depth=15, n_estimators=1000, subsample=0.9;, score=-1.229 total time=   1.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.247 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.291 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.233 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.178 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=7, n_estimators=50, subsample=1.0;, score=-1.324 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.9;, score=-11.699 total time=   0.5s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.9;, score=-11.552 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.9;, score=-11.533 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.9;, score=-11.339 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=0.9;, score=-11.205 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.655 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.631 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.634 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.633 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=1.0;, score=-2.678 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.210 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.237 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.174 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.149 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=5, n_estimators=300, subsample=1.0;, score=-1.296 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.212 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.300 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.252 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.245 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.1, max_depth=15, n_estimators=200, subsample=1.0;, score=-1.297 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-22.189 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-21.888 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-21.814 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-21.362 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.1, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=1.0;, score=-21.131 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.698 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.441 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.518 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.392 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.01, max_depth=3, n_estimators=1000, subsample=0.9;, score=-2.642 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.105 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.112 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.108 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.026 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=1.0;, score=-2.108 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8;, score=-4.071 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8;, score=-3.733 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8;, score=-3.788 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8;, score=-3.612 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=100, subsample=0.8;, score=-4.052 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=-2.729 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=-2.737 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=-2.509 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=-2.589 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=1.0;, score=-2.690 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=-1.824 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=-1.720 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=-1.673 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=-1.586 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_depth=3, n_estimators=200, subsample=0.8;, score=-1.819 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.224 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.300 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.251 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.239 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.1, max_depth=15, n_estimators=100, subsample=0.8;, score=-1.335 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.559 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.219 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-24.110 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-23.632 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=12, n_estimators=200, subsample=1.0;, score=-23.389 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.182 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.256 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.229 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.193 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.05, max_depth=12, n_estimators=300, subsample=0.9;, score=-1.272 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-18.314 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-18.060 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.998 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.652 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=0.8;, score=-17.405 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.170 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.186 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.154 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.092 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=7, n_estimators=300, subsample=0.9;, score=-2.184 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.617 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.584 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.559 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.517 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.5, learning_rate=0.05, max_depth=3, n_estimators=500, subsample=1.0;, score=-1.609 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.182 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.196 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.179 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.144 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.01, max_depth=9, n_estimators=2000, subsample=1.0;, score=-1.228 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=-2.493 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=-2.478 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=-2.276 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=-2.139 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.1, max_depth=3, n_estimators=100, subsample=0.8;, score=-2.408 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.213 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.259 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.174 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.173 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.05, max_depth=5, n_estimators=500, subsample=1.0;, score=-1.300 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.184 total time=   0.7s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.227 total time=   0.7s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.215 total time=   0.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.191 total time=   0.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=12, n_estimators=500, subsample=0.8;, score=-1.264 total time=   0.7s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=-7.688 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=-7.421 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=-7.294 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=-7.282 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.01, max_depth=3, n_estimators=200, subsample=0.9;, score=-7.737 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.295 total time=   1.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.331 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.250 total time=   1.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.208 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.4, learning_rate=0.005, max_depth=5, n_estimators=2000, subsample=0.8;, score=-1.380 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-11.241 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-11.078 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-11.089 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.809 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.5, learning_rate=0.01, max_depth=12, n_estimators=100, subsample=1.0;, score=-10.674 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.567 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.226 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-24.117 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-23.641 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=15, n_estimators=200, subsample=0.8;, score=-23.398 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.205 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.257 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.229 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.204 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=9, n_estimators=200, subsample=0.8;, score=-1.279 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=1.0;, score=-14.074 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=1.0;, score=-13.685 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=1.0;, score=-13.611 total time=   0.3s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=1.0;, score=-13.330 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.001, max_depth=3, n_estimators=1000, subsample=1.0;, score=-13.507 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.564 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.553 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.513 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.445 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.2, learning_rate=0.05, max_depth=5, n_estimators=100, subsample=0.8;, score=-1.610 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-18.206 total time=   0.3s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.980 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.931 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.560 total time=   0.3s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.2, learning_rate=0.001, max_depth=7, n_estimators=500, subsample=1.0;, score=-17.317 total time=   0.3s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.233 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.249 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.173 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.154 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.1, max_depth=5, n_estimators=200, subsample=1.0;, score=-1.301 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-6.116 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.904 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.833 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-5.910 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.3, learning_rate=0.05, max_depth=3, n_estimators=50, subsample=1.0;, score=-6.200 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=0.8;, score=-24.534 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=0.8;, score=-24.159 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=0.8;, score=-24.068 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=0.8;, score=-23.597 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.1, learning_rate=0.005, max_depth=3, n_estimators=50, subsample=0.8;, score=-23.387 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-7.270 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-7.113 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-7.152 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-6.981 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=7, n_estimators=300, subsample=0.8;, score=-6.850 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=1.0;, score=-2.063 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=1.0;, score=-2.069 total time=   0.3s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=1.0;, score=-2.076 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=1.0;, score=-2.012 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.01, max_depth=9, n_estimators=300, subsample=1.0;, score=-2.055 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.172 total time=   1.5s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.211 total time=   1.8s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.177 total time=   1.7s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.136 total time=   1.7s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.3, learning_rate=0.005, max_depth=7, n_estimators=2000, subsample=0.8;, score=-1.257 total time=   1.7s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=-2.497 total time=   0.1s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=-2.439 total time=   0.1s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=-2.470 total time=   0.1s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=-2.298 total time=   0.1s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.2, learning_rate=0.01, max_depth=5, n_estimators=300, subsample=0.9;, score=-2.532 total time=   0.1s\n",
      "[CV 1/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.136 total time=   1.1s\n",
      "[CV 2/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.985 total time=   1.0s\n",
      "[CV 3/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-11.034 total time=   1.1s\n",
      "[CV 4/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.751 total time=   1.1s\n",
      "[CV 5/5] END colsample_bytree=1.0, gamma=0.4, learning_rate=0.001, max_depth=15, n_estimators=1000, subsample=0.8;, score=-10.595 total time=   1.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-7.232 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-7.073 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-7.122 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.926 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0, learning_rate=0.005, max_depth=9, n_estimators=300, subsample=1.0;, score=-6.829 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.694 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.556 total time=   0.4s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.530 total time=   0.4s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.307 total time=   0.4s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.4, learning_rate=0.001, max_depth=5, n_estimators=1000, subsample=1.0;, score=-11.212 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.463 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.398 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.452 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.327 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0, learning_rate=0.01, max_depth=12, n_estimators=200, subsample=0.9;, score=-4.290 total time=   0.2s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=1.0;, score=-11.967 total time=   0.0s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=1.0;, score=-11.764 total time=   0.0s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=1.0;, score=-11.751 total time=   0.0s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=1.0;, score=-11.531 total time=   0.0s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.005, max_depth=5, n_estimators=200, subsample=1.0;, score=-11.385 total time=   0.0s\n",
      "[CV 1/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.224 total time=   0.4s\n",
      "[CV 2/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.309 total time=   0.5s\n",
      "[CV 3/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.261 total time=   0.5s\n",
      "[CV 4/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.254 total time=   0.5s\n",
      "[CV 5/5] END colsample_bytree=0.8, gamma=0.5, learning_rate=0.1, max_depth=15, n_estimators=500, subsample=0.8;, score=-1.325 total time=   0.5s\n",
      "[CV 1/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-22.266 total time=   0.2s\n",
      "[CV 2/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.953 total time=   0.2s\n",
      "[CV 3/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.867 total time=   0.2s\n",
      "[CV 4/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.424 total time=   0.2s\n",
      "[CV 5/5] END colsample_bytree=0.9, gamma=0.3, learning_rate=0.001, max_depth=12, n_estimators=300, subsample=0.9;, score=-21.197 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                          n_estimators=None, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          random_state=42, ...),\n",
       "                   n_iter=1000,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.8, 0.9, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                                        &#x27;learning_rate&#x27;: [0.001, 0.005, 0.01,\n",
       "                                                          0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 9, 12, 15],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 200, 300, 500,\n",
       "                                                         1000, 2000],\n",
       "                                        &#x27;subsample&#x27;: [0.8, 0.9, 1.0]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "                   verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                          n_estimators=None, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          random_state=42, ...),\n",
       "                   n_iter=1000,\n",
       "                   param_distributions={&#x27;colsample_bytree&#x27;: [0.8, 0.9, 1.0],\n",
       "                                        &#x27;gamma&#x27;: [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                                        &#x27;learning_rate&#x27;: [0.001, 0.005, 0.01,\n",
       "                                                          0.05, 0.1],\n",
       "                                        &#x27;max_depth&#x27;: [3, 5, 7, 9, 12, 15],\n",
       "                                        &#x27;n_estimators&#x27;: [50, 100, 200, 300, 500,\n",
       "                                                         1000, 2000],\n",
       "                                        &#x27;subsample&#x27;: [0.8, 0.9, 1.0]},\n",
       "                   random_state=42, scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "                   verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "             gamma=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "             num_parallel_tree=None, random_state=42, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          callbacks=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, device=None,\n",
       "                                          early_stopping_rounds=None,\n",
       "                                          enable_categorical=False,\n",
       "                                          eval_metric=None, feature_types=None,\n",
       "                                          gamma=None, grow_policy=None,\n",
       "                                          importance_type=None,\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=...\n",
       "                                          n_estimators=None, n_jobs=None,\n",
       "                                          num_parallel_tree=None,\n",
       "                                          random_state=42, ...),\n",
       "                   n_iter=1000,\n",
       "                   param_distributions={'colsample_bytree': [0.8, 0.9, 1.0],\n",
       "                                        'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
       "                                        'learning_rate': [0.001, 0.005, 0.01,\n",
       "                                                          0.05, 0.1],\n",
       "                                        'max_depth': [3, 5, 7, 9, 12, 15],\n",
       "                                        'n_estimators': [50, 100, 200, 300, 500,\n",
       "                                                         1000, 2000],\n",
       "                                        'subsample': [0.8, 0.9, 1.0]},\n",
       "                   random_state=42, scoring='neg_mean_absolute_error',\n",
       "                   verbose=3)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "searchCV = RandomizedSearchCV(\n",
    "    estimator = xgb_model,\n",
    "    param_distributions = params,\n",
    "    n_iter = 1000,\n",
    "    scoring = 'neg_mean_absolute_error',\n",
    "    cv = 5,\n",
    "    verbose = 3,\n",
    "    random_state = 42\n",
    ")\n",
    "\n",
    "searchCV.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss : 2.05\n"
     ]
    }
   ],
   "source": [
    "best_model = searchCV.best_estimator_\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "mse_loss = mean_squared_error(y_pred, y_test)\n",
    "rmse_loss = mse_loss ** 0.5\n",
    "print(f'MSE loss : {rmse_loss:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[130.5088    79.88908   64.84758   35.029934  41.91058  102.85184\n",
      "  23.17026   36.52204   81.32663   23.224688  69.34338   62.55764\n",
      "  40.214306 100.262314  90.663475  22.947094 126.1691    52.443893\n",
      "  60.006718  34.855286  37.796066 159.8093    51.282085  55.77923\n",
      "  22.799162  43.543438  79.21934   79.9267    27.947556 126.23641\n",
      "  69.08447   43.72464  114.634544  88.17935   35.880405  79.862656\n",
      "  24.288229  36.947422  23.420235 120.88507  127.38409   21.352177\n",
      " 119.60027   60.711487  22.781172 100.078804  23.224688  74.096504\n",
      "  62.910484  77.53992   35.54916   16.151     38.78573  126.50788\n",
      "  23.699068  27.947607 155.99019   41.110504 159.89899   40.214306\n",
      "  55.744648 124.648636  47.922035 120.8268    40.143463  34.12049\n",
      "  72.356476  50.572002 100.11191   23.106705  44.831676  27.947607\n",
      "  64.12446   39.107437 124.83039   22.790588  41.108635 120.942116\n",
      " 160.19987   80.04771   27.51886   40.98694   19.38161   34.12049\n",
      "  36.351948  36.726353  57.405926  88.26016   64.80233   53.701527\n",
      "  40.99912   70.06196   19.957151  79.70491   23.32533   24.790703\n",
      "  65.472984 126.338264  65.53013   96.06184  127.62547   27.947607\n",
      "  68.12365   40.15817   23.75156   22.929358  97.14273  101.18911\n",
      "  23.679094  34.746403  52.443893  34.166515  24.784586  24.769798\n",
      "  36.52204   20.219246  70.17023  119.548904 156.0052    46.480167\n",
      "  64.022385  37.679337 160.20401   60.967632  14.100251  37.628464\n",
      "  72.16125   80.01177   28.085344  81.09292   76.31464   19.051271\n",
      "  23.302486  37.110825  23.527327  79.66973   59.753872  63.873493\n",
      "  71.72529   28.161549  27.816004  55.786774  23.18697   72.45628\n",
      "  23.200998  73.86977   70.03596   28.083757  53.701527  65.45853\n",
      "  64.95963  130.38933   77.46841   37.68698   63.991264 151.30237\n",
      "  23.062954  65.475655  95.3546    81.22564   41.012783  60.719\n",
      "  38.63065   53.867405  45.79419   72.35911   40.214306 126.19816\n",
      "  81.19391  151.25426  151.24004   95.18205   60.696083  38.710068\n",
      "  23.113882  22.943651  50.720463  44.18402   57.91075   23.801117\n",
      "  97.33247  159.0304    58.8122    23.14702   27.731745  38.7655\n",
      "  58.827984  37.679337  22.947094  27.731745 151.17632   23.14702\n",
      "  38.86867   96.06184   19.562256  79.71221  100.15319   44.532055\n",
      "  35.582146  22.900192  35.676044  98.74621   55.768555  58.588093\n",
      "  35.676044  22.892769  71.72529   58.030075  70.053375  35.623844\n",
      "  35.735184 155.98306   43.392914 100.32232   69.52292   23.083384\n",
      "  65.442955  80.03426   72.26858   43.87091   37.6674    51.62766\n",
      " 114.8994   159.83919   71.45426   37.628464  78.09049   58.83948\n",
      "  44.78996   69.99397   79.93333   79.98667   36.973915 156.02504\n",
      "  99.2839    34.800888 124.83039   53.709282  69.92555   83.63136\n",
      "  53.86002   99.41785   44.05994   59.689007  67.30559   80.00848\n",
      " 159.59073  120.807556  80.07923   37.611824  42.49063   38.993977\n",
      " 126.23641   45.11569   63.883873 160.27264   22.575478  63.90795\n",
      "  74.0981    79.98249  130.48112   27.382015  28.061962  19.272472\n",
      "  23.64736   34.84388  120.88613   37.628464  64.20659   72.735405\n",
      "  44.451714 126.59589   28.161549  27.731745  19.575497  41.839767\n",
      "  65.404884  52.443893  45.559723  35.893494  23.75552   90.65832\n",
      "  77.57557   36.047165 120.8807    19.599087  27.998543 120.71574\n",
      " 124.52992   43.12673   34.746403  98.74621   27.382015  74.11042\n",
      "  64.05312   99.23816   27.918037  27.947607  38.78573   63.04133\n",
      "  34.746403  57.57418   44.86454   19.034206  83.34093   43.467766\n",
      " 126.338264  74.431854  35.394234  73.846375  36.52204   52.443893\n",
      "  70.31567   77.42693  101.21956   22.891388  38.667984  23.01029\n",
      " 100.315384  36.911728  95.58791   74.09851   49.234367  73.96861\n",
      "  95.21523  120.877625  23.723736  70.740204  80.04041   23.679094\n",
      "  27.382015 159.15723   23.765059  38.76691   34.12049  100.15816\n",
      "  57.42777   50.213963  99.37814   64.94136   69.52292   34.8113\n",
      "  22.900192  36.278397 119.570404 100.14479  120.8807    23.311031\n",
      " 126.444176  57.57418   76.331856  80.10618   38.98653   39.022995\n",
      "  71.79677   92.727036  41.010284  24.80724   43.626293 100.18614\n",
      "  23.707724  22.804369  22.82506   35.214005  38.92154   35.68916\n",
      "  44.40776   88.20636   55.76201   79.64841   72.16125  100.05558\n",
      "  40.286324  35.688793  96.81487  120.69222   38.880898  42.372932\n",
      "  35.214005  19.334814  39.022995  22.891388  23.285992  73.84068\n",
      "  23.788525  45.28839  159.565     36.57778   44.4377    64.02671\n",
      "  50.43221   64.30803   23.094772 126.23663   38.87838   60.154884\n",
      "  35.771744  93.38815   36.695488  28.154423  22.875187  99.247086\n",
      "  36.351948  20.235083  67.60485   38.958004  39.03917  100.17917\n",
      "  80.18587   58.8122    37.827477  64.95151   27.731745  64.948944\n",
      "  70.10335   59.738216  38.93249   41.02143  122.51484  130.50023\n",
      "  45.151817  99.250114  57.601482  27.998543 155.90619   64.95963\n",
      "  28.03277   60.053898  37.80651   79.95992   38.923225  63.782227\n",
      "  53.895267  19.481565  72.38375   22.837255  38.502773  79.93676\n",
      "  37.684196  77.67938   75.54563   41.090435  99.737236  73.81322\n",
      "  74.38501   52.96916   37.359745  57.57418   63.73774   79.915886\n",
      "  83.32379  100.02636   17.613682  69.50283   57.20778   27.382015\n",
      "  50.824245  38.7655    27.79579   23.08095   22.575478  95.23022\n",
      "  34.746403  49.506306  79.38225  120.942116  50.8924   159.1956\n",
      "  80.3443    36.51183   62.651093  43.445778  27.970882  38.70125\n",
      "  40.214306  35.696682 120.8807    59.709255  62.58176   65.27084\n",
      "  41.01102   60.98989  151.14102   77.57557   28.171135  53.701527\n",
      "  65.442955  70.06437   27.947607  23.019615  27.731745  38.659912\n",
      "  59.720917  59.949497  79.98667   37.054497  37.68698   77.51498\n",
      "  85.15296  101.02164   60.7819   129.80927   23.778622  74.09303\n",
      "  66.85379   68.36806  160.01433   17.162354  80.05154   59.826515\n",
      "  50.75208   16.805136  38.93249  100.4724    59.65241   38.827015\n",
      "  63.73548   27.731745  74.30775   69.52292   69.713684  95.64127\n",
      "  17.289463  36.89684   43.72464   18.555395  73.85432   72.669205\n",
      "  68.9118    23.75261  125.06444   24.979214 127.382065  53.13652\n",
      " 159.17867   79.92781   34.084003  77.69244   79.94207   27.79579\n",
      " 126.23641  122.53524   22.906351  62.647217  65.150375 120.82334\n",
      "  72.282524  59.954533  23.04761   38.659912  23.241829  23.158638\n",
      "  41.491314  79.98667   22.7481    63.73784  100.033775  44.801548\n",
      "  22.549646  35.66799   80.199295  36.937004  18.246428  99.267075\n",
      "  28.039946  80.04041   73.854805  23.715094  22.901018  79.17509\n",
      "  59.754547 126.10972   28.032106  23.813488  35.59708   45.620586\n",
      "  80.0558    79.93676  118.27354   52.21103   27.947556  57.693714\n",
      "  27.868254  60.51252   68.67978   40.214306  64.01423   27.970882\n",
      "  23.254246  34.15527  160.59514   27.816004 114.96428   88.35739\n",
      "  28.110561  23.679094  35.746876 160.50334  159.2138    23.75552\n",
      "  38.958004  27.96054   21.258514  99.28001   19.562256  77.13901\n",
      "  60.600822  70.06446   34.12049   35.646786 155.9011   118.49528\n",
      "  80.10296   27.918037  23.795029  22.990911  37.6674   100.46984\n",
      "  79.86156   37.827477  59.858334  79.90043  123.56386   64.00875\n",
      "  40.230186  19.609747  35.676044  34.166515  37.644924  79.88652\n",
      "  45.200466  23.05204   22.878132  23.679094  36.479774 100.27986\n",
      "  22.549646 130.48509   79.96664  159.68272  159.57253   22.980404\n",
      "  72.90009   27.876593  19.489138  77.54427   73.854805  99.25559\n",
      "  44.312153  36.57778   79.88652   23.756475  16.374218  28.0714\n",
      "  77.8483    77.46841   38.63065   27.731745  23.016575  55.822224\n",
      "  69.73964  122.51484   65.51222  160.6611    45.896217 159.89899\n",
      "  59.694008 114.970184  38.880898  27.382015  79.954926  52.999096\n",
      "  49.133186  74.12283   42.767426  20.259466 130.49481   60.719\n",
      "  83.332405  99.2839   100.25813   50.454403  28.003769  79.94207\n",
      "  37.70816   36.959385  37.270336  27.359797  60.192055 114.76553\n",
      "  64.02891  120.69222   22.990911  22.965044  73.85997   67.90898\n",
      " 100.21126   37.801247  34.746403  59.746895  85.15296   28.062025\n",
      "  38.958004  96.06184  124.648636  41.108635  72.19072   24.785181\n",
      "  38.728363 155.8874   160.01433   23.245472  63.920883  74.11364\n",
      "  27.970882  72.329575 126.05784   23.746412  43.842842  98.02426\n",
      "  99.270966  58.8122    60.776527  59.882656  37.679337  36.937004\n",
      "  43.176285  77.79798   36.830227  36.85762   75.66102   35.80947\n",
      "  22.80707   62.57835   24.88189  100.08467   50.6701   120.835144\n",
      "  45.77114   27.372116  27.816004  23.748556  20.63052   63.750393\n",
      "  34.84474   23.14702   71.72529   79.976364  70.06437   22.575478\n",
      "  67.90898   70.264046  78.379745  19.489138  90.6411    28.061474\n",
      "  83.3258    52.443893 120.71789   36.197285  36.629387  50.365967\n",
      "  51.78039   28.077633  74.176025 100.11026  155.99019   65.09627\n",
      "  22.951683  90.66487   34.746403  27.731745  35.548485  23.023603\n",
      "  40.230186  34.166515  49.506306  95.64127   22.799162  72.35889\n",
      "  27.561073  63.777863 118.677765  19.115435 160.12804   64.9253\n",
      "  64.020775 126.3534    79.94207   68.560196  60.053898  23.134424\n",
      " 160.24426  151.2179    96.06184  118.418106  55.76201   22.875187\n",
      "  23.39      41.721706  23.08095   64.95204   37.64449   28.05743\n",
      " 101.21811   44.352043  24.792158  63.742996  65.352066 100.28058\n",
      " 155.91331   37.65882  160.20967   83.2768    28.171135  59.923187\n",
      "  23.340145  27.424229 156.08636  100.16442   22.951683  27.424229\n",
      "  74.43493   35.0941    64.91176   53.849205  37.65882   36.937004\n",
      " 126.50788  151.26707   22.811357 120.87214  114.96428   35.745922\n",
      "  34.819054  79.64841   59.698746  57.601482 100.1227    45.200466\n",
      "  22.781172 151.26707   38.819225  38.92154   58.827515  22.973999]\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_model.predict(test_df)\n",
    "print(test_pred)\n",
    "\n",
    "submission_df['가격(백만원)'] = test_pred\n",
    "\n",
    "submission_df.to_csv(DATA_PATH + 'submission.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
