{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "이 파일은 read.me 같은 설명서 \n",
    "모델의 약점은 제일 마지막에 설명되어잇음 \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "내가 사용한 전처리 이미지 전처리 부분 \n",
    "\n",
    "단, 예를 들어 사용한다면 꼭 train = False를 매개변수로 써서 활용할것! \n",
    "\n",
    "val_transforms = CustomTransforms(train=False)\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransforms:\n",
    "    def __init__(self, train=True):\n",
    "        if train:\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.RandomResizedCrop(size=(224, 224), scale=(0.8, 1.0)),\n",
    "                transforms.RandomHorizontalFlip(p=0.5),\n",
    "                transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        else:\n",
    "            self.transforms = transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "\n",
    "    def __call__(self, img):\n",
    "        return self.transforms(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = CustomTransforms(train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "저장된 모델을 불러올때는 쓰는 부분은 밑에 거 처럼 하면 됌\n",
    "결국 제일 마지막에 한 리니어 층 한개로 한개 일단 제일 성능이 잘 나왓음. \n",
    "약 0.7 정도임 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 저장된 모델 불러오기\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = models.vgg16(pretrained=False)\n",
    "model.classifier[6] = torch.nn.Linear(4096, 1)\n",
    "model.load_state_dict(torch.load('vgg16_cheetah_classifier.pth', map_location=device))\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "그리고 예측 값을 보기 위해서  sigmoid를 써서 0.5 이하라면 0 / 0.5 이상이라면 1이나오게끔 하는 함수 \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    image = val_transforms(image).unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        prediction = torch.sigmoid(output).item()\n",
    "    return 1 if prediction >= 0.5 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'''\n",
    "일단 문양 구분이 부분이 매우 부족함\n",
    "따라서 아기 표범의 경우 구분을 매우 못함\n",
    "\n",
    "두번째 늘씬한 형태로 점박이가 되어 있으면 치타라 인식할 가능성이 잇음\n",
    "\n",
    "세번째 위의 것과 연관되는 것으로 늘씬한 형태가 아니면 예를 들어 치타의 얼굴이 있다면 치타가 아니라고 할 가능성이 높음\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TORCH_CV_38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
